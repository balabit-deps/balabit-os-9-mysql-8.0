From 70ae968189d17cf7ccbd4abe4b4aa20b28309d84 Mon Sep 17 00:00:00 2001
From: Corey Bryant <corey.bryant@canonical.com>
Date: Fri, 27 Jan 2023 17:06:49 -0500
Subject: [PATCH 41/86] Revert "Bug#34698897 Metadata cache does not allow
 returning the whole cluster(set) topology."

This reverts commit 173fa4db9d433d60e1072a70b5ae64cbdc1187cc.
---
 .../include/mysqlrouter/metadata.h            |   6 +-
 .../include/mysqlrouter/metadata_cache.h      |  54 +--
 .../mysqlrouter/metadata_cache_datatypes.h    |  61 +--
 router/src/metadata_cache/src/cache_api.cc    |  20 +-
 .../metadata_cache/src/cluster_metadata.cc    |  17 +-
 .../src/metadata_cache/src/cluster_metadata.h |   8 +-
 .../metadata_cache/src/cluster_metadata_ar.cc |  79 ++--
 .../metadata_cache/src/cluster_metadata_ar.h  |  14 +-
 .../metadata_cache/src/cluster_metadata_gr.cc | 430 +++++++++---------
 .../metadata_cache/src/cluster_metadata_gr.h  |  18 +-
 .../src/gr_notifications_listener.cc          |  81 ++--
 .../src/gr_notifications_listener.h           |   3 +-
 .../src/metadata_cache/src/metadata_cache.cc  |  67 ++-
 .../src/metadata_cache/src/metadata_cache.h   |  20 +-
 .../metadata_cache/src/metadata_cache_ar.cc   |  14 +-
 .../metadata_cache/src/metadata_cache_gr.cc   |  79 ++--
 .../src/metadata_cache_plugin.cc              |   8 +-
 .../tests/helper/mock_metadata.cc             |  20 +-
 .../tests/helper/mock_metadata.h              |   5 +-
 .../metadata_cache/tests/test_cache_plugin.cc |   4 +-
 .../src/metadata_cache/tests/test_failover.cc |  20 +-
 .../src/metadata_cache/tests/test_metadata.cc | 384 ++++++----------
 .../tests/test_metadata_cache.cc              |  16 +-
 .../src/rest_clusters_nodes.cc                |   4 +-
 .../src/rest_metadata_cache_config.cc         |  26 +-
 router/src/router/src/cluster_metadata.cc     |   9 +-
 router/src/routing/src/dest_metadata_cache.cc |  37 +-
 router/src/routing/src/dest_metadata_cache.h  |  19 +-
 .../tests/test_metadata_cache_group.cc        | 281 ++++--------
 .../data/bootstrap_access_error_at_grant.js   |   2 +-
 ...bootstrap_account_host_pattern_too_long.js |   2 +-
 router/tests/component/data/bootstrap_ar.js   |   2 +-
 .../data/bootstrap_exec_time_2_seconds.js     |   2 +-
 router/tests/component/data/bootstrap_gr.js   |   7 +-
 .../component/data/bootstrap_gr_dup_router.js |   2 +-
 .../tests/component/data/bootstrap_gr_v1.js   |   2 +-
 .../component/data/bootstrap_report_host.js   |   2 +-
 .../data/local_modules/common_statements.js   |  70 +--
 .../component/data/metadata_clusterset.js     |   8 -
 .../data/metadata_dynamic_nodes_v2_gr.js      |   6 +
 .../tests/component/data/rest_api_enable.js   |   2 +-
 router/tests/component/test_bootstrap.cc      |  63 ++-
 .../tests/component/test_bootstrap_account.cc |   5 +-
 .../component/test_bootstrap_clusterset.cc    |  15 +-
 .../test_bootstrap_system_deployment.cc       |   2 +-
 router/tests/component/test_clusterset.cc     | 294 ++----------
 .../test_master_key_reader_writer.cc          |   8 +-
 .../tests/component/test_rest_api_enable.cc   |   8 +-
 router/tests/component/test_routing.cc        |   2 +-
 router/tests/component/test_state_file.cc     |  10 +-
 .../helpers/router_component_clusterset.cc    |  16 +-
 .../helpers/router_component_clusterset.h     |   7 +-
 router/tests/helpers/router_component_test.cc |   2 +-
 router/tests/helpers/router_component_test.h  |   2 +-
 54 files changed, 925 insertions(+), 1420 deletions(-)

diff --git a/router/src/metadata_cache/include/mysqlrouter/metadata.h b/router/src/metadata_cache/include/mysqlrouter/metadata.h
index e086632cea7..08ffdf8d00a 100644
--- a/router/src/metadata_cache/include/mysqlrouter/metadata.h
+++ b/router/src/metadata_cache/include/mysqlrouter/metadata.h
@@ -62,8 +62,7 @@ class METADATA_CACHE_EXPORT MetaData {
       mysqlrouter::TargetCluster &target_cluster, const unsigned router_id,
       const metadata_cache::metadata_servers_list_t &metadata_servers,
       bool needs_writable_node, const std::string &cluster_type_specific_id,
-      const std::string &clusterset_id, bool whole_topology,
-      std::size_t &instance_id) = 0;
+      const std::string &clusterset_id, std::size_t &instance_id) = 0;
 
   virtual bool update_router_attributes(
       const metadata_cache::metadata_server_t &rw_server,
@@ -80,7 +79,8 @@ class METADATA_CACHE_EXPORT MetaData {
   virtual void disconnect() = 0;
 
   virtual void setup_notifications_listener(
-      const metadata_cache::ClusterTopology &cluster_topology,
+      const std::vector<metadata_cache::ManagedInstance> &instances,
+      const mysqlrouter::TargetCluster &target_cluster,
       const std::function<void()> &callback) = 0;
 
   virtual void shutdown_notifications_listener() = 0;
diff --git a/router/src/metadata_cache/include/mysqlrouter/metadata_cache.h b/router/src/metadata_cache/include/mysqlrouter/metadata_cache.h
index 9afef98002b..f55c2ebbecf 100644
--- a/router/src/metadata_cache/include/mysqlrouter/metadata_cache.h
+++ b/router/src/metadata_cache/include/mysqlrouter/metadata_cache.h
@@ -81,6 +81,20 @@ class metadata_error : public std::runtime_error {
       : std::runtime_error(what_arg) {}
 };
 
+/** @class LookupResult
+ *
+ * Class holding result after looking up data in the cache.
+ */
+class METADATA_CACHE_EXPORT LookupResult {
+ public:
+  /** @brief Constructor */
+  LookupResult(const cluster_nodes_list_t &instance_vector_)
+      : instance_vector(instance_vector_) {}
+
+  /** @brief List of ManagedInstance objects */
+  const cluster_nodes_list_t instance_vector;
+};
+
 /**
  * @brief Abstract class that provides interface for listener on
  *        cluster status changes.
@@ -93,14 +107,16 @@ class METADATA_CACHE_EXPORT ClusterStateListenerInterface {
    * @brief Callback function that is called when state of cluster is
    * changed.
    *
-   * @param cluster_topology current cluster topology
+   * @param instances allowed nodes
+   * @param metadata_servers list of the Cluster metadata servers
    * @param md_servers_reachable true if metadata changed, false if metadata
    * unavailable
    * @param view_id current metadata view_id in case of ReplicaSet cluster
    */
-  virtual void notify_instances_changed(const ClusterTopology &cluster_topology,
-                                        const bool md_servers_reachable,
-                                        const uint64_t view_id) = 0;
+  virtual void notify_instances_changed(
+      const LookupResult &instances,
+      const metadata_cache::metadata_servers_list_t &metadata_servers,
+      const bool md_servers_reachable, const uint64_t view_id) = 0;
 
   ClusterStateListenerInterface() = default;
   // disable copy as it isn't needed right now. Feel free to enable
@@ -122,10 +138,9 @@ class METADATA_CACHE_EXPORT AcceptorUpdateHandlerInterface {
    * @brief Callback function that is called when the state of the sockets
    * acceptors is handled during the metadata refresh.
    *
-   * @param instances list of the current cluster nodes
+   * @param instances allowed nodes for new connections
    */
-  virtual bool update_socket_acceptor_state(
-      const metadata_cache::cluster_nodes_list_t &instances) = 0;
+  virtual bool update_socket_acceptor_state(const LookupResult &instances) = 0;
 
   AcceptorUpdateHandlerInterface() = default;
 
@@ -149,12 +164,12 @@ class METADATA_CACHE_EXPORT MetadataRefreshListenerInterface {
   /**
    * Callback that is going to be used on each metadata refresh.
    *
-   * @param[in] instances_changed Informs if the cluster topology has changed
-   * since last md refresh.
-   * @param[in] cluster_topology current cluster topology
+   * @param[in] instances_changed Informs if the instances returned by the
+   *            metadata refresh has changed since last md refresh.
+   * @param[in] instances List of new instances available after md refresh.
    */
   virtual void on_md_refresh(const bool instances_changed,
-                             const ClusterTopology &cluster_topology) = 0;
+                             const LookupResult &instances) = 0;
 
   virtual ~MetadataRefreshListenerInterface() = default;
 };
@@ -276,9 +291,6 @@ class METADATA_CACHE_EXPORT MetadataCacheAPIBase
 
   virtual bool is_initialized() noexcept = 0;
 
-  virtual bool fetch_whole_topology() const = 0;
-  virtual void fetch_whole_topology(bool val) = 0;
-
   virtual mysqlrouter::ClusterType cluster_type() const = 0;
 
   /**
@@ -297,13 +309,7 @@ class METADATA_CACHE_EXPORT MetadataCacheAPIBase
    *
    * @return List of ManagedInstance objects
    */
-  virtual cluster_nodes_list_t get_cluster_nodes() = 0;
-
-  /** @brief Return object containing current cluster topology.
-   *
-   * @return List of ManagedInstance objects
-   */
-  virtual ClusterTopology get_cluster_topology() = 0;
+  virtual LookupResult get_cluster_nodes() = 0;
 
   /** @brief Wait until there's a primary member in the cluster
    *
@@ -484,8 +490,7 @@ class METADATA_CACHE_EXPORT MetadataCacheAPI : public MetadataCacheAPIBase {
 
   void cache_stop() noexcept override;
 
-  cluster_nodes_list_t get_cluster_nodes() override;
-  ClusterTopology get_cluster_topology() override;
+  LookupResult get_cluster_nodes() override;
 
   bool wait_primary_failover(const std::string &primary_server_uuid,
                              const std::chrono::seconds &timeout) override;
@@ -521,9 +526,6 @@ class METADATA_CACHE_EXPORT MetadataCacheAPI : public MetadataCacheAPIBase {
     instance_factory_ = std::move(cb);
   }
 
-  bool fetch_whole_topology() const override;
-  void fetch_whole_topology(bool val) override;
-
  private:
   metadata_factory_t instance_factory_{&metadata_factory_get_instance};
 
diff --git a/router/src/metadata_cache/include/mysqlrouter/metadata_cache_datatypes.h b/router/src/metadata_cache/include/mysqlrouter/metadata_cache_datatypes.h
index 376af307a79..2b25e5058f4 100644
--- a/router/src/metadata_cache/include/mysqlrouter/metadata_cache_datatypes.h
+++ b/router/src/metadata_cache/include/mysqlrouter/metadata_cache_datatypes.h
@@ -27,8 +27,6 @@
 
 #include "mysqlrouter/metadata_cache_export.h"
 
-#include <algorithm>
-#include <optional>
 #include <string>
 #include <system_error>
 #include <vector>
@@ -40,6 +38,8 @@ namespace metadata_cache {
 
 enum class metadata_errc {
   ok,
+  no_rw_node_found,
+  no_rw_node_needed,
   no_metadata_server_reached,
   no_metadata_read_successful,
   metadata_refresh_terminated,
@@ -64,6 +64,10 @@ inline const std::error_category &metadata_cache_category() noexcept {
       switch (static_cast<metadata_errc>(ev)) {
         case metadata_errc::ok:
           return "ok";
+        case metadata_errc::no_rw_node_found:
+          return "no RW node found";
+        case metadata_errc::no_rw_node_needed:
+          return "RW node not requested";
         case metadata_errc::no_metadata_server_reached:
           return "no metadata server accessible";
         case metadata_errc::no_metadata_read_successful:
@@ -94,7 +98,6 @@ constexpr const bool kNodeTagHiddenDefault{false};
 constexpr const bool kNodeTagDisconnectWhenHiddenDefault{true};
 
 enum class ServerMode { ReadWrite, ReadOnly, Unavailable };
-enum class ServerRole { Primary, Secondary, Unavailable };
 enum class InstanceType { GroupMember, AsyncMember, ReadReplica };
 
 /** @class ManagedInstance
@@ -104,9 +107,8 @@ enum class InstanceType { GroupMember, AsyncMember, ReadReplica };
 class METADATA_CACHE_EXPORT ManagedInstance {
  public:
   ManagedInstance(InstanceType p_type, const std::string &p_mysql_server_uuid,
-                  const ServerMode p_mode, const ServerRole p_role,
-                  const std::string &p_host, const uint16_t p_port,
-                  const uint16_t p_xport);
+                  const ServerMode p_mode, const std::string &p_host,
+                  const uint16_t p_port, const uint16_t p_xport);
 
   using TCPAddress = mysql_harness::TCPAddress;
   explicit ManagedInstance(InstanceType p_type);
@@ -119,17 +121,13 @@ class METADATA_CACHE_EXPORT ManagedInstance {
   /** @brief The uuid of the MySQL server */
   std::string mysql_server_uuid;
   /** @brief The mode of the server */
-  ServerMode mode{ServerMode::Unavailable};
-  /** @brief The role of the server */
-  ServerRole role{ServerRole::Unavailable};
+  ServerMode mode;
   /** @brief The host name on which the server is running */
   std::string host;
   /** The port number in which the server is running */
-  uint16_t port{0};
+  uint16_t port;
   /** The X protocol port number in which the server is running */
-  uint16_t xport{0};
-  /** Node atributes as a json string from metadata */
-  std::string attributes;
+  uint16_t xport;
   /** Should the node be hidden from the application to use it */
   bool hidden{kNodeTagHiddenDefault};
   /** Should the Router disconnect existing client sessions to the node when it
@@ -158,7 +156,6 @@ class METADATA_CACHE_EXPORT ManagedCluster {
   /** @brief Whether the cluster is in single_primary_mode (from PFS in case of
    * GR) */
   bool single_primary_mode;
-
   /** @brief Metadata for the cluster is not consistent (only applicable for
    * the GR cluster when the data in the GR metadata is not consistent with the
    * cluster metadata)*/
@@ -169,6 +166,12 @@ class METADATA_CACHE_EXPORT ManagedCluster {
   /** @brief Is the Cluster marked as invalid in the metadata */
   bool is_invalidated{false};
 
+  // address of the writable metadata server that can be used for updating the
+  // metadata (router version, last_check_in), error code if not found
+  stdx::expected<metadata_cache::metadata_server_t, std::error_code>
+      writable_server{stdx::make_unexpected(
+          make_error_code(metadata_cache::metadata_errc::no_rw_node_found))};
+
   bool empty() const noexcept { return members.empty(); }
 
   void clear() noexcept { members.clear(); }
@@ -178,40 +181,12 @@ class METADATA_CACHE_EXPORT ManagedCluster {
  * Represents a cluster (a GR group or AR members) and its metadata servers
  */
 struct METADATA_CACHE_EXPORT ClusterTopology {
-  using clusters_list_t = std::vector<ManagedCluster>;
-
-  clusters_list_t clusters_data;
-  // index of the target cluster in the clusters_data vector
-  std::optional<size_t> target_cluster_pos{};
+  ManagedCluster cluster_data;
   metadata_servers_list_t metadata_servers;
 
   /** @brief Id of the view this metadata represents (used for AR and
    * ClusterSets)*/
   uint64_t view_id{0};
-
-  /** @brief name of the ClusterSet or empty in case of standalone Cluster */
-  std::string name{};
-
-  // address of the writable metadata server that can be used for updating the
-  // metadata (router version, last_check_in), nullptr_t if not found
-  std::optional<metadata_cache::metadata_server_t> writable_server{};
-
-  cluster_nodes_list_t get_all_members() const {
-    cluster_nodes_list_t result;
-
-    for (const auto &cluster : clusters_data) {
-      result.insert(result.end(), cluster.members.begin(),
-                    cluster.members.end());
-    }
-
-    return result;
-  }
-
-  void clear_all_members() {
-    for (auto &cluster : clusters_data) {
-      cluster.members.clear();
-    }
-  }
 };
 
 /**
diff --git a/router/src/metadata_cache/src/cache_api.cc b/router/src/metadata_cache/src/cache_api.cc
index a446acdf99a..91934a047f4 100644
--- a/router/src/metadata_cache/src/cache_api.cc
+++ b/router/src/metadata_cache/src/cache_api.cc
@@ -173,19 +173,13 @@ void MetadataCacheAPI::cache_stop() noexcept {
  * @return An object that encapsulates a list of managed MySQL servers.
  *
  */
-cluster_nodes_list_t MetadataCacheAPI::get_cluster_nodes() {
+LookupResult MetadataCacheAPI::get_cluster_nodes() {
   // We only want to keep the lock when checking if the metadata cache global is
   // initialized. The object itself protects its shared state in its
   // replicaset_lookup.
   { LOCK_METADATA_AND_CHECK_INITIALIZED(); }
 
-  return g_metadata_cache->get_cluster_nodes();
-}
-
-ClusterTopology MetadataCacheAPI::get_cluster_topology() {
-  { LOCK_METADATA_AND_CHECK_INITIALIZED(); }
-
-  return g_metadata_cache->get_cluster_topology();
+  return LookupResult(g_metadata_cache->get_cluster_nodes());
 }
 
 bool MetadataCacheAPI::wait_primary_failover(
@@ -283,14 +277,4 @@ void MetadataCacheAPI::handle_sockets_acceptors_on_md_refresh() {
   g_metadata_cache->handle_sockets_acceptors_on_md_refresh();
 }
 
-bool MetadataCacheAPI::fetch_whole_topology() const {
-  LOCK_METADATA_AND_CHECK_INITIALIZED();
-
-  return g_metadata_cache->fetch_whole_topology();
-}
-
-void MetadataCacheAPI::fetch_whole_topology(bool val) {
-  g_metadata_cache->fetch_whole_topology(val);
-}
-
 }  // namespace metadata_cache
diff --git a/router/src/metadata_cache/src/cluster_metadata.cc b/router/src/metadata_cache/src/cluster_metadata.cc
index 31fe0e9409b..97a6333b37c 100644
--- a/router/src/metadata_cache/src/cluster_metadata.cc
+++ b/router/src/metadata_cache/src/cluster_metadata.cc
@@ -417,7 +417,7 @@ ClusterMetadata::auth_credentials_t ClusterMetadata::fetch_auth_credentials(
   return auth_credentials;
 }
 
-std::optional<metadata_cache::metadata_server_t>
+stdx::expected<metadata_cache::metadata_server_t, std::error_code>
 ClusterMetadata::find_rw_server(
     const std::vector<metadata_cache::ManagedInstance> &instances) {
   for (auto &instance : instances) {
@@ -426,17 +426,8 @@ ClusterMetadata::find_rw_server(
     }
   }
 
-  return {};
-}
-
-std::optional<metadata_cache::metadata_server_t>
-ClusterMetadata::find_rw_server(
-    const std::vector<metadata_cache::ManagedCluster> &clusters) {
-  for (auto &cluster : clusters) {
-    if (cluster.is_primary) return find_rw_server(cluster.members);
-  }
-
-  return {};
+  return stdx::make_unexpected(
+      make_error_code(metadata_cache::metadata_errc::no_rw_node_found));
 }
 
 /**
@@ -567,8 +558,6 @@ void set_instance_attributes(metadata_cache::ManagedInstance &instance,
   std::string warning;
   auto &log_suppressor = LogSuppressor::instance();
 
-  instance.attributes = attributes;
-
   instance.hidden = get_hidden(attributes, warning);
   // we want to log the warning only when it's changing
   if (warning !=
diff --git a/router/src/metadata_cache/src/cluster_metadata.h b/router/src/metadata_cache/src/cluster_metadata.h
index 44d09772308..dbd8481bdae 100644
--- a/router/src/metadata_cache/src/cluster_metadata.h
+++ b/router/src/metadata_cache/src/cluster_metadata.h
@@ -37,7 +37,6 @@
 #include <cstring>
 #include <map>
 #include <memory>
-#include <optional>
 #include <string>
 #include <vector>
 
@@ -121,11 +120,8 @@ class METADATA_CACHE_EXPORT ClusterMetadata : public MetaData {
       const mysqlrouter::TargetCluster &target_cluster,
       const std::string &cluster_type_specific_id) override;
 
-  std::optional<metadata_cache::metadata_server_t> find_rw_server(
-      const std::vector<metadata_cache::ManagedInstance> &instances);
-
-  std::optional<metadata_cache::metadata_server_t> find_rw_server(
-      const std::vector<metadata_cache::ManagedCluster> &clusters);
+  stdx::expected<metadata_cache::metadata_server_t, std::error_code>
+  find_rw_server(const std::vector<metadata_cache::ManagedInstance> &instances);
 
   std::optional<std::chrono::seconds>
   get_periodic_stats_update_frequency() noexcept override {
diff --git a/router/src/metadata_cache/src/cluster_metadata_ar.cc b/router/src/metadata_cache/src/cluster_metadata_ar.cc
index 63c125257e2..e6716a1fb51 100644
--- a/router/src/metadata_cache/src/cluster_metadata_ar.cc
+++ b/router/src/metadata_cache/src/cluster_metadata_ar.cc
@@ -43,9 +43,8 @@ ARClusterMetadata::fetch_cluster_topology(
     const unsigned /*router_id*/,
     const metadata_cache::metadata_servers_list_t &metadata_servers,
     bool /* needs_writable_node */, const std::string &cluster_type_specific_id,
-    const std::string & /*clusterset_id*/, bool /*whole_topology*/,
-    std::size_t &instance_id) {
-  metadata_cache::ClusterTopology result;
+    const std::string & /*clusterset_id*/, std::size_t &instance_id) {
+  std::vector<metadata_cache::ManagedInstance> new_instances;
 
   bool metadata_read = false;
 
@@ -94,8 +93,8 @@ ARClusterMetadata::fetch_cluster_topology(
         continue;
       }
 
-      result = fetch_topology_from_member(*metadata_connection_, view_id,
-                                          cluster_type_specific_id);
+      new_instances = fetch_instances_from_member(*metadata_connection_,
+                                                  cluster_type_specific_id);
 
       this->view_id_ = view_id;
       metadata_read = true;
@@ -109,18 +108,22 @@ ARClusterMetadata::fetch_cluster_topology(
     }
   }
 
-  const auto &cluster_members = result.get_all_members();
-
-  if (cluster_members.empty()) {
+  if (new_instances.empty()) {
     return stdx::make_unexpected(make_error_code(
         metadata_cache::metadata_errc::no_metadata_read_successful));
   }
 
+  metadata_cache::ClusterTopology result;
+  result.cluster_data.single_primary_mode = true;
+  result.cluster_data.members = std::move(new_instances);
+  result.cluster_data.writable_server =
+      find_rw_server(result.cluster_data.members);
+  result.view_id = this->view_id_;
+
   // for ReplicaSet Cluster we assume metadata servers are just Cluster nodes
-  for (const auto &cluster_node : cluster_members) {
-    result.metadata_servers.emplace_back(cluster_node.host, cluster_node.port);
+  for (const auto &cluster_node : result.cluster_data.members) {
+    result.metadata_servers.push_back({cluster_node.host, cluster_node.port});
   }
-  result.writable_server = find_rw_server(cluster_members);
 
   return result;
 }
@@ -146,18 +149,17 @@ bool ARClusterMetadata::get_member_view_id(mysqlrouter::MySQLSession &session,
 }
 
 // throws metadata_cache::metadata_error
-metadata_cache::ClusterTopology ARClusterMetadata::fetch_topology_from_member(
-    mysqlrouter::MySQLSession &session, unsigned view_id,
-    const std::string &cluster_id) {
-  metadata_cache::ClusterTopology result;
-  metadata_cache::ManagedCluster cluster;
+std::vector<metadata_cache::ManagedInstance>
+ARClusterMetadata::fetch_instances_from_member(
+    mysqlrouter::MySQLSession &session, const std::string &cluster_id) {
+  std::vector<metadata_cache::ManagedInstance> result;
 
   // Get expected topology (what was configured) from metadata server. This will
   // later be compared against current topology (what exists NOW) obtained by
   // comparing to other members view of the world
   std::string query =
-      "select C.cluster_id, C.cluster_name, M.member_id, I.endpoint, "
-      "I.xendpoint, M.member_role, I.attributes from "
+      "select M.member_id, I.endpoint, I.xendpoint, M.member_role, "
+      "I.attributes from "
       "mysql_innodb_cluster_metadata.v2_ar_members M join "
       "mysql_innodb_cluster_metadata.v2_instances I on I.instance_id = "
       "M.instance_id join mysql_innodb_cluster_metadata.v2_ar_clusters C on "
@@ -167,35 +169,40 @@ metadata_cache::ClusterTopology ARClusterMetadata::fetch_topology_from_member(
     query += " where C.cluster_id = " + session.quote(cluster_id);
   }
 
-  auto result_processor = [&cluster](const MySQLSession::Row &row) -> bool {
-    if (row.size() != 7) {
+  // example response
+  // clang-format off
+  // +--------------------------------------+----------------+-----------------+-------------+--------------------------------------------------------------------+
+  // | member_id                            | endpoint       | xendpoint       | member_role | attributes                                                         |
+  // +--------------------------------------+----------------+-----------------+-------------+--------------------------------------------------------------------+
+  // | dc46223b-d620-11e9-9f25-0800276c00e7 | 127.0.0.1:5000 | 127.0.0.1:50000 | PRIMARY     | {"tags": {"_hidden": true}, "joinTime": "2020-03-18 09:36:50.416"} |
+  // | f167ceb4-d620-11e9-9155-0800276c00e7 | 127.0.0.1:5001 | 127.0.0.1:50010 | SECONDARY   | {"joinTime": "2020-03-18 09:36:51.000"}                            |
+  // | 06c519c9-d621-11e9-9451-0800276c00e7 | 127.0.0.1:5002 | 127.0.0.1:50020 | SECONDARY   | {"joinTime": "2020-03-18 09:36:53.456"}                            |
+  // +--------------------------------------+----------------+-----------------+-------------+--------------------------------------------------------------------+
+  // clang-format on
+
+  auto result_processor = [&result](const MySQLSession::Row &row) -> bool {
+    if (row.size() != 5) {
       throw metadata_cache::metadata_error(
           "Unexpected number of fields in the resultset. "
-          "Expected = 7, got = " +
+          "Expected = 5, got = " +
           std::to_string(row.size()));
     }
 
-    cluster.id = get_string(row[0]);
-    cluster.name = get_string(row[1]);
     metadata_cache::ManagedInstance instance{
         metadata_cache::InstanceType::AsyncMember};
-    instance.mysql_server_uuid = get_string(row[2]);
+    instance.mysql_server_uuid = get_string(row[0]);
 
-    if (!set_instance_ports(instance, row, 3, 4)) {
+    if (!set_instance_ports(instance, row, 1, 2)) {
       return true;  // next row
     }
 
-    if (get_string(row[5]) == "PRIMARY") {
-      instance.mode = metadata_cache::ServerMode::ReadWrite;
-      instance.role = metadata_cache::ServerRole::Primary;
-    } else {
-      instance.mode = metadata_cache::ServerMode::ReadOnly;
-      instance.role = metadata_cache::ServerRole::Secondary;
-    }
+    instance.mode = get_string(row[3]) == "PRIMARY"
+                        ? metadata_cache::ServerMode::ReadWrite
+                        : metadata_cache::ServerMode::ReadOnly;
 
-    set_instance_attributes(instance, get_string(row[6]));
+    set_instance_attributes(instance, get_string(row[4]));
 
-    cluster.members.push_back(instance);
+    result.push_back(instance);
     return true;  // get next row if available
   };
 
@@ -207,9 +214,5 @@ metadata_cache::ClusterTopology ARClusterMetadata::fetch_topology_from_member(
     throw metadata_cache::metadata_error(e.what());
   }
 
-  cluster.single_primary_mode = true;
-  result.view_id = view_id;
-  result.clusters_data.push_back(cluster);
-  result.target_cluster_pos = 0;
   return result;
 }
diff --git a/router/src/metadata_cache/src/cluster_metadata_ar.h b/router/src/metadata_cache/src/cluster_metadata_ar.h
index 92a03baf348..4b6cd56a1bd 100644
--- a/router/src/metadata_cache/src/cluster_metadata_ar.h
+++ b/router/src/metadata_cache/src/cluster_metadata_ar.h
@@ -83,8 +83,7 @@ class METADATA_CACHE_EXPORT ARClusterMetadata : public ClusterMetadata {
       mysqlrouter::TargetCluster &target_cluster, const unsigned router_id,
       const metadata_cache::metadata_servers_list_t &metadata_servers,
       bool needs_writable_node, const std::string &cluster_type_specific_id,
-      const std::string & /*clusterset_id*/, bool /*whole_topology*/,
-      std::size_t &instance_id) override;
+      const std::string & /*clusterset_id*/, std::size_t &instance_id) override;
 
   /** @brief Returns cluster type this object is suppsed to handle
    */
@@ -93,7 +92,8 @@ class METADATA_CACHE_EXPORT ARClusterMetadata : public ClusterMetadata {
   }
 
   void setup_notifications_listener(
-      const metadata_cache::ClusterTopology & /*cluster_topology*/,
+      const std::vector<metadata_cache::ManagedInstance> & /*instances*/,
+      const mysqlrouter::TargetCluster & /*target_cluster*/,
       const GRNotificationListener::NotificationClb & /*callback*/) override {}
 
   /** @brief Deinitializes the notifications listener thread
@@ -101,18 +101,16 @@ class METADATA_CACHE_EXPORT ARClusterMetadata : public ClusterMetadata {
   void shutdown_notifications_listener() override {}
 
  private:
-  /** @brief Returns the current cluster topology according to the metadata of
+  /** @brief Returns vector of the cluster members according to the metadata of
    * the given metadata server.
    *
    * @param session active connection to the member that is checked for the
    * metadata
-   * @param view_id last known view_id of the cluster metadata
    * @param cluster_id ID of the cluster this operation refers to
    * @return vector of the cluster members
    */
-  metadata_cache::ClusterTopology fetch_topology_from_member(
-      mysqlrouter::MySQLSession &session, unsigned view_id,
-      const std::string &cluster_id = "");
+  std::vector<metadata_cache::ManagedInstance> fetch_instances_from_member(
+      mysqlrouter::MySQLSession &session, const std::string &cluster_id = "");
 
   /** @brief Returns metadata view id the given member holds
    *
diff --git a/router/src/metadata_cache/src/cluster_metadata_gr.cc b/router/src/metadata_cache/src/cluster_metadata_gr.cc
index 448e30d4787..8f8c6144fbb 100644
--- a/router/src/metadata_cache/src/cluster_metadata_gr.cc
+++ b/router/src/metadata_cache/src/cluster_metadata_gr.cc
@@ -75,7 +75,7 @@ class GRMetadataBackend {
   /** @brief Queries the metadata server for the list of instances that belong
    * to the desired cluster.
    */
-  virtual metadata_cache::ClusterTopology fetch_instances_from_metadata_server(
+  virtual metadata_cache::ManagedCluster fetch_instances_from_metadata_server(
       const mysqlrouter::TargetCluster &target_cluster,
       const std::string &group_name, const std::string &clusterset_id = "") = 0;
 
@@ -88,7 +88,7 @@ class GRMetadataBackend {
       mysqlrouter::TargetCluster &target_cluster, const unsigned router_id,
       const metadata_cache::metadata_server_t &metadata_server,
       bool needs_writable_node, const std::string &group_name,
-      const std::string &clusterset_id, bool whole_topology);
+      const std::string &clusterset_id);
 
   virtual void fetch_periodic_stats_update_frequency(
       const mysqlrouter::MetadataSchemaVersion & /*schema_version*/,
@@ -127,7 +127,7 @@ class GRMetadataBackendV1 : public GRMetadataBackend {
   /** @brief Queries the metadata server for the list of instances that belong
    * to the desired cluster.
    */
-  metadata_cache::ClusterTopology fetch_instances_from_metadata_server(
+  metadata_cache::ManagedCluster fetch_instances_from_metadata_server(
       const mysqlrouter::TargetCluster &target_cluster,
       const std::string &group_name,
       const std::string &clusterset_id = "") override;
@@ -146,7 +146,7 @@ class GRMetadataBackendV2 : public GRMetadataBackend {
   /** @brief Queries the metadata server for the list of instances that belong
    * to the desired cluster.
    */
-  metadata_cache::ClusterTopology fetch_instances_from_metadata_server(
+  metadata_cache::ManagedCluster fetch_instances_from_metadata_server(
       const mysqlrouter::TargetCluster &target_cluster,
       const std::string &group_name,
       const std::string &clusterset_id = "") override;
@@ -192,8 +192,6 @@ class GRClusterSetMetadataBackend : public GRMetadataBackendV2 {
    * single Cluster)
    * @param clusterset_id UUID of the ClusterSet the Cluster belongs to (if
    * bootstrapped as a ClusterSet)
-   * @param whole_topology return all usable nodes, ignore potential metadata
-   * filters or policies (like target_cluster etc.)
    * @return object containing cluster topology information in case of success,
    * or error code in case of failure
    * @throws metadata_cache::metadata_error
@@ -205,41 +203,14 @@ class GRClusterSetMetadataBackend : public GRMetadataBackendV2 {
       mysqlrouter::TargetCluster &target_cluster, const unsigned router_id,
       const metadata_cache::metadata_server_t &metadata_server,
       bool needs_writable_node, const std::string &group_name,
-      const std::string &clusterset_id = "",
-      bool whole_topology = false) override;
+      const std::string &clusterset_id = "") override;
 
   void reset() override { metadata_read_ = false; }
 
   std::vector<metadata_cache::metadata_servers_list_t> get_metadata_servers(
       const metadata_cache::metadata_servers_list_t &metadata_servers)
       override {
-    std::vector<metadata_cache::metadata_servers_list_t> result;
-
-    if (cluster_topology_) {
-      // We already know the latest ClusterSet topology so we return the
-      // servers grouped by the Cluster they belong to
-      for (const auto &cluster : (*cluster_topology_).clusters_data) {
-        metadata_cache::metadata_servers_list_t nodes;
-        for (const auto &node : cluster.members) {
-          nodes.push_back({node.host, node.port});
-        }
-        if (!nodes.empty()) {
-          result.push_back(nodes);
-        }
-      }
-    }
-
-    // if did not read the metadata yet we have the list from the state file
-    // we don't know which server belongs to which Cluster at this point so we
-    // have to assume the safest scenario: each is from different Cluster, we
-    // have to check metadata on each of them
-    if (result.empty()) {
-      for (const auto &server : metadata_servers) {
-        result.push_back({server});
-      }
-    }
-
-    return result;
+    return clusterset_topology_.get_metadata_servers(metadata_servers);
   }
 
   virtual std::optional<std::chrono::seconds>
@@ -260,18 +231,6 @@ class GRClusterSetMetadataBackend : public GRMetadataBackendV2 {
   uint64_t view_id_{0};
   bool metadata_read_{false};
 
-  /** @brief Returns vector of the cluster members according to the metadata of
-   * the selected server.
-   *
-   * @param session active connection to the member that is checked for the
-   * metadata
-   * @param cluster_id ID of the cluster this operation refers to
-   * @return vector of the cluster members
-   */
-  metadata_cache::cluster_nodes_list_t
-  fetch_target_cluster_instances_from_metadata_server(
-      mysqlrouter::MySQLSession &session, const std::string &cluster_id);
-
   // returns cluster_id
   std::string get_target_cluster_info_from_metadata_server(
       mysqlrouter::MySQLSession &session,
@@ -279,31 +238,84 @@ class GRClusterSetMetadataBackend : public GRMetadataBackendV2 {
       const std::string &clusterset_id);
 
   /** @brief Queries the metada for the current ClusterSet topology. Stores the
-   * topology in the class state. Returns the set of the metadata server for the
-   * ClusterSet.
+   * topology in the class state.
    *
    * @param session active connection to the member that is checked for the
    * metadata
    * @param clusterset_id ID of the ClusterSet this operation refers to
-   * @param view_id view id of the metadata
-   * @return set of the servers that contains metadata for the ClusterSet
    */
-  metadata_cache::ClusterTopology
-  update_clusterset_topology_from_metadata_server(
-      mysqlrouter::MySQLSession &session, const std::string &clusterset_id,
-      uint64_t view_id);
+  void update_clusterset_topology_from_metadata_server(
+      mysqlrouter::MySQLSession &session, const std::string &clusterset_id);
 
   /** @brief Finds the writable node within the currently known ClusterSet
    * topology.
    *
    * @return address of the current primary node if found
-   * @return std::nullopt if did not find any writable node
+   * @return metadata_cache::metadata_errc::no_rw_node_found if did not find any
    * primary
    */
-  std::optional<metadata_cache::metadata_server_t> find_rw_server();
+  stdx::expected<metadata_cache::metadata_server_t, std::error_code>
+  find_rw_server() const;
+
+  struct ClusterSetTopology {
+    // we at least once successfully read the metadata from one of the metadata
+    // servers we had stored in the state file; if true we have the
+    // clusters-nodes assignment, we know which cluster is the primary etc. so
+    // when refreshing the metadata we can only check one node per cluster for
+    // highiest view_id
+    bool is_set{false};
+
+    // the key is Cluster UUID
+    std::vector<metadata_cache::ManagedCluster> clusters_data;
+    // index of the target cluster in the clusters_data vector
+    std::optional<size_t> target_cluster_pos{};
+    metadata_cache::metadata_servers_list_t metadata_servers;
+
+    std::vector<metadata_cache::metadata_servers_list_t> get_metadata_servers(
+        const metadata_cache::metadata_servers_list_t &metadata_servers) const {
+      std::vector<metadata_cache::metadata_servers_list_t> result;
+
+      if (is_set) {
+        // We already know the latest ClusterSet topology so we return the
+        // servers grouped by the Cluster they belong to
+        for (const auto &cluster : clusters_data) {
+          metadata_cache::metadata_servers_list_t nodes;
+          for (const auto &node : cluster.members) {
+            nodes.push_back({node.host, node.port});
+          }
+          if (!nodes.empty()) {
+            result.push_back(nodes);
+          }
+        }
+      }
+
+      // if did not read the metadata yet we have the list from the state file
+      // we don't know which server belongs to which Cluster at this point so we
+      // have to assume the safest scenario: each is from different Cluster, we
+      // have to check metadata on each of them
+      if (result.empty()) {
+        for (const auto &server : metadata_servers) {
+          result.push_back({server});
+        }
+      }
+
+      return result;
+    }
+  };
+
+  /** @brief Returns index of the target cluster in the clusters vector in
+   * topology.
+   *
+   * @param topology object containing ClusterSet topology to search
+   * @param target_cluster_id UUID fo the target_cluster to find
+   * @return index in the clusters array or std::nullopt if not found
+   */
+  static std::optional<size_t> target_cluster_pos(
+      const ClusterSetTopology &topology, const std::string &target_cluster_id);
+
+  ClusterSetTopology clusterset_topology_;
 
   std::string router_cs_options_string{""};
-  std::optional<metadata_cache::ClusterTopology> cluster_topology_{};
 };
 
 namespace {
@@ -535,10 +547,11 @@ GRClusterMetadata::GRClusterMetadata(
 }
 
 void GRClusterMetadata::update_cluster_status(
+    const mysqlrouter::TargetCluster &target_cluster,
     metadata_cache::ManagedCluster
         &cluster) {  // throws metadata_cache::metadata_error
 
-  log_debug("Updating cluster status from GR for '%s'", cluster.name.c_str());
+  log_debug("Updating cluster status from GR for '%s'", target_cluster.c_str());
 
   // iterate over all candidate nodes until we find the node that is part of
   // quorum
@@ -579,12 +592,12 @@ void GRClusterMetadata::update_cluster_status(
             log_level,
             "While updating metadata, could not establish a connection to "
             "cluster '%s' through %s",
-            cluster.name.c_str(), mi_addr.c_str());
+            target_cluster.c_str(), mi_addr.c_str());
         continue;  // server down, next!
       }
     }
 
-    log_debug("Connected to cluster '%s' through %s", cluster.name.c_str(),
+    log_debug("Connected to cluster '%s' through %s", target_cluster.c_str(),
               mi_addr.c_str());
 
     try {
@@ -596,7 +609,7 @@ void GRClusterMetadata::update_cluster_status(
               *gr_member_connection,
               single_primary_mode);  // throws metadata_cache::metadata_error
       log_debug("Cluster '%s' has %zu members in metadata, %zu in status table",
-                cluster.name.c_str(), cluster.members.size(),
+                target_cluster.c_str(), cluster.members.size(),
                 member_status.size());
 
       // check status of all nodes; updates instances
@@ -621,12 +634,12 @@ void GRClusterMetadata::update_cluster_status(
                                                       // (cornercase)
           log_warning(
               "quorum for cluster '%s' consists only of recovering nodes!",
-              cluster.name.c_str());
-          found_quorum = true;  // no point in futher search
+              target_cluster.c_str());
+          found_quorum = true;  // no point in further search
           break;
         case GRClusterStatus::Unavailable:  // we have nothing
           log_warning("%s is not part of quorum for cluster '%s'",
-                      mi_addr.c_str(), cluster.name.c_str());
+                      mi_addr.c_str(), target_cluster.c_str());
           continue;  // this server is no good, next!
       }
 
@@ -640,24 +653,24 @@ void GRClusterMetadata::update_cluster_status(
       log_warning(
           "Unable to fetch live group_replication member data from %s from "
           "cluster '%s': %s",
-          mi_addr.c_str(), cluster.name.c_str(), e.what());
+          mi_addr.c_str(), target_cluster.c_str(), e.what());
       continue;  // faulty server, next!
     } catch (const std::exception &e) {
       log_warning(
           "Unable to fetch live group_replication member data from %s from "
           "cluster '%s': %s",
-          mi_addr.c_str(), cluster.name.c_str(), e.what());
+          mi_addr.c_str(), target_cluster.c_str(), e.what());
       continue;  // faulty server, next!
     }
 
   }  // for (const metadata_cache::ManagedInstance& mi : instances)
-  log_debug("End updating cluster for '%s'", cluster.name.c_str());
+  log_debug("End updating cluster for '%s'", target_cluster.c_str());
 
   if (!found_quorum) {
     std::string msg(
         "Unable to fetch live group_replication member data from any server in "
         "cluster '");
-    msg += cluster.name + "'";
+    msg += target_cluster.to_string() + "'";
     log_error("%s", msg.c_str());
 
     // if we don't have a quorum, we want to give "nothing" to the Routing
@@ -688,7 +701,6 @@ GRClusterStatus GRClusterMetadata::check_cluster_status(
   // is negligible while keeping code simple.
 
   using metadata_cache::ServerMode;
-  using metadata_cache::ServerRole;
   using GR_State = GroupReplicationMember::State;
   using GR_Role = GroupReplicationMember::Role;
 
@@ -756,13 +768,11 @@ GRClusterStatus GRClusterMetadata::check_cluster_status(
           switch (status->second.role) {
             case GR_Role::Primary:
               have_primary_instance = true;
-              member.role = ServerRole::Primary;
               member.mode = ServerMode::ReadWrite;
               quorum_count++;
               break;
             case GR_Role::Secondary:
               have_secondary_instance = true;
-              member.role = ServerRole::Secondary;
               member.mode = ServerMode::ReadOnly;
               quorum_count++;
               break;
@@ -777,12 +787,10 @@ GRClusterStatus GRClusterMetadata::check_cluster_status(
           // generates a warning for that and there is no sane and portable way
           // to suppress it.
           if (GR_State::Recovering == status->second.state) quorum_count++;
-          member.role = ServerRole::Unavailable;
           member.mode = ServerMode::Unavailable;
           break;
       }
     } else {
-      member.role = ServerRole::Unavailable;
       member.mode = ServerMode::Unavailable;
       metadata_gr_discrepancy = true;
       const auto log_level =
@@ -865,7 +873,7 @@ GRClusterMetadata::auth_credentials_t GRClusterMetadata::fetch_auth_credentials(
   }
 }
 
-metadata_cache::ClusterTopology
+metadata_cache::ManagedCluster
 GRClusterMetadata::fetch_instances_from_metadata_server(
     const mysqlrouter::TargetCluster &target_cluster,
     const std::string &cluster_type_specific_id) {
@@ -917,13 +925,13 @@ GRMetadataBackend::fetch_cluster_topology(
     mysqlrouter::TargetCluster &target_cluster, const unsigned router_id,
     const metadata_cache::metadata_server_t & /*metadata_server*/,
     bool needs_writable_node, const std::string &group_name,
-    const std::string &clusterset_id = "", bool /*whole_topology*/ = false) {
+    const std::string &clusterset_id = "") {
   metadata_cache::ClusterTopology result;
 
   // fetch cluster topology from the metadata server (this is
   // the topology that was configured, it will be compared later against
   // current topology reported by (a server in) Group Replication)
-  result = fetch_instances_from_metadata_server(
+  result.cluster_data = fetch_instances_from_metadata_server(
       target_cluster, group_name,
       clusterset_id);  // throws metadata_cache::metadata_error
 
@@ -932,18 +940,25 @@ GRMetadataBackend::fetch_cluster_topology(
   // we are done with querying metadata
   transaction.commit();
 
-  auto &cluster = result.clusters_data[0];
-
   // now connect to the cluster and query it for the list and status of its
   // members. (more precisely: search and connect to a
   // member which is part of quorum to retrieve this data)
   metadata_->update_cluster_status(
-      cluster);  // throws metadata_cache::metadata_error
+      target_cluster,
+      result.cluster_data);  // throws metadata_cache::metadata_error
+
+  // for Cluster that is not part of the ClusterSet we assume metadata
+  // servers are just Cluster nodes
+  for (const auto &cluster_node : result.cluster_data.members) {
+    result.metadata_servers.push_back({cluster_node.host, cluster_node.port});
+  }
 
   if (needs_writable_node) {
-    result.writable_server = metadata_->find_rw_server(cluster.members);
+    result.cluster_data.writable_server =
+        metadata_->find_rw_server(result.cluster_data.members);
   } else {
-    result.writable_server = std::nullopt;
+    result.cluster_data.writable_server = stdx::make_unexpected(
+        make_error_code(metadata_cache::metadata_errc::no_rw_node_needed));
   }
 
   return result;
@@ -955,8 +970,7 @@ GRClusterMetadata::fetch_cluster_topology(
     mysqlrouter::TargetCluster &target_cluster, const unsigned router_id,
     const metadata_cache::metadata_servers_list_t &metadata_servers,
     bool needs_writable_node, const std::string &group_name,
-    const std::string &clusterset_id, bool whole_topology,
-    std::size_t &instance_id) {
+    const std::string &clusterset_id, std::size_t &instance_id) {
   log_debug("Updating metadata information for cluster '%s'",
             target_cluster.c_str());
   stdx::expected<metadata_cache::ClusterTopology, std::error_code> result{
@@ -1014,7 +1028,7 @@ GRClusterMetadata::fetch_cluster_topology(
 
         result_tmp = metadata_backend_->fetch_cluster_topology(
             transaction, version, target_cluster, router_id, metadata_server,
-            needs_writable_node, group_name, clusterset_id, whole_topology);
+            needs_writable_node, group_name, clusterset_id);
 
         last_fetch_cluster_id = i;
       } catch (const mysqlrouter::MetadataUpgradeInProgressException &) {
@@ -1053,7 +1067,7 @@ GRClusterMetadata::fetch_cluster_topology(
 }
 
 // throws metadata_cache::metadata_error
-metadata_cache::ClusterTopology
+metadata_cache::ManagedCluster
 GRMetadataBackendV1::fetch_instances_from_metadata_server(
     const mysqlrouter::TargetCluster &target_cluster,
     const std::string &group_name, const std::string & /*clusterset_id*/) {
@@ -1087,7 +1101,6 @@ GRMetadataBackendV1::fetch_instances_from_metadata_server(
   // replicaset are two orthogonal ideas.
   std::string query(
       "SELECT "
-      "F.cluster_id, F.cluster_name, "
       "R.replicaset_name, "
       "I.mysql_server_uuid, "
       "I.addresses->>'$.mysqlClassic', "
@@ -1101,27 +1114,37 @@ GRMetadataBackendV1::fetch_instances_from_metadata_server(
       "WHERE " +
       limit_cluster + limit_group_replication);
 
-  metadata_cache::ManagedCluster cluster;
-  auto result_processor = [&cluster](const MySQLSession::Row &row) -> bool {
-    if (row.size() != 6) {
+  // example response
+  // clang-format off
+  // +-----------------+--------------------------------------+--------------------------------+--------------------------+
+  // | replicaset_name | mysql_server_uuid                    | I.addresses->>'$.mysqlClassic' | I.addresses->>'$.mysqlX' |
+  // +-----------------+--------------------------------------+--------------------------------+--------------------------+
+  // | default         | 30ec658e-861d-11e6-9988-08002741aeb6 | localhost:3310                 | NULL                     |
+  // | default         | 3acfe4ca-861d-11e6-9e56-08002741aeb6 | localhost:3320                 | NULL                     |
+  // | default         | 4c08b4a2-861d-11e6-a256-08002741aeb6 | localhost:3330                 | NULL                     |
+  // +-----------------+--------------------------------------+--------------------------------+--------------------------+
+  // clang-format on
+  //
+
+  metadata_cache::ManagedCluster result;
+  auto result_processor = [&result](const MySQLSession::Row &row) -> bool {
+    if (row.size() != 4) {
       throw metadata_cache::metadata_error(
           "Unexpected number of fields in the resultset. "
-          "Expected = 6, got = " +
+          "Expected = 4, got = " +
           std::to_string(row.size()));
     }
 
     metadata_cache::ManagedInstance s{
         metadata_cache::InstanceType::GroupMember};
-    s.mysql_server_uuid = get_string(row[3]);
-    if (!set_instance_ports(s, row, 4, 5)) {
+    s.mysql_server_uuid = get_string(row[1]);
+    if (!set_instance_ports(s, row, 2, 3)) {
       return true;  // next row
     }
 
-    cluster.members.push_back(s);
-    cluster.single_primary_mode =
+    result.members.push_back(s);
+    result.single_primary_mode =
         true;  // actual value set elsewhere from GR metadata
-    cluster.id = get_string(row[0]);
-    cluster.name = get_string(row[1]);
 
     return true;  // false = I don't want more rows
   };
@@ -1134,16 +1157,6 @@ GRMetadataBackendV1::fetch_instances_from_metadata_server(
     throw metadata_cache::metadata_error(e.what());
   }
 
-  metadata_cache::ClusterTopology result;
-  result.clusters_data.push_back(cluster);
-  result.target_cluster_pos = 0;
-
-  // for Cluster that is not part of the ClusterSet we assume metadata
-  // servers are just Cluster nodes
-  for (const auto &cluster_node : cluster.members) {
-    result.metadata_servers.emplace_back(cluster_node.host, cluster_node.port);
-  }
-
   return result;
 }
 
@@ -1160,7 +1173,7 @@ std::string GRMetadataBackendV2::get_cluster_type_specific_id_limit_sql(
 }
 
 // throws metadata_cache::metadata_error
-metadata_cache::ClusterTopology
+metadata_cache::ManagedCluster
 GRMetadataBackendV2::fetch_instances_from_metadata_server(
     const mysqlrouter::TargetCluster &target_cluster,
     const std::string &group_name, const std::string &clusterset_id) {
@@ -1185,35 +1198,43 @@ GRMetadataBackendV2::fetch_instances_from_metadata_server(
   // server is not part of GR, as serving metadata and being part of
   // replicaset are two orthogonal ideas.
   std::string query(
-      "select C.cluster_id, C.cluster_name, I.mysql_server_uuid, I.endpoint, "
-      "I.xendpoint, I.attributes "
+      "select I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes "
       "from "
       "mysql_innodb_cluster_metadata.v2_instances I join "
       "mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = "
       "C.cluster_id where " +
       limit_cluster + limit_group_replication);
 
-  metadata_cache::ManagedCluster cluster;
-  auto result_processor = [&cluster](const MySQLSession::Row &row) -> bool {
-    if (row.size() != 6) {
+  // example response
+  // clang-format off
+  //  +--------------------------------------+----------------+-----------------+--------------------------------------------------------------------+
+  //  | mysql_server_uuid                    | endpoint       | xendpoint       | attributes                                                         |
+  //  +--------------------------------------+----------------+-----------------+--------------------------------------------------------------------+
+  //  | 201eabcf-adfa-11e9-8205-0800276c00e7 | 127.0.0.1:5000 | 127.0.0.1:50000 | {"tags": {"_hidden": true}, "joinTime": "2020-03-18 09:36:50.416"} |
+  //  | 351ea0ec-adfa-11e9-b348-0800276c00e7 | 127.0.0.1:5001 | 127.0.0.1:50010 | {"joinTime": "2020-03-18 09:36:51.000"}                            |
+  //  | 559bd763-adfa-11e9-b2c3-0800276c00e7 | 127.0.0.1:5002 | 127.0.0.1:50020 | {"joinTime": "2020-03-18 09:36:53.456"}                            |
+  //  +--------------------------------------+----------------+-----------------+--------------------------------------------------------------------+
+  // clang-format on
+  //
+  metadata_cache::ManagedCluster result;
+  auto result_processor = [&result](const MySQLSession::Row &row) -> bool {
+    if (row.size() != 4) {
       throw metadata_cache::metadata_error(
           "Unexpected number of fields in the resultset. "
-          "Expected = 6, got = " +
+          "Expected = 4, got = " +
           std::to_string(row.size()));
     }
 
     metadata_cache::ManagedInstance instance{
         metadata_cache::InstanceType::GroupMember};
-    instance.mysql_server_uuid = get_string(row[2]);
-    if (!set_instance_ports(instance, row, 3, 4)) {
+    instance.mysql_server_uuid = get_string(row[0]);
+    if (!set_instance_ports(instance, row, 1, 2)) {
       return true;  // next row
     }
-    set_instance_attributes(instance, get_string(row[5]));
+    set_instance_attributes(instance, get_string(row[3]));
 
-    cluster.id = get_string(row[0]);
-    cluster.name = get_string(row[1]);
-    cluster.members.push_back(instance);
-    cluster.single_primary_mode =
+    result.members.push_back(instance);
+    result.single_primary_mode =
         true;  // actual value set elsewhere from GR metadata
 
     return true;  // false = I don't want more rows
@@ -1225,16 +1246,6 @@ GRMetadataBackendV2::fetch_instances_from_metadata_server(
     throw metadata_cache::metadata_error(e.what());
   }
 
-  metadata_cache::ClusterTopology result;
-  result.clusters_data.push_back(cluster);
-  result.target_cluster_pos = 0;
-
-  // for Cluster that is not part of the ClusterSet we assume metadata
-  // servers are just Cluster nodes
-  for (const auto &cluster_node : cluster.members) {
-    result.metadata_servers.emplace_back(cluster_node.host, cluster_node.port);
-  }
-
   return result;
 }
 
@@ -1384,17 +1395,14 @@ GRClusterSetMetadataBackend::get_target_cluster_info_from_metadata_server(
   return result;
 }
 
-metadata_cache::ClusterTopology
-GRClusterSetMetadataBackend::update_clusterset_topology_from_metadata_server(
-    mysqlrouter::MySQLSession &session, const std::string &clusterset_id,
-    uint64_t view_id) {
-  metadata_cache::ClusterTopology result;
-  result.view_id = view_id;
+void GRClusterSetMetadataBackend::
+    update_clusterset_topology_from_metadata_server(
+        mysqlrouter::MySQLSession &session, const std::string &clusterset_id) {
+  ClusterSetTopology result;
 
   std::string query =
       "select I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes, "
-      "C.cluster_id, C.cluster_name, CSM.member_role, CSM.invalidated, "
-      "CS.domain_name "
+      "C.cluster_id, C.cluster_name, CSM.member_role, CSM.invalidated "
       "from mysql_innodb_cluster_metadata.v2_instances I join "
       "mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = "
       "C.cluster_id join mysql_innodb_cluster_metadata.v2_cs_members CSM on "
@@ -1434,8 +1442,7 @@ GRClusterSetMetadataBackend::update_clusterset_topology_from_metadata_server(
           mysqlrouter::URI uri_x("mysql://" + node_addr_x);
           result.clusters_data.back().members.emplace_back(
               metadata_cache::InstanceType::GroupMember, node_uuid,
-              metadata_cache::ServerMode::ReadOnly,
-              metadata_cache::ServerRole::Secondary, uri_classic.host,
+              metadata_cache::ServerMode::ReadOnly, uri_classic.host,
               uri_classic.port, uri_x.port);
 
           set_instance_attributes(result.clusters_data.back().members.back(),
@@ -1443,17 +1450,14 @@ GRClusterSetMetadataBackend::update_clusterset_topology_from_metadata_server(
 
           result.metadata_servers.emplace_back(uri_classic.host,
                                                uri_classic.port);
-          if (result.name.empty()) {
-            result.name = get_string(row[8]);
-          }
           return true;
         });
   } catch (const MySQLSession::Error &e) {
     throw std::runtime_error(std::string("Error querying metadata: ") +
                              e.what());
   }
-
-  return result;
+  result.is_set = true;
+  clusterset_topology_ = std::move(result);
 }
 
 static void log_target_cluster_warnings(
@@ -1486,6 +1490,33 @@ static void log_target_cluster_warnings(
   }
 }
 
+stdx::expected<metadata_cache::metadata_server_t, std::error_code>
+GRClusterSetMetadataBackend::find_rw_server() const {
+  for (const auto &cluster : clusterset_topology_.clusters_data) {
+    if (!cluster.is_primary) continue;
+
+    const auto cluster_uuid = cluster.id;
+    metadata_cache::ManagedCluster primary_cluster;
+    for (const auto &node : cluster.members) {
+      primary_cluster.members.emplace_back(node);
+    }
+
+    log_debug("Updating the status of cluster '%s' to find the writable node",
+              cluster_uuid.c_str());
+
+    // we need to connect to the Primary Cluster and query its GR status to
+    // figure out the current Primary node
+    metadata_->update_cluster_status(
+        {mysqlrouter::TargetCluster::TargetType::ByUUID, cluster_uuid},
+        primary_cluster);
+
+    return metadata_->find_rw_server(primary_cluster.members);
+  }
+
+  return stdx::make_unexpected(
+      make_error_code(metadata_cache::metadata_errc::no_rw_node_needed));
+}
+
 static bool is_cluster_usable(
     const metadata_cache::ManagedCluster &cluster,
     const mysqlrouter::TargetCluster::InvalidatedClusterRoutingPolicy
@@ -1495,8 +1526,8 @@ static bool is_cluster_usable(
           mysqlrouter::TargetCluster::InvalidatedClusterRoutingPolicy::DropAll);
 }
 
-static std::optional<size_t> target_cluster_pos(
-    const metadata_cache::ClusterTopology &topology,
+std::optional<size_t> GRClusterSetMetadataBackend::target_cluster_pos(
+    const GRClusterSetMetadataBackend::ClusterSetTopology &topology,
     const std::string &target_cluster_id) {
   size_t i{};
   for (const auto &cluster : topology.clusters_data) {
@@ -1509,24 +1540,6 @@ static std::optional<size_t> target_cluster_pos(
   return std::nullopt;
 }
 
-std::optional<metadata_cache::metadata_server_t>
-GRClusterSetMetadataBackend::find_rw_server() {
-  for (auto &cluster : (*cluster_topology_).clusters_data) {
-    if (!cluster.is_primary) continue;
-
-    log_debug("Updating the status of cluster '%s' to find the writable node",
-              cluster.name.c_str());
-
-    // we need to connect to the Primary Cluster and query its GR status to
-    // figure out the current Primary node
-    metadata_->update_cluster_status(cluster);
-
-    return metadata_->find_rw_server(cluster.members);
-  }
-
-  return std::nullopt;
-}
-
 stdx::expected<metadata_cache::ClusterTopology, std::error_code>
 GRClusterSetMetadataBackend::fetch_cluster_topology(
     MySQLSession::Transaction &transaction,
@@ -1534,7 +1547,7 @@ GRClusterSetMetadataBackend::fetch_cluster_topology(
     mysqlrouter::TargetCluster &target_cluster, const unsigned router_id,
     const metadata_cache::metadata_server_t &metadata_server,
     bool needs_writable_node, const std::string &group_name,
-    const std::string &clusterset_id, bool whole_topology) {
+    const std::string &clusterset_id) {
   metadata_cache::ClusterTopology result;
   auto connection = metadata_->get_connection();
 
@@ -1632,74 +1645,73 @@ GRClusterSetMetadataBackend::fetch_cluster_topology(
   }
 
   // update the clusterset topology
-  result = update_clusterset_topology_from_metadata_server(*connection, cs_id,
-                                                           view_id);
+  update_clusterset_topology_from_metadata_server(*connection, cs_id);
 
-  // we are done with querying metadata
+  // we are done with querying metadata, this transaction commit has to be
+  // done unconditionally, regardless of the target cluster usability
   transaction.commit();
 
-  this->cluster_topology_ = result;
+  const auto target_cluster_idx =
+      target_cluster_pos(clusterset_topology_, target_cluster_id);
 
-  result.target_cluster_pos = target_cluster_pos(result, target_cluster_id);
+  if (target_cluster_idx)
+    result.cluster_data =
+        clusterset_topology_.clusters_data[*target_cluster_idx];
+  else
+    result.cluster_data.name = target_cluster.to_string();
 
-  // if we are supposed to only work with single target_cluster clean
-  // all other clusters from the result
-  if (!whole_topology) {
-    if (result.target_cluster_pos)
-      result.clusters_data = {result.clusters_data[*result.target_cluster_pos]};
-    else
-      result.clusters_data.clear();
-  }
+  log_target_cluster_warnings(
+      result.cluster_data, target_cluster.invalidated_cluster_routing_policy());
 
-  for (auto &cluster : result.clusters_data) {
-    if (!whole_topology) {
-      log_target_cluster_warnings(
-          cluster, target_cluster.invalidated_cluster_routing_policy());
-      if (!is_cluster_usable(
-              cluster, target_cluster.invalidated_cluster_routing_policy())) {
-        cluster.members.clear();
-        continue;
-      }
-    }
+  result.view_id = view_id;
+  result.cluster_data.single_primary_mode = true;
+  result.metadata_servers = clusterset_topology_.metadata_servers;
 
+  if (!is_cluster_usable(result.cluster_data,
+                         target_cluster.invalidated_cluster_routing_policy())) {
+    result.cluster_data.members.clear();
+  } else {
     // connect to the cluster and query for the list and status of its
     // members. (more precisely: search and connect to a
     // member which is part of quorum to retrieve this data)
     metadata_->update_cluster_status(
-        cluster);  // throws metadata_cache::metadata_error
+        target_cluster,
+        result.cluster_data);  // throws metadata_cache::metadata_error
 
     // change the mode of RW node(s) reported by the GR to RO if the
-    // Cluster is Replica (and 'use_replica_primary_as_rw' option is not set)
-    // or if our target cluster is invalidated
-    if (!whole_topology) {
-      if ((!cluster.is_primary &&
-           !router_clusterset_options.get_use_replica_primary_as_rw()) ||
-          cluster.is_invalidated) {
-        for (auto &member : cluster.members) {
-          if (member.mode == metadata_cache::ServerMode::ReadWrite) {
-            member.mode = metadata_cache::ServerMode::ReadOnly;
-          }
+    // Cluster is Replica (and 'use_replica_primary_as_rw' option is not set) or
+    // if our target cluster is invalidated
+    if ((!result.cluster_data.is_primary &&
+         !router_clusterset_options.get_use_replica_primary_as_rw()) ||
+        result.cluster_data.is_invalidated) {
+      for (auto &member : result.cluster_data.members) {
+        if (member.mode == metadata_cache::ServerMode::ReadWrite) {
+          member.mode = metadata_cache::ServerMode::ReadOnly;
         }
       }
     }
   }
 
   if (needs_writable_node) {
-    result.writable_server =
-        metadata_->find_rw_server((*this->cluster_topology_).clusters_data);
-    if (!result.writable_server) {
-      result.writable_server = find_rw_server();
+    if (result.cluster_data.is_primary) {
+      // if our target cluster is PRIMARY we grab the writable node; we
+      // already know which one is it as we just checked it
+      result.cluster_data.writable_server =
+          metadata_->find_rw_server(result.cluster_data.members);
+    } else {
+      result.cluster_data.writable_server = find_rw_server();
     }
 
     log_debug("Writable server is: %s",
-              result.writable_server
-                  ? result.writable_server.value().str().c_str()
+              result.cluster_data.writable_server
+                  ? result.cluster_data.writable_server.value().str().c_str()
                   : "(not found)");
   } else {
-    result.writable_server = std::nullopt;
+    result.cluster_data.writable_server = stdx::make_unexpected(
+        make_error_code(metadata_cache::metadata_errc::no_rw_node_needed));
   }
 
   this->view_id_ = view_id;
   this->metadata_read_ = true;
   return result;
-}
\ No newline at end of file
+}
diff --git a/router/src/metadata_cache/src/cluster_metadata_gr.h b/router/src/metadata_cache/src/cluster_metadata_gr.h
index 6156fe9198f..7da26b6db05 100644
--- a/router/src/metadata_cache/src/cluster_metadata_gr.h
+++ b/router/src/metadata_cache/src/cluster_metadata_gr.h
@@ -80,8 +80,6 @@ class METADATA_CACHE_EXPORT GRClusterMetadata : public ClusterMetadata {
    * single Cluster)
    * @param clusterset_id UUID of the ClusterSet the Cluster belongs to (if
    * bootstrapped as a ClusterSet)
-   * @param whole_topology return all usable nodes, ignore potential metadata
-   * filters or policies (like target_cluster etc.)
    * @param [out] instance_id of the server the metadata was fetched from
    * @return object containing cluster topology information in case of success,
    * or error code in case of failure
@@ -93,22 +91,23 @@ class METADATA_CACHE_EXPORT GRClusterMetadata : public ClusterMetadata {
       mysqlrouter::TargetCluster &target_cluster, const unsigned router_id,
       const metadata_cache::metadata_servers_list_t &metadata_servers,
       bool needs_writable_node, const std::string &group_name,
-      const std::string &clusterset_id, bool whole_topology,
-      std::size_t &instance_id) override;
+      const std::string &clusterset_id, std::size_t &instance_id) override;
 
   /** @brief Initializes the notifications listener thread (if a given cluster
    * type supports it)
    *
-   * @param cluster_topology current topology of the monitored Cluster(s)
+   * @param instances vector of the current cluster nodes
+   * @param target_cluster object identifying the Cluster this operation refers
    * to
    * @param callback  callback function to get called when the GR notification
    *                  was received
    */
   void setup_notifications_listener(
-      const metadata_cache::ClusterTopology &cluster_topology,
+      const std::vector<metadata_cache::ManagedInstance> &instances,
+      const mysqlrouter::TargetCluster &target_cluster,
       const GRNotificationListener::NotificationClb &callback) override {
     if (gr_notifications_listener_)
-      gr_notifications_listener_->setup(cluster_topology, callback);
+      gr_notifications_listener_->setup(instances, target_cluster, callback);
   }
 
   /** @brief Deinitializes the notifications listener thread
@@ -146,7 +145,7 @@ class METADATA_CACHE_EXPORT GRClusterMetadata : public ClusterMetadata {
   /** @brief Queries the metadata server for the list of instances that belong
    * to the desired cluster.
    */
-  metadata_cache::ClusterTopology fetch_instances_from_metadata_server(
+  metadata_cache::ManagedCluster fetch_instances_from_metadata_server(
       const mysqlrouter::TargetCluster &target_cluster,
       const std::string &cluster_type_specific_id);
 
@@ -161,7 +160,8 @@ class METADATA_CACHE_EXPORT GRClusterMetadata : public ClusterMetadata {
    *
    * The information is pulled from GR maintained performance_schema tables.
    */
-  void update_cluster_status(metadata_cache::ManagedCluster &cluster);
+  void update_cluster_status(const mysqlrouter::TargetCluster &target_cluster,
+                             metadata_cache::ManagedCluster &cluster);
 
   GRClusterStatus check_cluster_status(
       std::vector<metadata_cache::ManagedInstance> &instances,
diff --git a/router/src/metadata_cache/src/gr_notifications_listener.cc b/router/src/metadata_cache/src/gr_notifications_listener.cc
index 04dc66aaab3..f69d4032985 100644
--- a/router/src/metadata_cache/src/gr_notifications_listener.cc
+++ b/router/src/metadata_cache/src/gr_notifications_listener.cc
@@ -109,16 +109,19 @@ struct GRNotificationListener::Impl {
   void listener_thread_func();
   bool read_from_session(const NodeId &node_id, NodeSession &session);
 
-  xcl::XError enable_notices(xcl::XSession &session, const NodeId &node_id,
-                             const std::string &cluster_name) noexcept;
+  xcl::XError enable_notices(
+      xcl::XSession &session, const NodeId &node_id,
+      const mysqlrouter::TargetCluster &target_cluster) noexcept;
   void set_mysqlx_wait_timeout(xcl::XSession &session,
                                const NodeId &node_id) noexcept;
   void check_mysqlx_wait_timeout();
   xcl::XError ping(xcl::XSession &session) noexcept;
   void remove_node_session(const NodeId &node) noexcept;
 
-  void reconfigure(const metadata_cache::ClusterTopology &cluster_topology,
-                   const NotificationClb &notification_clb);
+  void reconfigure(
+      const std::vector<metadata_cache::ManagedInstance> &instances,
+      const mysqlrouter::TargetCluster &target_cluster,
+      const NotificationClb &notification_clb);
 
   // handles the notice from the session
   xcl::Handler_result notice_handler(const xcl::XProtocol *,
@@ -402,9 +405,9 @@ GRNotificationListener::Impl::~Impl() {
  */
 xcl::XError GRNotificationListener::Impl::enable_notices(
     xcl::XSession &session, const NodeId &node_id,
-    const std::string &cluster_name) noexcept {
+    const mysqlrouter::TargetCluster &target_cluster) noexcept {
   log_info("Enabling GR notices for cluster '%s' changes on node %s:%u",
-           cluster_name.c_str(), node_id.host.c_str(), node_id.port);
+           target_cluster.c_str(), node_id.host.c_str(), node_id.port);
   xcl::XError err;
 
   xcl::Argument_value::Object arg_obj;
@@ -475,21 +478,21 @@ xcl::XError GRNotificationListener::Impl::ping(
 }
 
 void GRNotificationListener::Impl::reconfigure(
-    const metadata_cache::ClusterTopology &cluster_topology,
+    const std::vector<metadata_cache::ManagedInstance> &instances,
+    const mysqlrouter::TargetCluster &target_cluster,
     const NotificationClb &notification_clb) {
   std::lock_guard<std::mutex> lock(configuration_data_mtx_);
 
   notification_callback = notification_clb;
 
-  const auto all_nodes = cluster_topology.get_all_members();
   // if there are connections to the nodes that are no longer required, remove
   // them first
   for (auto it = sessions_.cbegin(); it != sessions_.cend();) {
-    if (std::find_if(all_nodes.begin(), all_nodes.end(),
+    if (std::find_if(instances.begin(), instances.end(),
                      [&it](const metadata_cache::ManagedInstance &i) {
                        return it->first.host == i.host &&
                               it->first.port == i.xport;
-                     }) == all_nodes.end()) {
+                     }) == instances.end()) {
       log_info("Removing unused GR notification session to '%s:%d'",
                it->first.host.c_str(), it->first.port);
       sessions_.erase(it++);
@@ -500,36 +503,33 @@ void GRNotificationListener::Impl::reconfigure(
   }
 
   // check if there are some new nodes that we should connect to
-  for (const auto &cluster : cluster_topology.clusters_data) {
-    for (const auto &instance : cluster.members) {
+  for (const auto &instance : instances) {
+    NodeId node_id{instance.host, instance.xport, NodeId::kInvalidSocket};
+    if (std::find_if(
+            sessions_.begin(), sessions_.end(),
+            [&node_id](const std::pair<const NodeId, NodeSession> &node) {
+              return node.first.host == node_id.host &&
+                     node.first.port == node_id.port;
+            }) == sessions_.end()) {
       NodeId node_id{instance.host, instance.xport, NodeId::kInvalidSocket};
-      if (std::find_if(
-              sessions_.begin(), sessions_.end(),
-              [&node_id](const std::pair<const NodeId, NodeSession> &node) {
-                return node.first.host == node_id.host &&
-                       node.first.port == node_id.port;
-              }) == sessions_.end()) {
-        NodeId node_id{instance.host, instance.xport, NodeId::kInvalidSocket};
-        NodeSession session;
-        // If we could not connect it's not fatal, we only log it and live with
-        // the node not being monitored for GR notifications.
-        if (connect(session, node_id)) continue;
-
-        set_mysqlx_wait_timeout(*session, node_id);
-
-        if (enable_notices(*session, node_id, cluster.name)) continue;
-
-        session->get_protocol().add_notice_handler(
-            [this](const xcl::XProtocol *protocol, const bool is_global,
-                   const Mysqlx::Notice::Frame::Type type, const char *data,
-                   const uint32_t data_length) -> xcl::Handler_result {
-              return notice_handler(protocol, is_global, type, data,
-                                    data_length);
-            });
+      NodeSession session;
+      // If we could not connect it's not fatal, we only log it and live with
+      // the node not being monitored for GR notifications.
+      if (connect(session, node_id)) continue;
 
-        sessions_[node_id] = std::move(session);
-        sessions_changed_ = true;
-      }
+      set_mysqlx_wait_timeout(*session, node_id);
+
+      if (enable_notices(*session, node_id, target_cluster)) continue;
+
+      session->get_protocol().add_notice_handler(
+          [this](const xcl::XProtocol *protocol, const bool is_global,
+                 const Mysqlx::Notice::Frame::Type type, const char *data,
+                 const uint32_t data_length) -> xcl::Handler_result {
+            return notice_handler(protocol, is_global, type, data, data_length);
+          });
+
+      sessions_[node_id] = std::move(session);
+      sessions_changed_ = true;
     }
   }
 
@@ -545,7 +545,8 @@ GRNotificationListener::GRNotificationListener(
 GRNotificationListener::~GRNotificationListener() = default;
 
 void GRNotificationListener::setup(
-    const metadata_cache::ClusterTopology &cluster_topology,
+    const std::vector<metadata_cache::ManagedInstance> &instances,
+    const mysqlrouter::TargetCluster &target_cluster,
     const NotificationClb &notification_clb) {
-  impl_->reconfigure(cluster_topology, notification_clb);
+  impl_->reconfigure(instances, target_cluster, notification_clb);
 }
diff --git a/router/src/metadata_cache/src/gr_notifications_listener.h b/router/src/metadata_cache/src/gr_notifications_listener.h
index d9d51288d33..1766e406695 100644
--- a/router/src/metadata_cache/src/gr_notifications_listener.h
+++ b/router/src/metadata_cache/src/gr_notifications_listener.h
@@ -41,7 +41,8 @@ class GRNotificationListener {
 
   using NotificationClb = std::function<void()>;
 
-  void setup(const metadata_cache::ClusterTopology &cluster_topology,
+  void setup(const std::vector<metadata_cache::ManagedInstance> &instances,
+             const mysqlrouter::TargetCluster &target_cluster,
              const NotificationClb &notification_clb);
 
  private:
diff --git a/router/src/metadata_cache/src/metadata_cache.cc b/router/src/metadata_cache/src/metadata_cache.cc
index 430036fd657..320ac881ceb 100644
--- a/router/src/metadata_cache/src/metadata_cache.cc
+++ b/router/src/metadata_cache/src/metadata_cache.cc
@@ -183,13 +183,7 @@ void MetadataCache::refresh_thread() {
         std::lock_guard<std::mutex> lock(cache_refreshing_mutex_);
         // if the metadata is not consistent refresh it at a higher rate (if the
         // ttl>1s) until it becomes consistent again
-        const bool md_discrepancy =
-            std::find_if(cluster_topology_.clusters_data.begin(),
-                         cluster_topology_.clusters_data.end(),
-                         [](const auto &c) { return c.md_discrepancy; }) !=
-            cluster_topology_.clusters_data.end();
-
-        if (md_discrepancy) {
+        if (cluster_topology_.cluster_data.md_discrepancy) {
           break;
         }
       }
@@ -223,34 +217,30 @@ void MetadataCache::stop() noexcept {
 
 /**
  * Return a list of servers that are part of a cluster.
+ *
+ * TODO: this is not needed, get rid of this API
  */
 metadata_cache::cluster_nodes_list_t MetadataCache::get_cluster_nodes() {
   std::lock_guard<std::mutex> lock(cache_refreshing_mutex_);
-  return cluster_topology_.get_all_members();
-}
-
-metadata_cache::ClusterTopology MetadataCache::get_cluster_topology() {
-  std::lock_guard<std::mutex> lock(cache_refreshing_mutex_);
-  return cluster_topology_;
+  return cluster_topology_.cluster_data.members;
 }
 
 bool metadata_cache::ManagedInstance::operator==(
     const ManagedInstance &other) const {
   return mysql_server_uuid == other.mysql_server_uuid && mode == other.mode &&
-         role == other.role && host == other.host && port == other.port &&
-         xport == other.xport && hidden == other.hidden &&
+         host == other.host && port == other.port && xport == other.xport &&
+         hidden == other.hidden &&
          disconnect_existing_sessions_when_hidden ==
              other.disconnect_existing_sessions_when_hidden;
 }
 
 metadata_cache::ManagedInstance::ManagedInstance(
     InstanceType p_type, const std::string &p_mysql_server_uuid,
-    const ServerMode p_mode, const ServerRole p_role, const std::string &p_host,
-    const uint16_t p_port, const uint16_t p_xport)
+    const ServerMode p_mode, const std::string &p_host, const uint16_t p_port,
+    const uint16_t p_xport)
     : type(p_type),
       mysql_server_uuid(p_mysql_server_uuid),
       mode(p_mode),
-      role(p_role),
       host(p_host),
       port(p_port),
       xport(p_xport) {}
@@ -300,8 +290,7 @@ bool operator!=(const metadata_cache::ManagedCluster &cluster_a,
 
 bool operator==(const metadata_cache::ClusterTopology &a,
                 const metadata_cache::ClusterTopology &b) {
-  if (!std::is_permutation(a.clusters_data.begin(), a.clusters_data.end(),
-                           b.clusters_data.begin(), b.clusters_data.end())) {
+  if (a.cluster_data != b.cluster_data) {
     return false;
   }
 
@@ -311,7 +300,7 @@ bool operator==(const metadata_cache::ClusterTopology &a,
     return false;
   }
 
-  return a.target_cluster_pos == b.target_cluster_pos && a.view_id == b.view_id;
+  return a.view_id == b.view_id;
 }
 
 bool operator!=(const metadata_cache::ClusterTopology &a,
@@ -372,8 +361,8 @@ void MetadataCache::on_refresh_failed(bool terminated,
     bool clearing;
     {
       std::lock_guard<std::mutex> lock(cache_refreshing_mutex_);
-      clearing = !cluster_topology_.get_all_members().empty();
-      if (clearing) cluster_topology_.clear_all_members();
+      clearing = !cluster_topology_.cluster_data.members.empty();
+      if (clearing) cluster_topology_.cluster_data.members.clear();
     }
     if (clearing) {
       const auto log_level =
@@ -399,7 +388,9 @@ void MetadataCache::on_refresh_succeeded(
 
 void MetadataCache::on_instances_changed(
     const bool md_servers_reachable,
-    const metadata_cache::ClusterTopology &cluster_topology, uint64_t view_id) {
+    const metadata_cache::cluster_nodes_list_t &cluster_nodes,
+    const metadata_cache::metadata_servers_list_t &metadata_servers,
+    uint64_t view_id) {
   // Socket acceptors state will be updated when processing new instances
   // information.
   trigger_acceptor_update_on_next_refresh_ = false;
@@ -408,15 +399,14 @@ void MetadataCache::on_instances_changed(
     std::lock_guard<std::mutex> lock(cluster_instances_change_callbacks_mtx_);
 
     for (auto each : state_listeners_) {
-      each->notify_instances_changed(cluster_topology, md_servers_reachable,
-                                     view_id);
+      each->notify_instances_changed(cluster_nodes, metadata_servers,
+                                     md_servers_reachable, view_id);
     }
   }
 
   if (use_cluster_notifications_) {
-    const auto cluster_nodes = cluster_topology.get_all_members();
     meta_data_->setup_notifications_listener(
-        cluster_topology, [this]() { on_refresh_requested(); });
+        cluster_nodes, target_cluster_, [this]() { on_refresh_requested(); });
   }
 }
 
@@ -437,10 +427,10 @@ void MetadataCache::on_handle_sockets_acceptors() {
 
 void MetadataCache::on_md_refresh(
     const bool cluster_nodes_changed,
-    const metadata_cache::ClusterTopology &cluster_topology) {
+    const metadata_cache::cluster_nodes_list_t &cluster_nodes) {
   std::lock_guard<std::mutex> lock(md_refresh_callbacks_mtx_);
   for (auto &each : md_refresh_listeners_) {
-    each->on_md_refresh(cluster_nodes_changed, cluster_topology);
+    each->on_md_refresh(cluster_nodes_changed, cluster_nodes);
   }
 }
 
@@ -626,9 +616,9 @@ bool MetadataCache::update_auth_cache() {
 }
 
 void MetadataCache::update_router_attributes() {
-  if (cluster_topology_.writable_server) {
-    const auto &rw_server = cluster_topology_.writable_server.value();
-
+  if (cluster_topology_.cluster_data.writable_server) {
+    const auto &rw_server =
+        cluster_topology_.cluster_data.writable_server.value();
     try {
       meta_data_->update_router_attributes(rw_server, router_id_,
                                            router_attributes_);
@@ -675,8 +665,9 @@ void MetadataCache::update_router_attributes() {
 }
 
 void MetadataCache::update_router_last_check_in() {
-  if (cluster_topology_.writable_server) {
-    const auto &rw_server = cluster_topology_.writable_server.value();
+  if (cluster_topology_.cluster_data.writable_server) {
+    const auto &rw_server =
+        cluster_topology_.cluster_data.writable_server.value();
     try {
       meta_data_->update_router_last_check_in(rw_server, router_id_);
     } catch (const mysqlrouter::MetadataUpgradeInProgressException &) {
@@ -706,9 +697,3 @@ bool MetadataCache::needs_last_check_in_update() {
                      std::chrono::seconds(*frequency);
   }
 }
-
-void MetadataCache::fetch_whole_topology(bool val) {
-  fetch_whole_topology_ = val;
-  log_info("Configuration changed, fetch_whole_topology=%s",
-           std::to_string(val).c_str());
-}
\ No newline at end of file
diff --git a/router/src/metadata_cache/src/metadata_cache.h b/router/src/metadata_cache/src/metadata_cache.h
index eb0788d8ba2..c2f610d9a3b 100644
--- a/router/src/metadata_cache/src/metadata_cache.h
+++ b/router/src/metadata_cache/src/metadata_cache.h
@@ -103,16 +103,14 @@ class METADATA_CACHE_EXPORT MetadataCache
   void stop() noexcept;
 
   /** @brief Returns list of managed servers in a cluster
+   * TODO: is this needed?!?
    *
+   * Returns list of managed servers in a cluster.
    *
    * @return std::vector containing ManagedInstance objects
    */
   metadata_cache::cluster_nodes_list_t get_cluster_nodes();
 
-  /** @brief Returns object containing current Cluster Topology
-   */
-  metadata_cache::ClusterTopology get_cluster_topology();
-
   /** Wait until cluster PRIMARY changes.
    *
    * wait until a change of the PRIMARY is noticed
@@ -238,10 +236,6 @@ class METADATA_CACHE_EXPORT MetadataCache
     trigger_acceptor_update_on_next_refresh_ = true;
   }
 
-  bool fetch_whole_topology() const { return fetch_whole_topology_; }
-
-  void fetch_whole_topology(bool val);
-
  protected:
   /** @brief Refreshes the cache
    *
@@ -256,7 +250,8 @@ class METADATA_CACHE_EXPORT MetadataCache
   // the subscribed observers
   void on_instances_changed(
       const bool md_servers_reachable,
-      const metadata_cache::ClusterTopology &cluster_topology,
+      const metadata_cache::cluster_nodes_list_t &cluster_nodes,
+      const metadata_cache::metadata_servers_list_t &metadata_servers,
       uint64_t view_id = 0);
 
   /**
@@ -271,10 +266,10 @@ class METADATA_CACHE_EXPORT MetadataCache
    *
    * @param[in] cluster_nodes_changed Information whether there was a change
    *            in instances reported by metadata refresh.
-   * @param[in] cluster_topology current cluster topology
+   * @param[in] cluster_nodes Instances available after metadata refresh.
    */
   void on_md_refresh(const bool cluster_nodes_changed,
-                     const metadata_cache::ClusterTopology &cluster_topology);
+                     const metadata_cache::cluster_nodes_list_t &cluster_nodes);
 
   // Called each time we were requested to refresh the metadata
   void on_refresh_requested();
@@ -291,7 +286,7 @@ class METADATA_CACHE_EXPORT MetadataCache
   // Update Router last_check_in timestamp in the metadata
   void update_router_last_check_in();
 
-  // Stores the current cluster state and topology.
+  // Stores the current cluster topology
   metadata_cache::ClusterTopology cluster_topology_;
 
   // identifies the Cluster we work with
@@ -390,7 +385,6 @@ class METADATA_CACHE_EXPORT MetadataCache
       std::chrono::steady_clock::now()};
 
   bool ready_announced_{false};
-  bool fetch_whole_topology_{false};
 
   /**
    * Flag indicating if socket acceptors state should be updated on next
diff --git a/router/src/metadata_cache/src/metadata_cache_ar.cc b/router/src/metadata_cache/src/metadata_cache_ar.cc
index de302ec3d91..cda4eb58b09 100644
--- a/router/src/metadata_cache/src/metadata_cache_ar.cc
+++ b/router/src/metadata_cache/src/metadata_cache_ar.cc
@@ -35,8 +35,7 @@ bool ARMetadataCache::refresh(bool needs_writable_node) {
   size_t metadata_server_id;
   const auto res = meta_data_->fetch_cluster_topology(
       terminated_, target_cluster_, router_id_, metadata_servers_,
-      needs_writable_node, cluster_type_specific_id_, "", true,
-      metadata_server_id);
+      needs_writable_node, cluster_type_specific_id_, "", metadata_server_id);
 
   if (!res) {
     const bool md_servers_reachable =
@@ -59,13 +58,14 @@ bool ARMetadataCache::refresh(bool needs_writable_node) {
       cluster_topology_ = cluster_topology;
       changed = true;
     } else {
-      cluster_topology_.writable_server = cluster_topology.writable_server;
+      cluster_topology_.cluster_data.writable_server =
+          cluster_topology.cluster_data.writable_server;
     }
   }
 
-  on_md_refresh(changed, cluster_topology_);
+  const auto &cluster_members = cluster_topology_.cluster_data.members;
 
-  const auto cluster_members = cluster_topology_.get_all_members();
+  on_md_refresh(changed, cluster_members);
 
   if (changed) {
     log_info(
@@ -85,8 +85,8 @@ bool ARMetadataCache::refresh(bool needs_writable_node) {
       }
     }
 
-    on_instances_changed(/*md_servers_reachable=*/true, cluster_topology,
-                         view_id);
+    on_instances_changed(/*md_servers_reachable=*/true, cluster_members,
+                         cluster_topology.metadata_servers, view_id);
 
     on_refresh_succeeded(metadata_servers_[metadata_server_id]);
 
diff --git a/router/src/metadata_cache/src/metadata_cache_gr.cc b/router/src/metadata_cache/src/metadata_cache_gr.cc
index 46e4f88e863..ed401c77cc9 100644
--- a/router/src/metadata_cache/src/metadata_cache_gr.cc
+++ b/router/src/metadata_cache/src/metadata_cache_gr.cc
@@ -420,14 +420,11 @@ bool GRMetadataCache::refresh(bool needs_writable_node) {
   size_t metadata_server_id{0};
   changed = false;
   std::size_t instance_id;
-
-  const bool whole_topology = fetch_whole_topology();
-
   // Fetch the metadata and store it in a temporary variable.
   const auto res = meta_data_->fetch_cluster_topology(
       terminated_, target_cluster_, router_id_, metadata_servers_,
       needs_writable_node, cluster_type_specific_id_, clusterset_id_,
-      whole_topology, instance_id);
+      instance_id);
 
   if (!res) {
     const bool md_servers_reachable =
@@ -450,11 +447,13 @@ bool GRMetadataCache::refresh(bool needs_writable_node) {
       cluster_topology_ = cluster_topology;
       changed = true;
     } else {
-      cluster_topology_.writable_server = cluster_topology.writable_server;
+      cluster_topology_.cluster_data.writable_server =
+          cluster_topology.cluster_data.writable_server;
     }
   }
 
-  on_md_refresh(changed, cluster_topology_);
+  const auto &cluster_members = cluster_topology_.cluster_data.members;
+  on_md_refresh(changed, cluster_members);
 
   // we want to trigger those actions not only if the metadata has really
   // changed but also when something external (like unsuccessful client
@@ -463,29 +462,29 @@ bool GRMetadataCache::refresh(bool needs_writable_node) {
   view_id = cluster_topology_.view_id;
   if (changed) {
     log_info(
-        "Potential changes detected in cluster after metadata refresh "
-        "(view_id=%" PRIu64 ")",
-        view_id);
+        "Potential changes detected in cluster '%s' after metadata refresh",
+        target_cluster_.c_str());
     // dump some informational/debugging information about the cluster
     log_cluster_details();
-    for (const auto &cluster : cluster_topology_.clusters_data) {
-      if (cluster.members.empty())
-        log_error("Metadata for cluster '%s' is empty!", cluster.name.c_str());
-      else {
-        log_info(
-            "Metadata for cluster '%s' has %zu member(s), %s: ",
-            cluster.name.c_str(), cluster.members.size(),
-            cluster.single_primary_mode ? "single-primary" : "multi-primary");
-        for (const auto &mi : cluster.members) {
-          log_info("    %s:%i / %i - mode=%s %s", mi.host.c_str(), mi.port,
-                   mi.xport, to_string(mi.mode).c_str(),
-                   get_hidden_info(mi).c_str());
-        }
+    if (cluster_members.empty())
+      log_error("Metadata for cluster '%s' is empty!", target_cluster_.c_str());
+    else {
+      log_info(
+          "Metadata for cluster '%s' has %zu member(s), %s: (view_id=%" PRIu64
+          ")",
+          target_cluster_.c_str(), cluster_members.size(),
+          cluster_topology_.cluster_data.single_primary_mode ? "single-primary"
+                                                             : "multi-primary",
+          view_id);
+      for (const auto &mi : cluster_members) {
+        log_info("    %s:%i / %i - mode=%s %s", mi.host.c_str(), mi.port,
+                 mi.xport, to_string(mi.mode).c_str(),
+                 get_hidden_info(mi).c_str());
       }
     }
 
-    on_instances_changed(/*md_servers_reachable=*/true, cluster_topology,
-                         view_id);
+    on_instances_changed(/*md_servers_reachable=*/true, cluster_members,
+                         cluster_topology.metadata_servers, view_id);
     // never let the list that we iterate over become empty as we would
     // not recover from that
     if (!cluster_topology.metadata_servers.empty()) {
@@ -506,12 +505,17 @@ void GRMetadataCache::log_cluster_details() const {
   const auto cluster_type = meta_data_->get_cluster_type();
 
   if (cluster_type == mysqlrouter::ClusterType::GR_CS) {
+    const std::string cluster_role =
+        cluster_topology_.cluster_data.is_primary ? "primary" : "replica";
+    const std::string cluster_invalidated =
+        cluster_topology_.cluster_data.is_invalidated
+            ? "cluster is marked as invalid in the metadata; "
+            : "";
+
     bool has_rw_nodes{false};
-    const auto cluster_members = cluster_topology_.get_all_members();
-    for (const auto &mi : cluster_members) {
+    for (const auto &mi : cluster_topology_.cluster_data.members) {
       if (mi.mode == metadata_cache::ServerMode::ReadWrite) {
         has_rw_nodes = true;
-        break;
       }
     }
 
@@ -519,21 +523,10 @@ void GRMetadataCache::log_cluster_details() const {
                                          ? "accepting RW connections"
                                          : "not accepting RW connections";
 
-    log_info("Target cluster(s) are part of a ClusterSet: %s",
-             accepting_rw.c_str());
-
-    for (const auto &cluster : cluster_topology_.clusters_data) {
-      const std::string cluster_role =
-          cluster.is_primary ? "primary" : "replica";
-      const std::string cluster_invalidated =
-          cluster.is_invalidated
-              ? "cluster is marked as invalid in the metadata; "
-              : "";
-
-      log_info(
-          "Cluster '%s': role of a cluster within a ClusterSet is '%s'; %s",
-          cluster.name.c_str(), cluster_role.c_str(),
-          cluster_invalidated.c_str());
-    }
+    log_info(
+        "Target cluster '%s' is part of a ClusterSet; role of a cluster within "
+        "a ClusterSet is '%s'; %s%s",
+        target_cluster_.c_str(), cluster_role.c_str(),
+        cluster_invalidated.c_str(), accepting_rw.c_str());
   }
 }
diff --git a/router/src/metadata_cache/src/metadata_cache_plugin.cc b/router/src/metadata_cache/src/metadata_cache_plugin.cc
index b0a8a1ca7a0..a4a45b4f971 100644
--- a/router/src/metadata_cache/src/metadata_cache_plugin.cc
+++ b/router/src/metadata_cache/src/metadata_cache_plugin.cc
@@ -46,6 +46,7 @@
 #include "mysqlrouter/utils.h"
 #include "plugin_config.h"
 
+using metadata_cache::LookupResult;
 IMPORT_LOG_FUNCTIONS()
 
 static const mysql_harness::AppInfo *g_app_info;
@@ -142,11 +143,12 @@ class MetadataServersStateListener
   }
 
   void notify_instances_changed(
-      const metadata_cache::ClusterTopology &cluster_topology,
+      const LookupResult & /*instances*/,
+      const metadata_cache::metadata_servers_list_t &metadata_servers,
       const bool md_servers_reachable, const uint64_t view_id) override {
     if (!md_servers_reachable) return;
 
-    if (cluster_topology.metadata_servers.empty()) {
+    if (metadata_servers.empty()) {
       // This happens for example when the router could connect to one of the
       // metadata servers but failed to fetch metadata because the connection
       // went down while querying metadata
@@ -158,7 +160,7 @@ class MetadataServersStateListener
 
     // need to convert from ManagedInstance to uri string
     std::vector<std::string> metadata_servers_str;
-    for (auto &md_server : cluster_topology.metadata_servers) {
+    for (auto &md_server : metadata_servers) {
       mysqlrouter::URI uri;
       uri.scheme = "mysql";
       uri.host = md_server.address();
diff --git a/router/src/metadata_cache/tests/helper/mock_metadata.cc b/router/src/metadata_cache/tests/helper/mock_metadata.cc
index 6fd4b9c98ca..f444e7d8ac0 100644
--- a/router/src/metadata_cache/tests/helper/mock_metadata.cc
+++ b/router/src/metadata_cache/tests/helper/mock_metadata.cc
@@ -60,15 +60,12 @@ MockNG::MockNG(
   cluster_instances_vector.push_back(ms2);
   cluster_instances_vector.push_back(ms3);
 
-  metadata_cache::ManagedCluster cluster;
-  cluster.single_primary_mode = true;
-  cluster.members = cluster_instances_vector;
-  cluster_topology.clusters_data.push_back(cluster);
-  cluster_topology.target_cluster_pos = 0;
-
-  cluster_topology.metadata_servers.emplace_back(ms1.host, ms1.port);
-  cluster_topology.metadata_servers.emplace_back(ms2.host, ms2.port);
-  cluster_topology.metadata_servers.emplace_back(ms3.host, ms3.port);
+  cluster_info.single_primary_mode = true;
+  cluster_info.members = cluster_instances_vector;
+
+  metadata_servers.push_back({ms1.host, ms1.port});
+  metadata_servers.push_back({ms2.host, ms2.port});
+  metadata_servers.push_back({ms3.host, ms3.port});
 }
 
 /** @brief Destructor
@@ -89,9 +86,8 @@ MockNG::fetch_cluster_topology(
     const unsigned /*router_id*/,
     const metadata_cache::metadata_servers_list_t & /*metadata_servers*/,
     bool /* needs_writable_node */, const string & /*group_replication_id*/,
-    const string & /*clusterset_id*/, bool /*whole_topology*/,
-    size_t & /*instance_id*/) {
-  return cluster_topology;
+    const string & /*clusterset_id*/, size_t & /*instance_id*/) {
+  return metadata_cache::ClusterTopology{cluster_info, metadata_servers};
 }
 
 /** @brief Mock connect method.
diff --git a/router/src/metadata_cache/tests/helper/mock_metadata.h b/router/src/metadata_cache/tests/helper/mock_metadata.h
index d1a9e77b641..66f92b7cb89 100644
--- a/router/src/metadata_cache/tests/helper/mock_metadata.h
+++ b/router/src/metadata_cache/tests/helper/mock_metadata.h
@@ -55,7 +55,7 @@ class MockNG : public GRClusterMetadata {
   /**
    * The information about the HA topology being managed.
    */
-  metadata_cache::ClusterTopology cluster_topology;
+  metadata_cache::ManagedCluster cluster_info;
 
   metadata_cache::metadata_servers_list_t metadata_servers;
 
@@ -104,8 +104,7 @@ class MockNG : public GRClusterMetadata {
       mysqlrouter::TargetCluster &target_cluster, const unsigned /*router_id*/,
       const metadata_cache::metadata_servers_list_t &metadata_servers,
       bool needs_writable_node, const std::string &group_replication_id,
-      const std::string &clusterset_id, bool whole_topology,
-      size_t &instance_id) override;
+      const std::string &clusterset_id, size_t &instance_id) override;
 
 #if 0  // not used so far
   /**
diff --git a/router/src/metadata_cache/tests/test_cache_plugin.cc b/router/src/metadata_cache/tests/test_cache_plugin.cc
index 6f1fbcd5660..50b3e8389b1 100644
--- a/router/src/metadata_cache/tests/test_cache_plugin.cc
+++ b/router/src/metadata_cache/tests/test_cache_plugin.cc
@@ -93,7 +93,7 @@ class MetadataCachePluginTest : public ::testing::Test {
      */
     while (instance_vector_1.size() != 3) {
       try {
-        instance_vector_1 = cache_api_->get_cluster_nodes();
+        instance_vector_1 = cache_api_->get_cluster_nodes().instance_vector;
       } catch (const std::runtime_error &exc) {
         /**
          * If the lookup fails after 5 attempts it points to an error
@@ -121,7 +121,7 @@ class MetadataCachePluginTest : public ::testing::Test {
  */
 TEST_F(MetadataCachePluginTest, ValidCluserTest_1) {
   std::vector<ManagedInstance> instance_vector_1 =
-      cache_api_->get_cluster_nodes();
+      cache_api_->get_cluster_nodes().instance_vector;
 
   EXPECT_EQ(instance_vector_1[0], mf.ms1);
   EXPECT_EQ(instance_vector_1[1], mf.ms2);
diff --git a/router/src/metadata_cache/tests/test_failover.cc b/router/src/metadata_cache/tests/test_failover.cc
index 6f64e33293d..d8da35cdc11 100644
--- a/router/src/metadata_cache/tests/test_failover.cc
+++ b/router/src/metadata_cache/tests/test_failover.cc
@@ -55,8 +55,6 @@ static constexpr const char node_3_uuid[] =
     "f0a2079f-8b90-4324-9eec-a0496c4338e0";
 
 static constexpr const char replicaset_name[] = "default";
-static constexpr const char cluster_id[] = "cluster-1-id";
-static constexpr const char cluster_name[] = "cluster-1";
 
 class FailoverTest : public ::testing::Test {
  public:
@@ -118,8 +116,7 @@ class FailoverTest : public ::testing::Test {
                           m.string_or_null("1")},
                      });
     m.expect_query(
-        "SELECT F.cluster_id, F.cluster_name, R.replicaset_name, "
-        "I.mysql_server_uuid, "
+        "SELECT R.replicaset_name, I.mysql_server_uuid, "
         "I.addresses->>'$.mysqlClassic', I.addresses->>'$.mysqlX' FROM "
         "mysql_innodb_cluster_metadata.clusters "
         "AS F JOIN mysql_innodb_cluster_metadata.replicasets AS R ON "
@@ -129,19 +126,16 @@ class FailoverTest : public ::testing::Test {
         "AND R.attributes->>'$.group_replication_group_name' = "
         "'3e4338a1-2c5d-49ac-8baa-e5a25ba61e76'");
     m.then_return(
-        5,
-        {// cluster_id, cluster_name, replicaset_name, mysql_server_uuid,
-         // I.addresses->>'$.mysqlClassic', I.addresses->>'$.mysqlX'
-         {m.string_or_null(cluster_id), m.string_or_null(cluster_name),
-          m.string_or_null(replicaset_name), m.string_or_null(node_1_uuid),
+        7,
+        {// replicaset_name, mysql_server_uuid,
+         // location, I.addresses->>'$.mysqlClassic', I.addresses->>'$.mysqlX'
+         {m.string_or_null(replicaset_name), m.string_or_null(node_1_uuid),
           m.string_or_null("localhost:3000"),
           m.string_or_null("localhost:30000")},
-         {m.string_or_null(cluster_id), m.string_or_null(cluster_name),
-          m.string_or_null(replicaset_name), m.string_or_null(node_2_uuid),
+         {m.string_or_null(replicaset_name), m.string_or_null(node_2_uuid),
           m.string_or_null("localhost:3001"),
           m.string_or_null("localhost:30010")},
-         {m.string_or_null(cluster_id), m.string_or_null(cluster_name),
-          m.string_or_null(replicaset_name), m.string_or_null(node_3_uuid),
+         {m.string_or_null(replicaset_name), m.string_or_null(node_3_uuid),
           m.string_or_null("localhost:3002"),
           m.string_or_null("localhost:30020")}});
 
diff --git a/router/src/metadata_cache/tests/test_metadata.cc b/router/src/metadata_cache/tests/test_metadata.cc
index 273b9993f4e..cf63a85d102 100644
--- a/router/src/metadata_cache/tests/test_metadata.cc
+++ b/router/src/metadata_cache/tests/test_metadata.cc
@@ -54,13 +54,13 @@ using ::testing::Throw;
 using metadata_cache::ManagedCluster;
 using metadata_cache::ManagedInstance;
 using metadata_cache::ServerMode;
-using metadata_cache::ServerRole;
 using mysqlrouter::MySQLSession;
 
 using State = GroupReplicationMember::State;
 using Role = GroupReplicationMember::Role;
 
 constexpr auto GR = metadata_cache::InstanceType::GroupMember;
+
 ////////////////////////////////////////////////////////////////////////////////
 //
 // These tests focus on testing functionality implemented in
@@ -96,7 +96,7 @@ const std::string query_schema_version =
 // metadata server
 std::string query_metadata =
     "SELECT "
-    "F.cluster_id, F.cluster_name, R.replicaset_name, I.mysql_server_uuid, "
+    "R.replicaset_name, I.mysql_server_uuid, "
     "I.addresses->>'$.mysqlClassic', I.addresses->>'$.mysqlX' "
     "FROM mysql_innodb_cluster_metadata.clusters AS F "
     "JOIN mysql_innodb_cluster_metadata.replicasets AS R ON F.cluster_id = "
@@ -287,8 +287,7 @@ class MetadataTest : public ::testing::Test {
 
   void connect_to_first_metadata_server() {
     std::vector<ManagedInstance> metadata_servers{
-        {GR, "instance-1", ServerMode::ReadWrite, ServerRole::Primary,
-         "localhost", 3310, 33100},
+        {GR, "instance-1", ServerMode::ReadWrite, "localhost", 3310, 33100},
     };
     session_factory.get(0).set_good_conns(
         {"localhost:3310", "localhost:3320", "localhost:3330"});
@@ -399,12 +398,9 @@ class MetadataTest : public ::testing::Test {
       {
           // will be set ----------------------vvvvvvvvvvvvvvvvvvvvvvv
           // v--v--vv--- ignored at the time of writing
-          {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable,
-           "localhost", 3310, 33100},
-          {GR, "instance-2", ServerMode::Unavailable, ServerRole::Unavailable,
-           "localhost", 3320, 33200},
-          {GR, "instance-3", ServerMode::Unavailable, ServerRole::Unavailable,
-           "localhost", 3330, 33300},
+          {GR, "instance-1", ServerMode::Unavailable, "localhost", 3310, 33100},
+          {GR, "instance-2", ServerMode::Unavailable, "localhost", 3320, 33200},
+          {GR, "instance-3", ServerMode::Unavailable, "localhost", 3330, 33300},
           // ignored at time of writing
           // -^^^^--------------------------------------------------------^^^^^
           // TODO: ok to ignore xport?
@@ -419,13 +415,8 @@ class MetadataTest : public ::testing::Test {
 ////////////////////////////////////////////////////////////////////////////////
 
 TEST_F(MetadataTest, ConnectToMetadataServer_Succeed) {
-  ManagedInstance metadata_server{GR,
-                                  "instance-1",
-                                  ServerMode::ReadWrite,
-                                  ServerRole::Primary,
-                                  "localhost",
-                                  3310,
-                                  33100};
+  ManagedInstance metadata_server{
+      GR, "instance-1", ServerMode::ReadWrite, "localhost", 3310, 33100};
   session_factory.get(0).set_good_conns({"localhost:3310"});
 
   // should connect successfully
@@ -436,13 +427,8 @@ TEST_F(MetadataTest, ConnectToMetadataServer_Succeed) {
 }
 
 TEST_F(MetadataTest, ConnectToMetadataServer_Failed) {
-  ManagedInstance metadata_server{GR,
-                                  "instance-1",
-                                  ServerMode::ReadWrite,
-                                  ServerRole::Primary,
-                                  "localhost",
-                                  3310,
-                                  33100};
+  ManagedInstance metadata_server{
+      GR, "instance-1", ServerMode::ReadWrite, "localhost", 3310, 33100};
 
   // connection attempt should fail
   EXPECT_CALL(session_factory.get(0), flag_fail(_, 3310)).Times(1);
@@ -474,16 +460,13 @@ TEST_F(MetadataTest, FetchInstancesFromMetadataServer) {
         [this](const std::string &, const MySQLSession::RowProcessor &processor,
                const MySQLSession::FieldValidator &) {
           session_factory.get(0).query_impl(
-              processor, {
-                             {"cluster-id", "cluster-name", "", "instance-1",
-                              "localhost:3310", "localhost:33100"},
-                             {"cluster-id", "cluster-name", "", "instance-2",
-                              "localhost:3320", nullptr},
-                             {"cluster-id", "cluster-name", "", "instance-3",
-                              "localhost", nullptr},
-                             {"cluster-id", "cluster-name", "", "instance-4",
-                              nullptr, nullptr},
-                         });
+              processor,
+              {
+                  {"", "instance-1", "localhost:3310", "localhost:33100"},
+                  {"", "instance-2", "localhost:3320", nullptr},
+                  {"", "instance-3", "localhost", nullptr},
+                  {"", "instance-4", nullptr, nullptr},
+              });
         };
     EXPECT_CALL(session_factory.get(0), query(StartsWith(query_metadata), _, _))
         .Times(1)
@@ -491,30 +474,30 @@ TEST_F(MetadataTest, FetchInstancesFromMetadataServer) {
 
     ASSERT_NO_THROW({
       metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-      auto cluster_topology = metadata.fetch_instances_from_metadata_server(
+      auto cluster = metadata.fetch_instances_from_metadata_server(
           {mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name"},
           "0001");
 
-      ASSERT_EQ(1u, cluster_topology.clusters_data.size());
-      const auto &cluster = cluster_topology.clusters_data[0];
-      EXPECT_EQ(4u, cluster.members.size());
-
+      EXPECT_EQ(4u, cluster.members.size());  // not set/checked
+      // -------------------vvvvvvvvvvvvvvvvvvvvvvv
       EXPECT_TRUE(cmp_mi_FIFMS(
           ManagedInstance{GR, "instance-1", ServerMode::Unavailable,
-                          ServerRole::Unavailable, "localhost", 3310, 33100},
+                          "localhost", 3310, 33100},
           cluster.members.at(0)));
       EXPECT_TRUE(cmp_mi_FIFMS(
           ManagedInstance{GR, "instance-2", ServerMode::Unavailable,
-                          ServerRole::Unavailable, "localhost", 3320, 33200},
+                          "localhost", 3320, 33200},
           cluster.members.at(1)));
       EXPECT_TRUE(cmp_mi_FIFMS(
           ManagedInstance{GR, "instance-3", ServerMode::Unavailable,
-                          ServerRole::Unavailable, "localhost", 3306, 33060},
+                          "localhost", 3306, 33060},
           cluster.members.at(2)));
       EXPECT_TRUE(cmp_mi_FIFMS(
-          ManagedInstance{GR, "instance-4", ServerMode::Unavailable,
-                          ServerRole::Unavailable, "", 3306, 33060},
+          ManagedInstance{GR, "instance-4", ServerMode::Unavailable, "", 3306,
+                          33060},
           cluster.members.at(3)));
+      // TODO is this really right behavior?
+      // ---------------------------------------------------------------------------------------------------^^
     });
   }
 
@@ -531,12 +514,11 @@ TEST_F(MetadataTest, FetchInstancesFromMetadataServer) {
 
     ASSERT_NO_THROW({
       metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-      auto cluster_topology = metadata.fetch_instances_from_metadata_server(
+      auto cluster = metadata.fetch_instances_from_metadata_server(
           {mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name"},
           "0001");
 
-      ASSERT_EQ(1u, cluster_topology.clusters_data.size());
-      EXPECT_EQ(0u, cluster_topology.clusters_data[0].members.size());
+      EXPECT_EQ(0u, cluster.members.size());
     });
   }
 
@@ -585,8 +567,7 @@ TEST_F(MetadataTest, FetchInstancesFromMetadataServer) {
 TEST_F(MetadataTest, CheckClusterStatus_1Online1RecoveringNotInMetadata) {
   std::vector<ManagedInstance> servers_in_metadata{
       // ServerMode doesn't matter ---vvvvv
-      {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
+      {GR, "instance-1", ServerMode::Unavailable, "", 0, 0},
   };
   bool metadata_gr_discrepancy{false};
 
@@ -615,12 +596,9 @@ TEST_F(MetadataTest, CheckClusterStatus_1Online1RecoveringNotInMetadata) {
 TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
   std::vector<ManagedInstance> servers_in_metadata{
       // ServerMode doesn't matter ------vvvvvvvvvvv
-      {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
-      {GR, "instance-2", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
-      {GR, "instance-3", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
+      {GR, "instance-1", ServerMode::Unavailable, "", 0, 0},
+      {GR, "instance-2", ServerMode::Unavailable, "", 0, 0},
+      {GR, "instance-3", ServerMode::Unavailable, "", 0, 0},
   };
   bool metadata_gr_discrepancy{false};
 
@@ -640,9 +618,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(2).role);
     EXPECT_FALSE(metadata_gr_discrepancy);
   }
 
@@ -737,9 +712,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-2) defined in metadata
     // not found in actual Group Replication"
     EXPECT_TRUE(metadata_gr_discrepancy);
@@ -757,9 +729,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-1) defined in metadata
     // not found in actual Group Replication"
     EXPECT_TRUE(metadata_gr_discrepancy);
@@ -776,9 +745,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-2) defined in metadata
     // not found in actual Group Replication", should log warning "Member
     // <host>:<port> (instance-3) defined in metadata not found in actual Group
@@ -797,9 +763,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-1) defined in metadata
     // not found in actual Group Replication" should log warning "Member
     // <host>:<port> (instance-2) defined in metadata not found in actual Group
@@ -816,9 +779,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-1) defined in metadata
     // not found in actual replicaset" should log warning "Member <host>:<port>
     // (instance-2) defined in metadata not found in actual Group Replication"
@@ -841,9 +801,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-1) defined in metadata
     // not found in actual Group Replication" should log error "Member
     // <host>:<port> (instance-4) found in Group Replication, yet is not defined
@@ -864,9 +821,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::Unavailable, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Unavailable, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-1) defined in metadata
     // not found in actual Group Replication" should log warning "Member
     // <host>:<port> (instance-3) defined in metadata not found in actual Group
@@ -892,9 +846,6 @@ TEST_F(MetadataTest, CheckClusterStatus_3NodeSetup) {
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(2).role);
     // should log error "Member <host>:<port> (instance-4) found in replicaset,
     // yet is not defined in metadata!" should log error "Member <host>:<port>
     // (instance-5) found in Group Replication, yet is not defined in metadata!"
@@ -932,20 +883,13 @@ TEST_F(MetadataTest, CheckClusterStatus_VariableNodeSetup) {
   {
     std::vector<ManagedInstance> servers_in_metadata{
         // ServerMode doesn't matter ------vvvvvvvvvvv
-        {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-2", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-3", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-4", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-5", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-6", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-7", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
+        {GR, "instance-1", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-2", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-3", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-4", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-5", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-6", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-7", ServerMode::Unavailable, "", 0, 0},
     };
     EXPECT_EQ(GRClusterStatus::AvailableWritable,
               metadata.check_cluster_status(servers_in_metadata, server_status,
@@ -953,9 +897,6 @@ TEST_F(MetadataTest, CheckClusterStatus_VariableNodeSetup) {
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-*) defined in metadata
     // not found in actual Group Replication" for instances 4-7
     EXPECT_TRUE(metadata_gr_discrepancy);
@@ -964,14 +905,10 @@ TEST_F(MetadataTest, CheckClusterStatus_VariableNodeSetup) {
   // 4-node setup according to metadata
   {
     std::vector<ManagedInstance> servers_in_metadata{
-        {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-2", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-3", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-4", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
+        {GR, "instance-1", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-2", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-3", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-4", ServerMode::Unavailable, "", 0, 0},
     };
     EXPECT_EQ(GRClusterStatus::AvailableWritable,
               metadata.check_cluster_status(servers_in_metadata, server_status,
@@ -979,9 +916,6 @@ TEST_F(MetadataTest, CheckClusterStatus_VariableNodeSetup) {
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(1).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(2).mode);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(1).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(2).role);
     // should log warning "Member <host>:<port> (instance-4) defined in metadata
     // not found in actual Group Replication"
     EXPECT_TRUE(metadata_gr_discrepancy);
@@ -1001,18 +935,14 @@ TEST_F(MetadataTest, CheckClusterStatus_VariableNodeSetup) {
   // count
   {
     std::vector<ManagedInstance> servers_in_metadata{
-        {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
-        {GR, "instance-2", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
+        {GR, "instance-1", ServerMode::Unavailable, "", 0, 0},
+        {GR, "instance-2", ServerMode::Unavailable, "", 0, 0},
     };
     EXPECT_EQ(GRClusterStatus::AvailableWritable,
               metadata.check_cluster_status(servers_in_metadata, server_status,
                                             metadata_gr_discrepancy));
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(0).mode);
     EXPECT_EQ(ServerMode::ReadOnly, servers_in_metadata.at(1).mode);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(0).role);
-    EXPECT_EQ(ServerRole::Secondary, servers_in_metadata.at(1).role);
     // should log error "Member <host>:<port> (instance-3) found in Group
     // Replication, yet is not defined in metadata!"
     EXPECT_TRUE(metadata_gr_discrepancy);
@@ -1022,14 +952,12 @@ TEST_F(MetadataTest, CheckClusterStatus_VariableNodeSetup) {
   // counts
   {
     std::vector<ManagedInstance> servers_in_metadata{
-        {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable, "",
-         0, 0},
+        {GR, "instance-1", ServerMode::Unavailable, "", 0, 0},
     };
     EXPECT_EQ(GRClusterStatus::Unavailable,
               metadata.check_cluster_status(servers_in_metadata, server_status,
                                             metadata_gr_discrepancy));
     EXPECT_EQ(ServerMode::ReadWrite, servers_in_metadata.at(0).mode);
-    EXPECT_EQ(ServerRole::Primary, servers_in_metadata.at(0).role);
     // should log error "Member <host>:<port> (instance-2) found in Group
     // Replication, yet is not defined in metadata!" should log error "Member
     // <host>:<port> (instance-3) found in Group Replication, yet is not defined
@@ -1068,12 +996,9 @@ TEST_F(MetadataTest, CheckClusterStatus_VariousStatuses) {
 
   std::vector<ManagedInstance> servers_in_metadata{
       // ServerMode doesn't matter ------vvvvvvvvvvv
-      {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
-      {GR, "instance-2", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
-      {GR, "instance-3", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
+      {GR, "instance-1", ServerMode::Unavailable, "", 0, 0},
+      {GR, "instance-2", ServerMode::Unavailable, "", 0, 0},
+      {GR, "instance-3", ServerMode::Unavailable, "", 0, 0},
   };
 
   for (State state :
@@ -1149,12 +1074,9 @@ TEST_F(MetadataTest, CheckClusterStatus_Recovering) {
 
   std::vector<ManagedInstance> servers_in_metadata{
       // ServerMode doesn't matter ------vvvvvvvvvvv
-      {GR, "instance-1", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
-      {GR, "instance-2", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
-      {GR, "instance-3", ServerMode::Unavailable, ServerRole::Unavailable, "",
-       0, 0},
+      {GR, "instance-1", ServerMode::Unavailable, "", 0, 0},
+      {GR, "instance-2", ServerMode::Unavailable, "", 0, 0},
+      {GR, "instance-3", ServerMode::Unavailable, "", 0, 0},
   };
 
   // 1 node recovering, 1 RW, 1 RO
@@ -1350,12 +1272,9 @@ TEST_F(MetadataTest, CheckClusterStatus_Cornercase2of5Alive) {
 
   // MD defines 3 nodes
   std::vector<ManagedInstance> servers_in_metadata{
-      {GR, "node-A", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
-      {GR, "node-B", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
-      {GR, "node-C", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
+      {GR, "node-A", ServerMode::Unavailable, "", 0, 0},
+      {GR, "node-B", ServerMode::Unavailable, "", 0, 0},
+      {GR, "node-C", ServerMode::Unavailable, "", 0, 0},
   };
 
   // GR reports 5 nodes, of which only 2 are alive (no qourum), BUT from
@@ -1430,12 +1349,9 @@ TEST_F(MetadataTest, CheckClusterStatus_Cornercase3of5Alive) {
 
   // MD defines 3 nodes
   std::vector<ManagedInstance> servers_in_metadata{
-      {GR, "node-A", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
-      {GR, "node-B", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
-      {GR, "node-C", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
+      {GR, "node-A", ServerMode::Unavailable, "", 0, 0},
+      {GR, "node-B", ServerMode::Unavailable, "", 0, 0},
+      {GR, "node-C", ServerMode::Unavailable, "", 0, 0},
   };
 
   // GR reports 5 nodes, of which 3 are alive (have qourum), BUT from
@@ -1509,12 +1425,9 @@ TEST_F(MetadataTest, CheckClusterStatus_Cornercase1Common) {
 
   // MD defines 3 nodes
   std::vector<ManagedInstance> servers_in_metadata{
-      {GR, "node-A", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
-      {GR, "node-B", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
-      {GR, "node-C", ServerMode::Unavailable, ServerRole::Unavailable, "", 0,
-       0},
+      {GR, "node-A", ServerMode::Unavailable, "", 0, 0},
+      {GR, "node-B", ServerMode::Unavailable, "", 0, 0},
+      {GR, "node-C", ServerMode::Unavailable, "", 0, 0},
   };
 
   // GR reports 3 nodes, of which 3 are alive (have qourum), BUT from
@@ -1615,21 +1528,20 @@ TEST_F(MetadataTest, UpdateClusterStatus_PrimaryMember_FailConnectOnNode2) {
 
   ManagedCluster cluster = typical_cluster;
   metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-  metadata.update_cluster_status(cluster);
+  metadata.update_cluster_status(
+      {mysqlrouter::TargetCluster::TargetType::ByName, "cluster_name"},
+      cluster);
 
   EXPECT_EQ(3u, cluster.members.size());
-  EXPECT_TRUE(
-      cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
-                                ServerRole::Primary, "localhost", 3310, 33100},
-                cluster.members.at(0)));
-  EXPECT_TRUE(cmp_mi_FI(
-      ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
-                      ServerRole::Secondary, "localhost", 3320, 33200},
-      cluster.members.at(1)));
-  EXPECT_TRUE(cmp_mi_FI(
-      ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
-                      ServerRole::Secondary, "localhost", 3330, 33300},
-      cluster.members.at(2)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
+                                        "localhost", 3310, 33100},
+                        cluster.members.at(0)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
+                                        "localhost", 3320, 33200},
+                        cluster.members.at(1)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
+                                        "localhost", 3330, 33300},
+                        cluster.members.at(2)));
 
   EXPECT_EQ(3, session_factory.create_cnt());  // +2 from new connections to
                                                // localhost:3320 and :3330
@@ -1675,7 +1587,9 @@ TEST_F(MetadataTest, UpdateClusterStatus_PrimaryMember_FailConnectOnAllNodes) {
   ManagedCluster cluster = typical_cluster;
   ConnectCallback clb;
   metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-  metadata.update_cluster_status(cluster);
+  metadata.update_cluster_status(
+      {mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name"},
+      cluster);
   EXPECT_TRUE(cluster.members.empty());
 
   EXPECT_EQ(3, session_factory.create_cnt());  // +2 from new connections to
@@ -1737,25 +1651,24 @@ TEST_F(MetadataTest, UpdateClusterStatus_PrimaryMember_FailQueryOnNode1) {
   ManagedCluster cluster = typical_cluster;
   ConnectCallback clb;
   metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-  metadata.update_cluster_status(cluster);
+  metadata.update_cluster_status(
+      {mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name"},
+      cluster);
 
   EXPECT_EQ(2, session_factory.create_cnt());  // +1 from new connection to
                                                // localhost:3320 (instance-2)
 
   // query_status reported back from instance-2
   EXPECT_EQ(3u, cluster.members.size());
-  EXPECT_TRUE(
-      cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
-                                ServerRole::Primary, "localhost", 3310, 33100},
-                cluster.members.at(0)));
-  EXPECT_TRUE(cmp_mi_FI(
-      ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
-                      ServerRole::Secondary, "localhost", 3320, 33200},
-      cluster.members.at(1)));
-  EXPECT_TRUE(cmp_mi_FI(
-      ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
-                      ServerRole::Secondary, "localhost", 3330, 33300},
-      cluster.members.at(2)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
+                                        "localhost", 3310, 33100},
+                        cluster.members.at(0)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
+                                        "localhost", 3320, 33200},
+                        cluster.members.at(1)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
+                                        "localhost", 3330, 33300},
+                        cluster.members.at(2)));
 }
 
 /**
@@ -1813,7 +1726,9 @@ TEST_F(MetadataTest, UpdateClusterStatus_PrimaryMember_FailQueryOnAllNodes) {
   // replicaset.members
   ManagedCluster cluster = typical_cluster;
   metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-  metadata.update_cluster_status(cluster);
+  metadata.update_cluster_status(
+      {mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name"},
+      cluster);
   EXPECT_TRUE(cluster.members.empty());
 
   EXPECT_EQ(3, session_factory.create_cnt());  // +2 from new connections to
@@ -1879,25 +1794,24 @@ TEST_F(MetadataTest, UpdateClusterStatus_Status_FailQueryOnNode1) {
 
   ManagedCluster cluster = typical_cluster;
   metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-  metadata.update_cluster_status(cluster);
+  metadata.update_cluster_status(
+      {mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name"},
+      cluster);
 
   EXPECT_EQ(2, session_factory.create_cnt());  // +1 from new connection to
                                                // localhost:3320 (instance-2)
 
   // query_status reported back from instance-1
   EXPECT_EQ(3u, cluster.members.size());
-  EXPECT_TRUE(
-      cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
-                                ServerRole::Primary, "localhost", 3310, 33100},
-                cluster.members.at(0)));
-  EXPECT_TRUE(cmp_mi_FI(
-      ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
-                      ServerRole::Secondary, "localhost", 3320, 33200},
-      cluster.members.at(1)));
-  EXPECT_TRUE(cmp_mi_FI(
-      ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
-                      ServerRole::Secondary, "localhost", 3330, 33300},
-      cluster.members.at(2)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
+                                        "localhost", 3310, 33100},
+                        cluster.members.at(0)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
+                                        "localhost", 3320, 33200},
+                        cluster.members.at(1)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
+                                        "localhost", 3330, 33300},
+                        cluster.members.at(2)));
 }
 
 /**
@@ -1972,7 +1886,9 @@ TEST_F(MetadataTest, UpdateClusterStatus_Status_FailQueryOnAllNodes) {
   // replicaset.members
   ManagedCluster cluster = typical_cluster;
   metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-  metadata.update_cluster_status(cluster);
+  metadata.update_cluster_status(
+      {mysqlrouter::TargetCluster::TargetType::ByName, "cluster_name"},
+      cluster);
   EXPECT_TRUE(cluster.members.empty());
 
   EXPECT_EQ(3, session_factory.create_cnt());  // +2 from new connections to
@@ -2019,7 +1935,9 @@ TEST_F(MetadataTest, UpdateClusterStatus_SimpleSunnyDayScenario) {
 
   ManagedCluster cluster = typical_cluster;
   metadata.reset_metadata_backend(mysqlrouter::ClusterType::GR_V1);
-  metadata.update_cluster_status(cluster);
+  metadata.update_cluster_status(
+      {mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name"},
+      cluster);
 
   EXPECT_EQ(
       1,
@@ -2027,18 +1945,15 @@ TEST_F(MetadataTest, UpdateClusterStatus_SimpleSunnyDayScenario) {
 
   // query_status reported back from instance-1
   EXPECT_EQ(3u, cluster.members.size());
-  EXPECT_TRUE(
-      cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
-                                ServerRole::Primary, "localhost", 3310, 33100},
-                cluster.members.at(0)));
-  EXPECT_TRUE(cmp_mi_FI(
-      ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
-                      ServerRole::Secondary, "localhost", 3320, 33200},
-      cluster.members.at(1)));
-  EXPECT_TRUE(cmp_mi_FI(
-      ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
-                      ServerRole::Secondary, "localhost", 3330, 33300},
-      cluster.members.at(2)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
+                                        "localhost", 3310, 33100},
+                        cluster.members.at(0)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
+                                        "localhost", 3320, 33200},
+                        cluster.members.at(1)));
+  EXPECT_TRUE(cmp_mi_FI(ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
+                                        "localhost", 3330, 33300},
+                        cluster.members.at(2)));
 }
 
 ////////////////////////////////////////////////////////////////////////////////
@@ -2081,12 +1996,9 @@ TEST_F(MetadataTest, FetchInstances_ok) {
                                    const MySQLSession::FieldValidator &) {
     session_factory.get(0).query_impl(
         processor, {
-                       {"cluster-id", "cluster-name", "", "instance-1",
-                        "localhost:3310", nullptr},
-                       {"cluster-id", "cluster-name", "", "instance-2",
-                        "localhost:3320", nullptr},
-                       {"cluster-id", "cluster-name", "", "instance-3",
-                        "localhost:3330", nullptr},
+                       {"", "instance-1", "localhost:3310", nullptr},
+                       {"", "instance-2", "localhost:3320", nullptr},
+                       {"", "instance-3", "localhost:3330", nullptr},
                    });
   };
   EXPECT_CALL(session_factory.get(session),
@@ -2110,29 +2022,27 @@ TEST_F(MetadataTest, FetchInstances_ok) {
     auto target_cluster = mysqlrouter::TargetCluster(
         mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name");
     EXPECT_CALL(session_factory.get(session), flag_succeed(_, 3310));
-    const auto res = metadata.fetch_cluster_topology(
-        terminated, target_cluster, 0, metadata_servers, true, "gr-id", "",
-        false, instance_id);
+    const auto res = metadata.fetch_cluster_topology(terminated, target_cluster,
+                                                     0, metadata_servers, true,
+                                                     "gr-id", "", instance_id);
 
     EXPECT_TRUE(res);
     EXPECT_EQ(0u, instance_id);
     const auto topology = res.value();
 
-    EXPECT_EQ(1u, topology.clusters_data.size());
-    const auto &cluster = topology.clusters_data[0];
-    EXPECT_EQ(3u, cluster.members.size());
-    EXPECT_TRUE(cmp_mi_FI(
-        ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
-                        ServerRole::Primary, "localhost", 3310, 33100},
-        cluster.members.at(0)));
-    EXPECT_TRUE(cmp_mi_FI(
-        ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
-                        ServerRole::Secondary, "localhost", 3320, 33200},
-        cluster.members.at(1)));
-    EXPECT_TRUE(cmp_mi_FI(
-        ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
-                        ServerRole::Secondary, "localhost", 3330, 33300},
-        cluster.members.at(2)));
+    EXPECT_EQ(3u, topology.cluster_data.members.size());
+    EXPECT_TRUE(
+        cmp_mi_FI(ManagedInstance{GR, "instance-1", ServerMode::ReadWrite,
+                                  "localhost", 3310, 33100},
+                  topology.cluster_data.members.at(0)));
+    EXPECT_TRUE(
+        cmp_mi_FI(ManagedInstance{GR, "instance-2", ServerMode::ReadOnly,
+                                  "localhost", 3320, 33200},
+                  topology.cluster_data.members.at(1)));
+    EXPECT_TRUE(
+        cmp_mi_FI(ManagedInstance{GR, "instance-3", ServerMode::ReadOnly,
+                                  "localhost", 3330, 33300},
+                  topology.cluster_data.members.at(2)));
   });
 }
 
@@ -2164,12 +2074,9 @@ TEST_F(MetadataTest, FetchInstances_fail) {
                                    const MySQLSession::FieldValidator &) {
     session_factory.get(0).query_impl(
         processor, {
-                       {"cluster-id", "cluster-name", "", "instance-1",
-                        "localhost:3310", nullptr},
-                       {"cluster-id", "cluster-name", "", "instance-2",
-                        "localhost:3320", nullptr},
-                       {"cluster-id", "cluster-name", "", "instance-3",
-                        "localhost:3330", nullptr},
+                       {"", "instance-1", "localhost:3310", nullptr},
+                       {"", "instance-2", "localhost:3320", nullptr},
+                       {"", "instance-3", "localhost:3330", nullptr},
                    });
   };
   EXPECT_CALL(session_factory.get(session),
@@ -2200,16 +2107,15 @@ TEST_F(MetadataTest, FetchInstances_fail) {
     std::atomic<bool> terminated{false};
     auto target_cluster = mysqlrouter::TargetCluster(
         mysqlrouter::TargetCluster::TargetType::ByName, "cluster-name");
-    const auto res = metadata.fetch_cluster_topology(
-        terminated, target_cluster, 0, metadata_servers, true, "gr-id", "",
-        false, instance_id);
+    const auto res = metadata.fetch_cluster_topology(terminated, target_cluster,
+                                                     0, metadata_servers, true,
+                                                     "gr-id", "", instance_id);
 
     EXPECT_TRUE(res);
     EXPECT_EQ(0u, instance_id);
     const auto topology = res.value();
 
-    ASSERT_EQ(1u, topology.clusters_data.size());
-    EXPECT_EQ(0u, topology.clusters_data[0].members.size());
+    EXPECT_EQ(0u, topology.cluster_data.members.size());
   });
 }
 
diff --git a/router/src/metadata_cache/tests/test_metadata_cache.cc b/router/src/metadata_cache/tests/test_metadata_cache.cc
index 453cdde0467..8cc2ff465a0 100644
--- a/router/src/metadata_cache/tests/test_metadata_cache.cc
+++ b/router/src/metadata_cache/tests/test_metadata_cache.cc
@@ -128,8 +128,7 @@ class MetadataCacheTest2 : public ::testing::Test {
                      });
 
     m.expect_query(
-        "SELECT F.cluster_id, F.cluster_name, R.replicaset_name, "
-        "I.mysql_server_uuid, "
+        "SELECT R.replicaset_name, I.mysql_server_uuid, "
         "I.addresses->>'$.mysqlClassic', I.addresses->>'$.mysqlX' FROM "
         "mysql_innodb_cluster_metadata.clusters "
         "AS F JOIN mysql_innodb_cluster_metadata.replicasets AS R ON "
@@ -138,19 +137,16 @@ class MetadataCacheTest2 : public ::testing::Test {
         "= I.replicaset_id WHERE F.cluster_name = 'cluster-1' "
         "AND R.attributes->>'$.group_replication_group_name' = '0000-0001'");
     m.then_return(
-        5,
-        {// cluster_id, cluster_name, replicaset_name, mysql_server_uuid,
+        8,
+        {// replicaset_name, mysql_server_uuid,
          // I.addresses->>'$.mysqlClassic', I.addresses->>'$.mysqlX'
-         {m.string_or_null("cluster-id-1"), m.string_or_null("cluster-1"),
-          m.string_or_null("default"), m.string_or_null("uuid-server1"),
+         {m.string_or_null("cluster-1"), m.string_or_null("uuid-server1"),
           m.string_or_null("localhost:3000"),
           m.string_or_null("localhost:30000")},
-         {m.string_or_null("cluster-id-1"), m.string_or_null("cluster-1"),
-          m.string_or_null("default"), m.string_or_null("uuid-server2"),
+         {m.string_or_null("cluster-1"), m.string_or_null("uuid-server2"),
           m.string_or_null("localhost:3001"),
           m.string_or_null("localhost:30010")},
-         {m.string_or_null("cluster-id-1"), m.string_or_null("cluster-1"),
-          m.string_or_null("default"), m.string_or_null("uuid-server3"),
+         {m.string_or_null("cluster-1"), m.string_or_null("uuid-server3"),
           m.string_or_null("localhost:3002"),
           m.string_or_null("localhost:30020")}});
 
diff --git a/router/src/rest_metadata_cache/src/rest_clusters_nodes.cc b/router/src/rest_metadata_cache/src/rest_clusters_nodes.cc
index af4c6e3c2fd..17b621f7ad0 100644
--- a/router/src/rest_metadata_cache/src/rest_clusters_nodes.cc
+++ b/router/src/rest_metadata_cache/src/rest_clusters_nodes.cc
@@ -58,12 +58,12 @@ bool RestClustersNodes::on_handle_request(
   {
     rapidjson::Document::AllocatorType &allocator = json_doc.GetAllocator();
 
-    const auto &res =
+    metadata_cache::LookupResult res =
         metadata_cache::MetadataCacheAPI::instance()->get_cluster_nodes();
 
     rapidjson::Value items(rapidjson::kArrayType);
 
-    for (auto &inst : res) {
+    for (auto &inst : res.instance_vector) {
       rapidjson::Value o(rapidjson::kObjectType);
 
       o.AddMember("replicasetName",
diff --git a/router/src/rest_metadata_cache/src/rest_metadata_cache_config.cc b/router/src/rest_metadata_cache/src/rest_metadata_cache_config.cc
index 0d89c0745f9..a34165afe28 100644
--- a/router/src/rest_metadata_cache/src/rest_metadata_cache_config.cc
+++ b/router/src/rest_metadata_cache/src/rest_metadata_cache_config.cc
@@ -40,32 +40,10 @@ static rapidjson::Value json_value_from_string(const std::string &s,
   return {s.data(), s.size(), allocator};
 }
 
-bool handle_params(HttpRequest &req) {
-  auto md_api = metadata_cache::MetadataCacheAPI::instance();
-
-  if (!req.get_uri().get_query().empty()) {
-    const auto q = req.get_uri().get_query();
-    if (q == "fetchWholeTopology=1") {
-      md_api->fetch_whole_topology(true);
-    } else if (q == "fetchWholeTopology=0") {
-      md_api->fetch_whole_topology(false);
-    } else {
-      send_rfc7807_error(req, HttpStatusCode::BadRequest,
-                         {
-                             {"title", "validation error"},
-                             {"detail", "unsupported parameter"},
-                         });
-    }
-    return true;
-  }
-
-  return true;
-}
-
 bool RestMetadataCacheConfig::on_handle_request(
     HttpRequest &req, const std::string & /* base_path */,
     const std::vector<std::string> &path_matches) {
-  if (!handle_params(req)) return true;
+  if (!ensure_no_params(req)) return true;
 
   if (path_matches[1] !=
       metadata_cache::MetadataCacheAPI::instance()->instance_name()) {
@@ -85,7 +63,7 @@ bool RestMetadataCacheConfig::on_handle_request(
 
     rapidjson::Value members(rapidjson::kArrayType);
 
-    for (auto &member : group_members) {
+    for (auto &member : group_members.instance_vector) {
       members.PushBack(
           rapidjson::Value(rapidjson::kObjectType)
               .AddMember("hostname",
diff --git a/router/src/router/src/cluster_metadata.cc b/router/src/router/src/cluster_metadata.cc
index 47478673244..07531ddce7a 100644
--- a/router/src/router/src/cluster_metadata.cc
+++ b/router/src/router/src/cluster_metadata.cc
@@ -938,14 +938,12 @@ static std::vector<std::string> do_get_routing_mode_queries(
     const std::string &cluster_name) {
   const std::string fetch_instances_query =
       metadata_v2
-          ? "select C.cluster_id, C.cluster_name, I.mysql_server_uuid, "
-            "I.endpoint, I.xendpoint, I.attributes "
+          ? "select I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes "
             "from mysql_innodb_cluster_metadata.v2_instances I join "
             "mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = "
             "C.cluster_id where C.cluster_name = " +
                 mysql->quote(cluster_name)
-          : "SELECT F.cluster_name, R.replicaset_name, I.mysql_server_uuid, "
-            "I.role, "
+          : "SELECT R.replicaset_name, I.mysql_server_uuid, I.role, "
             "I.addresses->>'$.mysqlClassic', "
             "I.addresses->>'$.mysqlX' "
             "FROM mysql_innodb_cluster_metadata.clusters AS F "
@@ -1038,8 +1036,7 @@ std::vector<std::string> ClusterMetadataAR::get_routing_mode_queries(
     const std::string &cluster_name) {
   return {
       // source: ClusterMetadata::fetch_instances_from_metadata_server()
-      "select C.cluster_id, C.cluster_name, I.mysql_server_uuid, I.endpoint, "
-      "I.xendpoint, I.attributes from "
+      "select I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes from "
       "mysql_innodb_cluster_metadata.v2_instances I join "
       "mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = "
       "C.cluster_id where C.cluster_name = " +
diff --git a/router/src/routing/src/dest_metadata_cache.cc b/router/src/routing/src/dest_metadata_cache.cc
index 0b1c1023c62..0bd82c8a321 100644
--- a/router/src/routing/src/dest_metadata_cache.cc
+++ b/router/src/routing/src/dest_metadata_cache.cc
@@ -228,17 +228,18 @@ DestMetadataCacheGroup::DestMetadataCacheGroup(
 #endif
 
 std::pair<AllowedNodes, bool> DestMetadataCacheGroup::get_available(
-    const metadata_cache::cluster_nodes_list_t &instances,
+    const metadata_cache::LookupResult &managed_servers,
     bool for_new_connections) const {
   AllowedNodes result;
 
   bool primary_fallback{false};
+  const auto &managed_servers_vec = managed_servers.instance_vector;
   if (routing_strategy_ == routing::RoutingStrategy::kRoundRobinWithFallback) {
     // if there are no secondaries available we fall-back to primaries
     std::lock_guard<std::mutex> lock(
         query_quarantined_destinations_callback_mtx_);
     auto secondary = std::find_if(
-        instances.begin(), instances.end(),
+        managed_servers_vec.begin(), managed_servers_vec.end(),
         [&](const metadata_cache::ManagedInstance &i) {
           if (for_new_connections && query_quarantined_destinations_callback_) {
             return i.mode == metadata_cache::ServerMode::ReadOnly &&
@@ -248,7 +249,7 @@ std::pair<AllowedNodes, bool> DestMetadataCacheGroup::get_available(
           }
         });
 
-    primary_fallback = secondary == instances.end();
+    primary_fallback = secondary == managed_servers_vec.end();
   }
   // if we are gathering the nodes for the decision about keeping existing
   // connections we look also at the disconnect_on_promoted_to_primary_ setting
@@ -258,7 +259,7 @@ std::pair<AllowedNodes, bool> DestMetadataCacheGroup::get_available(
     primary_fallback = true;
   }
 
-  for (const auto &it : instances) {
+  for (const auto &it : managed_servers_vec) {
     if (for_new_connections) {
       // for new connections skip (do not include) the node if it is hidden - it
       // is not allowed
@@ -301,10 +302,11 @@ std::pair<AllowedNodes, bool> DestMetadataCacheGroup::get_available(
 }
 
 AllowedNodes DestMetadataCacheGroup::get_available_primaries(
-    const metadata_cache::cluster_nodes_list_t &managed_servers) const {
+    const metadata_cache::LookupResult &managed_servers) const {
   AllowedNodes result;
+  const auto &managed_servers_vec = managed_servers.instance_vector;
 
-  for (const auto &it : managed_servers) {
+  for (const auto &it : managed_servers_vec) {
     if (it.hidden) continue;
 
     auto port = (protocol_ == Protocol::Type::kXProtocol) ? it.xport : it.port;
@@ -624,7 +626,8 @@ Destinations DestMetadataCacheGroup::destinations() {
 
   AllowedNodes available;
   bool primary_failover;
-  const auto &all_replicaset_nodes = cache_api_->get_cluster_nodes();
+  const auto &all_replicaset_nodes =
+      cache_api_->get_cluster_nodes().instance_vector;
 
   std::tie(available, primary_failover) = get_available(all_replicaset_nodes);
 
@@ -634,7 +637,8 @@ Destinations DestMetadataCacheGroup::destinations() {
 Destinations DestMetadataCacheGroup::primary_destinations() {
   if (!cache_api_->is_initialized()) return {};
 
-  const auto &all_replicaset_nodes = cache_api_->get_cluster_nodes();
+  const auto &all_replicaset_nodes =
+      cache_api_->get_cluster_nodes().instance_vector;
 
   auto available = get_available_primaries(all_replicaset_nodes);
 
@@ -646,7 +650,8 @@ DestMetadataCacheGroup::AddrVector DestMetadataCacheGroup::get_destinations()
   // don't call lookup if the cache-api is not ready yet.
   if (!cache_api_->is_initialized()) return {};
 
-  auto available = get_available(cache_api_->get_cluster_nodes()).first;
+  auto available =
+      get_available(cache_api_->get_cluster_nodes().instance_vector).first;
 
   AddrVector addresses;
   for (const auto &dest : available) {
@@ -657,7 +662,7 @@ DestMetadataCacheGroup::AddrVector DestMetadataCacheGroup::get_destinations()
 }
 
 void DestMetadataCacheGroup::on_instances_change(
-    const metadata_cache::ClusterTopology &cluster_topology,
+    const metadata_cache::LookupResult &instances,
     const bool md_servers_reachable) {
   // we got notified that the metadata has changed.
   // If instances is empty then (most like is empty)
@@ -668,7 +673,6 @@ void DestMetadataCacheGroup::on_instances_change(
   const bool disconnect =
       md_servers_reachable || disconnect_on_metadata_unavailable_;
 
-  const auto instances = cluster_topology.get_all_members();
   const std::string reason =
       md_servers_reachable ? "metadata change" : "metadata unavailable";
 
@@ -689,13 +693,14 @@ void DestMetadataCacheGroup::on_instances_change(
 }
 
 void DestMetadataCacheGroup::notify_instances_changed(
-    const metadata_cache::ClusterTopology &cluster_topology,
+    const metadata_cache::LookupResult &instances,
+    const metadata_cache::metadata_servers_list_t & /*metadata_servers*/,
     const bool md_servers_reachable, const uint64_t /*view_id*/) noexcept {
-  on_instances_change(cluster_topology, md_servers_reachable);
+  on_instances_change(instances, md_servers_reachable);
 }
 
 bool DestMetadataCacheGroup::update_socket_acceptor_state(
-    const metadata_cache::cluster_nodes_list_t &instances) noexcept {
+    const metadata_cache::LookupResult &instances) noexcept {
   const auto &nodes_for_new_connections =
       get_available(instances, /*for_new_connections=*/true).first;
 
@@ -718,9 +723,7 @@ bool DestMetadataCacheGroup::update_socket_acceptor_state(
 }
 
 void DestMetadataCacheGroup::on_md_refresh(
-    const bool nodes_changed,
-    const metadata_cache::ClusterTopology &cluster_topology) {
-  const auto instances = cluster_topology.get_all_members();
+    const bool nodes_changed, const metadata_cache::LookupResult &instances) {
   const auto &available_nodes =
       get_available(instances, /*for_new_connections=*/true).first;
   std::lock_guard<std::mutex> lock(md_refresh_callback_mtx_);
diff --git a/router/src/routing/src/dest_metadata_cache.h b/router/src/routing/src/dest_metadata_cache.h
index 197a47d7df1..a7f7f3bf0d3 100644
--- a/router/src/routing/src/dest_metadata_cache.h
+++ b/router/src/routing/src/dest_metadata_cache.h
@@ -158,11 +158,11 @@ class DestMetadataCacheGroup final
    *
    */
   std::pair<AllowedNodes, bool> get_available(
-      const metadata_cache::cluster_nodes_list_t &instances,
+      const metadata_cache::LookupResult &managed_servers,
       bool for_new_connections = true) const;
 
   AllowedNodes get_available_primaries(
-      const metadata_cache::cluster_nodes_list_t &managed_servers) const;
+      const metadata_cache::LookupResult &managed_servers) const;
 
   Destinations balance(const AllowedNodes &all_replicaset_nodes,
                        bool primary_fallback);
@@ -180,24 +180,23 @@ class DestMetadataCacheGroup final
   bool disconnect_on_promoted_to_primary_{false};
   bool disconnect_on_metadata_unavailable_{false};
 
-  void on_instances_change(
-      const metadata_cache::ClusterTopology &cluster_topology,
-      const bool md_servers_reachable);
+  void on_instances_change(const metadata_cache::LookupResult &instances,
+                           const bool md_servers_reachable);
   void subscribe_for_metadata_cache_changes();
   void subscribe_for_acceptor_handler();
   void subscribe_for_md_refresh_handler();
 
   void notify_instances_changed(
-      const metadata_cache::ClusterTopology &cluster_topology,
+      const metadata_cache::LookupResult &instances,
+      const metadata_cache::metadata_servers_list_t &metadata_servers,
       const bool md_servers_reachable,
       const uint64_t /*view_id*/) noexcept override;
 
   bool update_socket_acceptor_state(
-      const metadata_cache::cluster_nodes_list_t &instances) noexcept override;
+      const metadata_cache::LookupResult &instances) noexcept override;
 
-  void on_md_refresh(
-      const bool instances_changed,
-      const metadata_cache::ClusterTopology &cluster_topology) override;
+  void on_md_refresh(const bool instances_changed,
+                     const metadata_cache::LookupResult &instances) override;
 
   // MUST take the RouteDestination Mutex
   size_t start_pos_{};
diff --git a/router/src/routing/tests/test_metadata_cache_group.cc b/router/src/routing/tests/test_metadata_cache_group.cc
index dad315b65cc..3a7233bfa08 100644
--- a/router/src/routing/tests/test_metadata_cache_group.cc
+++ b/router/src/routing/tests/test_metadata_cache_group.cc
@@ -37,8 +37,8 @@
 #include "tcp_address.h"
 #include "test/helpers.h"  // init_test_logger
 
+using metadata_cache::LookupResult;
 using metadata_cache::ServerMode;
-using metadata_cache::ServerRole;
 using InstanceVector = std::vector<metadata_cache::ManagedInstance>;
 
 using ::testing::_;
@@ -77,14 +77,8 @@ MATCHER(IsGoodEq, "") {
 
 class MetadataCacheAPIStub : public metadata_cache::MetadataCacheAPIBase {
  public:
-  metadata_cache::cluster_nodes_list_t get_cluster_nodes() override {
-    if (cluster_topology_.clusters_data.size() == 0) return {};
-
-    return cluster_topology_.clusters_data[0].members;
-  }
-
-  metadata_cache::ClusterTopology get_cluster_topology() override {
-    return cluster_topology_;
+  LookupResult get_cluster_nodes() override {
+    return LookupResult(instance_vector_);
   }
 
   void add_state_listener(
@@ -145,9 +139,6 @@ class MetadataCacheAPIStub : public metadata_cache::MetadataCacheAPIBase {
 
   void cache_stop() noexcept override {}  // no easy way to mock noexcept method
   bool is_initialized() noexcept override { return true; }
-  bool fetch_whole_topology() const override { return false; }
-
-  void fetch_whole_topology(bool /*val*/) override {}
 
   void instance_name(const std::string &) override {}
   std::string instance_name() const override { return "foo"; }
@@ -162,28 +153,22 @@ class MetadataCacheAPIStub : public metadata_cache::MetadataCacheAPIBase {
   MOCK_METHOD1(set_instance_factory, void(metadata_factory_t cb));
 
  public:
-  void fill_instance_vector(const InstanceVector &iv) {
-    metadata_cache::metadata_servers_list_t md_servers;
-    for (const auto &instance : iv) {
-      md_servers.emplace_back(instance.host, instance.port);
-    }
-
-    metadata_cache::ManagedCluster cluster{"cluster-uuid", "cluster-name", iv,
-                                           true};
-
-    cluster_topology_ =
-        metadata_cache::ClusterTopology{{cluster}, 0, md_servers};
-  }
+  void fill_instance_vector(const InstanceVector &iv) { instance_vector_ = iv; }
 
   void trigger_instances_change_callback(
       const bool md_servers_reachable = true) {
     if (!instances_change_listener_) return;
 
+    metadata_cache::metadata_servers_list_t md_servers;
+    for (const auto &instance : instance_vector_) {
+      md_servers.push_back({instance.host, instance.port});
+    }
+
     instances_change_listener_->notify_instances_changed(
-        cluster_topology_, md_servers_reachable, 0);
+        instance_vector_, md_servers, md_servers_reachable, 0);
   }
 
-  metadata_cache::ClusterTopology cluster_topology_;
+  std::vector<metadata_cache::ManagedInstance> instance_vector_;
   metadata_cache::ClusterStateListenerInterface *instances_change_listener_{
       nullptr};
 };
@@ -210,12 +195,9 @@ TEST_F(DestMetadataCacheTest, StrategyFirstAvailableOnPrimaries) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   {
@@ -243,12 +225,9 @@ TEST_F(DestMetadataCacheTest, StrategyFirstAvailableOnSinglePrimary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // only one PRIMARY
@@ -275,12 +254,9 @@ TEST_F(DestMetadataCacheTest, StrategyFirstAvailableOnNoPrimary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3306", 3306,
-       33060},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3306", 3306, 33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // no PRIMARY
@@ -305,12 +281,9 @@ TEST_F(DestMetadataCacheTest, StrategyFirstAvailableOnSecondaries) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // two SECONDARY's
@@ -339,12 +312,9 @@ TEST_F(DestMetadataCacheTest, StrategyFirstAvailableOnSingleSecondary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // one SECONDARY
@@ -371,12 +341,9 @@ TEST_F(DestMetadataCacheTest, StrategyFirstAvailableOnNoSecondary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid3", ServerMode::ReadWrite, ServerRole::Primary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid3", metadata_cache::ServerMode::ReadWrite, "3308", 3308, 33062},
   });
 
   // no SECONDARY
@@ -402,12 +369,9 @@ TEST_F(DestMetadataCacheTest, StrategyFirstAvailablePrimaryAndSecondary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // all nodes
@@ -438,12 +402,10 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinWithFallbackUnavailableServer) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::Unavailable, ServerRole::Unavailable, "3306",
-       3306, 33060},
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::Unavailable, "3306", 3306,
+       33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3308", 3308, 33062},
   });
 
   // all available nodes
@@ -483,14 +445,10 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinOnPrimaries) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid3", ServerMode::ReadWrite, ServerRole::Primary, "3308", 3308,
-       33062},
-      {GR, "uuid4", ServerMode::ReadOnly, ServerRole::Secondary, "3309", 3309,
-       33063},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid3", metadata_cache::ServerMode::ReadWrite, "3308", 3308, 33062},
+      {GR, "uuid4", metadata_cache::ServerMode::ReadOnly, "3309", 3309, 33063},
   });
 
   // all PRIMARY nodes
@@ -539,12 +497,9 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinOnSinglePrimary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // the one PRIMARY nodes
@@ -571,10 +526,8 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinPrimaryMissing) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // no PRIMARY nodes
@@ -599,14 +552,10 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinOnSecondaries) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid3", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
-      {GR, "uuid4", ServerMode::ReadOnly, ServerRole::Secondary, "3309", 3309,
-       33063},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid3", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
+      {GR, "uuid4", metadata_cache::ServerMode::ReadOnly, "3309", 3309, 33063},
   });
 
   // all SECONDARY nodes
@@ -655,12 +604,9 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinOnSingleSecondary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // the one SECONDARY nodes
@@ -687,10 +633,8 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinSecondaryMissing) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid2", ServerMode::ReadWrite, ServerRole::Primary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadWrite, "3308", 3308, 33062},
   });
 
   // no SECONDARY nodes
@@ -716,12 +660,9 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinPrimaryAndSecondary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
-      {GR, "uuid3", ServerMode::ReadOnly, ServerRole::Secondary, "3309", 3309,
-       33063},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
+      {GR, "uuid3", metadata_cache::ServerMode::ReadOnly, "3309", 3309, 33063},
   });
 
   // all nodes
@@ -773,12 +714,9 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinWithFallbackBasicScenario) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid3", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid3", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // we have 2 SECONDARIES up so we expect round robin on them
@@ -815,12 +753,9 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinWithFallbackSingleSecondary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
-      {GR, "uuid3", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
+      {GR, "uuid3", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // we do not fallback to PRIMARIES as long as there is at least single
@@ -848,10 +783,8 @@ TEST_F(DestMetadataCacheTest, StrategyRoundRobinWithFallbackNoSecondary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
   });
 
   // no SECONDARY available so we expect round-robin on PRIAMRIES
@@ -900,12 +833,9 @@ TEST_F(DestMetadataCacheTest, AllowPrimaryReadsBasic) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // we expect round-robin on all the servers (PRIMARY and SECONDARY)
@@ -955,8 +885,7 @@ TEST_F(DestMetadataCacheTest, AllowPrimaryReadsNoSecondary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
   });
 
   // we expect the PRIMARY being used
@@ -986,10 +915,8 @@ TEST_F(DestMetadataCacheTest, PrimaryDefault) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadWrite, ServerRole::Primary, "3307", 3307,
-       33061},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadWrite, "3307", 3307, 33061},
   });
 
   // default for PRIMARY should be round-robin on ReadWrite servers
@@ -1026,12 +953,9 @@ TEST_F(DestMetadataCacheTest, SecondaryDefault) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid3", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid3", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // default for SECONDARY should be round-robin on ReadOnly servers
@@ -1069,12 +993,9 @@ TEST_F(DestMetadataCacheTest, PrimaryAndSecondaryDefault) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33061},
-      {GR, "uuid3", ServerMode::ReadOnly, ServerRole::Secondary, "3308", 3308,
-       33062},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33061},
+      {GR, "uuid3", metadata_cache::ServerMode::ReadOnly, "3308", 3308, 33062},
   });
 
   // default for PRIMARY_AND_SECONDARY should be round-robin on ReadOnly and
@@ -1133,10 +1054,8 @@ TEST_F(DestMetadataCacheTest, AllowedNodesNoPrimary) {
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33070},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33070},
   });
 
   EXPECT_CALL(metadata_cache_api_, add_acceptor_handler_listener(_));
@@ -1145,10 +1064,8 @@ TEST_F(DestMetadataCacheTest, AllowedNodesNoPrimary) {
 
   // new metadata - no primary
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadOnly, ServerRole::Secondary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33070},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadOnly, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33070},
   });
 
   bool callback_called{false};
@@ -1183,10 +1100,8 @@ TEST_F(DestMetadataCacheTest, AllowedNodes2Primaries) {
       &metadata_cache_api_);
 
   InstanceVector instances{
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33070},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33070},
   };
 
   fill_instance_vector(instances);
@@ -1241,10 +1156,8 @@ TEST_F(DestMetadataCacheTest, AllowedNodesNoSecondaries) {
       &metadata_cache_api_);
 
   InstanceVector instances{
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33070},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33070},
   };
 
   fill_instance_vector(instances);
@@ -1297,10 +1210,8 @@ TEST_F(DestMetadataCacheTest, AllowedNodesSecondaryDisconnectToPromoted) {
       &metadata_cache_api_);
 
   InstanceVector instances{
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33070},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33070},
   };
 
   fill_instance_vector(instances);
@@ -1358,10 +1269,8 @@ TEST_F(DestMetadataCacheTest, AllowedNodesSecondaryDisconnectToPromotedTwice) {
       &metadata_cache_api_);
 
   InstanceVector instances{
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33070},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33070},
   };
 
   fill_instance_vector(instances);
@@ -1410,10 +1319,8 @@ TEST_F(DestMetadataCacheTest,
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33070},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33070},
   });
 
   EXPECT_CALL(metadata_cache_api_, add_acceptor_handler_listener(_));
@@ -1462,10 +1369,8 @@ TEST_F(DestMetadataCacheTest,
       &metadata_cache_api_);
 
   fill_instance_vector({
-      {GR, "uuid1", ServerMode::ReadWrite, ServerRole::Primary, "3306", 3306,
-       33060},
-      {GR, "uuid2", ServerMode::ReadOnly, ServerRole::Secondary, "3307", 3307,
-       33070},
+      {GR, "uuid1", metadata_cache::ServerMode::ReadWrite, "3306", 3306, 33060},
+      {GR, "uuid2", metadata_cache::ServerMode::ReadOnly, "3307", 3307, 33070},
   });
 
   EXPECT_CALL(metadata_cache_api_, add_acceptor_handler_listener(_));
diff --git a/router/tests/component/data/bootstrap_access_error_at_grant.js b/router/tests/component/data/bootstrap_access_error_at_grant.js
index c2ac9d1291a..1e81366d369 100644
--- a/router/tests/component/data/bootstrap_access_error_at_grant.js
+++ b/router/tests/component/data/bootstrap_access_error_at_grant.js
@@ -3,7 +3,7 @@ var common_stmts = require("common_statements");
 var options = {
   cluster_type: "gr",
 
-  innodb_cluster_name: "mycluster",
+  innodb_cluster_name: "my-cluster",
   innodb_cluster_instances:
       [["localhost", 5500], ["localhost", 5510], ["localhost", 5520]],
 };
diff --git a/router/tests/component/data/bootstrap_account_host_pattern_too_long.js b/router/tests/component/data/bootstrap_account_host_pattern_too_long.js
index f070cb70e8b..160f209be8b 100644
--- a/router/tests/component/data/bootstrap_account_host_pattern_too_long.js
+++ b/router/tests/component/data/bootstrap_account_host_pattern_too_long.js
@@ -2,7 +2,7 @@ var common_stmts = require("common_statements");
 
 var options = {
   cluster_type: "gr",
-  innodb_cluster_name: "mycluster",
+  innodb_cluster_name: "my-cluster",
   innodb_cluster_instances:
       [["localhost", 5500], ["localhost", 5510], ["localhost", 5520]],
 };
diff --git a/router/tests/component/data/bootstrap_ar.js b/router/tests/component/data/bootstrap_ar.js
index 905e1131e67..01a78a174d0 100644
--- a/router/tests/component/data/bootstrap_ar.js
+++ b/router/tests/component/data/bootstrap_ar.js
@@ -3,7 +3,7 @@ var common_stmts = require("common_statements");
 var options = {
   cluster_type: "ar",
 
-  innodb_cluster_name: "mycluster",
+  innodb_cluster_name: "my-cluster",
   innodb_cluster_instances:
       [["localhost", 5500], ["localhost", 5510], ["localhost", 5520]],
 };
diff --git a/router/tests/component/data/bootstrap_exec_time_2_seconds.js b/router/tests/component/data/bootstrap_exec_time_2_seconds.js
index bafe2fc7807..c9a0d9e3d83 100644
--- a/router/tests/component/data/bootstrap_exec_time_2_seconds.js
+++ b/router/tests/component/data/bootstrap_exec_time_2_seconds.js
@@ -2,7 +2,7 @@ var common_stmts = require("common_statements");
 
 var options = {
   cluster_type: "gr",
-  innodb_cluster_name: "mycluster",
+  innodb_cluster_name: "my-cluster",
   innodb_cluster_instances:
       [["localhost", 5500], ["localhost", 5510], ["localhost", 5520]],
 };
diff --git a/router/tests/component/data/bootstrap_gr.js b/router/tests/component/data/bootstrap_gr.js
index 94d8e49a0bb..a49881c4ad9 100644
--- a/router/tests/component/data/bootstrap_gr.js
+++ b/router/tests/component/data/bootstrap_gr.js
@@ -6,21 +6,16 @@ if (mysqld.global.innodb_cluster_instances === undefined) {
 }
 
 if (mysqld.global.cluster_name == undefined) {
-  mysqld.global.cluster_name = "mycluster";
+  mysqld.global.cluster_name = "my-cluster";
 }
 
 if (mysqld.global.metadata_version === undefined) {
   mysqld.global.metadata_version = [2, 0, 3];
 }
 
-if (mysqld.global.gr_id === undefined) {
-  mysqld.global.gr_id = "cluster-specific-id";
-}
-
 var options = {
   metadata_schema_version: mysqld.global.metadata_version,
   cluster_type: "gr",
-  group_replication_name: mysqld.global.gr_id,
   clusterset_present: 0,
   innodb_cluster_name: mysqld.global.cluster_name,
   innodb_cluster_instances: mysqld.global.innodb_cluster_instances,
diff --git a/router/tests/component/data/bootstrap_gr_dup_router.js b/router/tests/component/data/bootstrap_gr_dup_router.js
index b5978d34071..13e3352ff47 100644
--- a/router/tests/component/data/bootstrap_gr_dup_router.js
+++ b/router/tests/component/data/bootstrap_gr_dup_router.js
@@ -6,7 +6,7 @@ if (mysqld.global.innodb_cluster_instances === undefined) {
 }
 
 if (mysqld.global.cluster_name == undefined) {
-  mysqld.global.cluster_name = "mycluster";
+  mysqld.global.cluster_name = "my-cluster";
 }
 
 var options = {
diff --git a/router/tests/component/data/bootstrap_gr_v1.js b/router/tests/component/data/bootstrap_gr_v1.js
index fdc4b2c9cde..8f4c1bed2a7 100644
--- a/router/tests/component/data/bootstrap_gr_v1.js
+++ b/router/tests/component/data/bootstrap_gr_v1.js
@@ -3,7 +3,7 @@ var common_stmts = require("common_statements");
 var options = {
   metadata_schema_version: [1, 0, 2],
   cluster_type: "gr",
-  innodb_cluster_name: "mycluster",
+  innodb_cluster_name: "my-cluster",
   innodb_cluster_instances:
       [["localhost", 5500], ["localhost", 5510], ["localhost", 5520]],
 };
diff --git a/router/tests/component/data/bootstrap_report_host.js b/router/tests/component/data/bootstrap_report_host.js
index cb69bf17953..aa0e0e978f5 100644
--- a/router/tests/component/data/bootstrap_report_host.js
+++ b/router/tests/component/data/bootstrap_report_host.js
@@ -2,7 +2,7 @@ var common_stmts = require("common_statements");
 
 var options = {
   cluster_type: "gr",
-  innodb_cluster_name: "mycluster",
+  innodb_cluster_name: "my-cluster",
   innodb_cluster_instances:
       [["localhost", 5500], ["localhost", 5510], ["localhost", 5520]],
   bootstrap_report_host_pattern: "host.foo.bar",
diff --git a/router/tests/component/data/local_modules/common_statements.js b/router/tests/component/data/local_modules/common_statements.js
index 1efae1f684a..46c7fceb015 100644
--- a/router/tests/component/data/local_modules/common_statements.js
+++ b/router/tests/component/data/local_modules/common_statements.js
@@ -11,9 +11,9 @@ var defaults = {
   // - state
   // - xport (if available and needed)
   group_replication_membership: [],
-  group_replication_name: "cluster-specific-id",
+  group_replication_name: "00000000-0000-0000-0000-0000000000g1",
   port: mysqld.session.port,
-  cluster_id: "cluster-specific-id",
+  cluster_id: "00000000-0000-0000-0000-0000000000c1",
   innodb_cluster_name: "test",
   innodb_cluster_replicaset_name: "default",
   use_bootstrap_big_data: false,
@@ -242,7 +242,7 @@ function get_response(stmt_key, options) {
     case "router_select_metadata":
       return {
         stmt:
-            "SELECT F.cluster_id, F.cluster_name, R.replicaset_name, I.mysql_server_uuid, I.addresses->>'$.mysqlClassic', I.addresses->>'$.mysqlX' FROM mysql_innodb_cluster_metadata.clusters AS F JOIN mysql_innodb_cluster_metadata.replicasets AS R ON F.cluster_id = R.cluster_id JOIN mysql_innodb_cluster_metadata.instances AS I" +
+            "SELECT R.replicaset_name, I.mysql_server_uuid, I.addresses->>'$.mysqlClassic', I.addresses->>'$.mysqlX' FROM mysql_innodb_cluster_metadata.clusters AS F JOIN mysql_innodb_cluster_metadata.replicasets AS R ON F.cluster_id = R.cluster_id JOIN mysql_innodb_cluster_metadata.instances AS I" +
             " ON R.replicaset_id = I.replicaset_id WHERE F.cluster_name = '" +
             options.innodb_cluster_name + "'" +
             (options.gr_id === undefined || options.gr_id === "" ?
@@ -251,10 +251,8 @@ function get_response(stmt_key, options) {
                   options.gr_id + "'")),
         result: {
           columns: [
-            {"name": "F.cluster_id", "type": "VAR_STRING"},
-            {"name": "F.cluster_name", "type": "VAR_STRING"},
-            {"name": "R.replicaset_name", "type": "VAR_STRING"},
-            {"name": "I.mysql_server_uuid", "type": "VAR_STRING"},
+            {"name": "replicaset_name", "type": "VAR_STRING"},
+            {"name": "mysql_server_uuid", "type": "VAR_STRING"},
             {"name": "I.addresses->>'$.mysqlClassic'", "type": "LONGBLOB"},
             {"name": "I.addresses->>'$.mysqlX'", "type": "LONGBLOB"}
           ],
@@ -262,7 +260,6 @@ function get_response(stmt_key, options) {
               currentValue) {
             var xport = currentValue[4] === undefined ? 0 : currentValue[4];
             return [
-              options.cluster_id, options.innodb_cluster_name,
               options.innodb_cluster_replicaset_name, currentValue[0],
               currentValue[1] + ":" + currentValue[2],
               currentValue[1] + ":" + xport
@@ -273,16 +270,14 @@ function get_response(stmt_key, options) {
     case "router_select_metadata_v2_gr":
       return {
         stmt:
-            "select C.cluster_id, C.cluster_name, I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes from mysql_innodb_cluster_metadata.v2_instances I join mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = C.cluster_id where C.cluster_name = '" +
+            "select I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes from mysql_innodb_cluster_metadata.v2_instances I join mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = C.cluster_id where C.cluster_name = '" +
             options.innodb_cluster_name + "'" +
             (options.gr_id === undefined || options.gr_id === "" ?
                  "" :
                  (" AND C.group_name = '" + options.gr_id + "'")),
         result: {
           columns: [
-            {"name": "C.cluster_id", "type": "VAR_STRING"},
-            {"name": "C.cluster_name", "type": "VAR_STRING"},
-            {"name": "I.mysql_server_uuid", "type": "VAR_STRING"},
+            {"name": "mysql_server_uuid", "type": "VAR_STRING"},
             {"name": "I.addresses->>'$.mysqlClassic'", "type": "LONGBLOB"},
             {"name": "I.addresses->>'$.mysqlX'", "type": "LONGBLOB"},
             {"name": "I.attributes", "type": "VAR_STRING"}
@@ -293,8 +288,35 @@ function get_response(stmt_key, options) {
             var attributes =
                 currentValue[5] === undefined ? "" : currentValue[5];
             return [
-              options.cluster_id, options.innodb_cluster_name, currentValue[0],
-              currentValue[1] + ":" + currentValue[2],
+              currentValue[0], currentValue[1] + ":" + currentValue[2],
+              currentValue[1] + ":" + xport, attributes
+            ]
+          }),
+        }
+      };
+
+    case "router_select_metadata_v2_gr_by_cluster_id":
+      return {
+        stmt:
+            "select I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes from mysql_innodb_cluster_metadata.v2_instances I join mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = C.cluster_id where C.cluster_id = '" +
+            options.cluster_id + "'" +
+            (options.gr_id === undefined || options.gr_id === "" ?
+                 "" :
+                 (" AND C.group_name = '" + options.gr_id + "'")),
+        result: {
+          columns: [
+            {"name": "mysql_server_uuid", "type": "VAR_STRING"},
+            {"name": "I.addresses->>'$.mysqlClassic'", "type": "LONGBLOB"},
+            {"name": "I.addresses->>'$.mysqlX'", "type": "LONGBLOB"},
+            {"name": "I.attributes", "type": "VAR_STRING"}
+          ],
+          rows: options["group_replication_membership"].map(function(
+              currentValue) {
+            var xport = currentValue[4] === undefined ? 0 : currentValue[4];
+            var attributes =
+                currentValue[5] === undefined ? "" : currentValue[5];
+            return [
+              currentValue[0], currentValue[1] + ":" + currentValue[2],
               currentValue[1] + ":" + xport, attributes
             ]
           }),
@@ -303,15 +325,13 @@ function get_response(stmt_key, options) {
     case "router_select_metadata_v2_ar":
       return {
         stmt:
-            "select C.cluster_id, C.cluster_name, M.member_id, I.endpoint, I.xendpoint, M.member_role, I.attributes from mysql_innodb_cluster_metadata.v2_ar_members M join mysql_innodb_cluster_metadata.v2_instances I on I.instance_id = M.instance_id join mysql_innodb_cluster_metadata.v2_ar_clusters C on I.cluster_id = C.cluster_id" +
+            "select M.member_id, I.endpoint, I.xendpoint, M.member_role, I.attributes from mysql_innodb_cluster_metadata.v2_ar_members M join mysql_innodb_cluster_metadata.v2_instances I on I.instance_id = M.instance_id join mysql_innodb_cluster_metadata.v2_ar_clusters C on I.cluster_id = C.cluster_id" +
             (options.cluster_id === undefined || options.cluster_id === "" ?
                  "" :
                  (" where C.cluster_id = '" + options.cluster_id + "'")),
         result: {
           columns: [
-            {"name": "C.cluster_id", "type": "VAR_STRING"},
-            {"name": "C.cluster_name", "type": "VAR_STRING"},
-            {"name": "M.member_id", "type": "VAR_STRING"},
+            {"name": "member_id", "type": "VAR_STRING"},
             {"name": "I.endpoint", "type": "LONGBLOB"},
             {"name": "I.xendpoint", "type": "LONGBLOB"},
             {"name": "I.member_role", "type": "VAR_STRING"},
@@ -323,8 +343,7 @@ function get_response(stmt_key, options) {
             var attributes =
                 currentValue[5] === undefined ? "" : currentValue[5];
             return [
-              options.cluster_id, options.innodb_cluster_name, currentValue[0],
-              currentValue[1] + ":" + currentValue[2],
+              currentValue[0], currentValue[1] + ":" + currentValue[2],
               currentValue[1] + ":" + xport,
               currentValue[2] === options.primary_port ? "PRIMARY" :
                                                          "SECONDARY",
@@ -1049,7 +1068,7 @@ function get_response(stmt_key, options) {
       return {
         stmt:
             "select I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes, " +
-            "C.cluster_id, C.cluster_name, CSM.member_role, CSM.invalidated, CS.domain_name " +
+            "C.cluster_id, C.cluster_name, CSM.member_role, CSM.invalidated " +
             "from mysql_innodb_cluster_metadata.v2_instances I " +
             "join mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = C.cluster_id join mysql_innodb_cluster_metadata.v2_cs_members CSM " +
             "on CSM.cluster_id = C.cluster_id left join mysql_innodb_cluster_metadata.v2_cs_clustersets CS on CSM.clusterset_id = CS.clusterset_id " +
@@ -1066,7 +1085,6 @@ function get_response(stmt_key, options) {
             {"type": "STRING", "name": "C.cluster_name"},
             {"type": "STRING", "name": "CSM.member_role"},
             {"type": "LONGLONG", "name": "CSM.invalidated"},
-            {"type": "STRING", "name": "CS.domain_name"},
           ],
 
           rows: options.clusterset_data.clusters
@@ -1086,12 +1104,12 @@ function get_response(stmt_key, options) {
                     .map(function(node) {
                       return [
                         node.uuid, node.host + ":" + node.classic_port,
-                        node.host + ":" +
-                            (node.x_port === undefined ? 0 : node.x_port),
+                        node.host + ":" + node.x_port === undefined ?
+                            0 :
+                            node.x_port,
                         "",  // is this ok ?
                         node.cluster_uuid, node.cluster_name, node.cluster_role,
-                        node.cluster_invalid,
-                        options.clusterset_data.clusterset_name
+                        node.cluster_invalid
                       ];
                     })
         }
diff --git a/router/tests/component/data/metadata_clusterset.js b/router/tests/component/data/metadata_clusterset.js
index 33fd7068760..aa41cc4994b 100644
--- a/router/tests/component/data/metadata_clusterset.js
+++ b/router/tests/component/data/metadata_clusterset.js
@@ -93,14 +93,6 @@ var router_update_last_check_in =
     } else if (stmt.match(router_update_attributes.stmt_regex)) {
       mysqld.global.update_attributes_count++;
       return router_update_attributes;
-    } else if (stmt === "set @@mysqlx_wait_timeout = 28800") {
-      return {
-        ok: {}
-      }
-    } else if (stmt === "enable_notices") {
-      return {
-        ok: {}
-      }
     } else {
       return common_stmts.unknown_statement_response(stmt);
     }
diff --git a/router/tests/component/data/metadata_dynamic_nodes_v2_gr.js b/router/tests/component/data/metadata_dynamic_nodes_v2_gr.js
index 3c4b6bcc067..0430657e2fd 100644
--- a/router/tests/component/data/metadata_dynamic_nodes_v2_gr.js
+++ b/router/tests/component/data/metadata_dynamic_nodes_v2_gr.js
@@ -108,6 +108,9 @@ var common_responses_regex = common_stmts.prepare_statement_responses_regex(
 var router_select_metadata =
     common_stmts.get("router_select_metadata_v2_gr", options);
 
+var router_select_metadata_by_cluster_id =
+    common_stmts.get("router_select_metadata_v2_gr_by_cluster_id", options);
+
 var router_start_transaction =
     common_stmts.get("router_start_transaction", options);
 
@@ -131,6 +134,9 @@ var router_start_transaction =
     } else if (stmt === router_select_metadata.stmt) {
       mysqld.global.md_query_count++;
       return router_select_metadata;
+    } else if (stmt === router_select_metadata_by_cluster_id.stmt) {
+      mysqld.global.md_query_count++;
+      return router_select_metadata_by_cluster_id;
     } else if (stmt === "set @@mysqlx_wait_timeout = 28800") {
       if (mysqld.global.mysqlx_wait_timeout_unsupported === 0) return {
           ok: {}
diff --git a/router/tests/component/data/rest_api_enable.js b/router/tests/component/data/rest_api_enable.js
index 76ed72ae574..66a69a04910 100644
--- a/router/tests/component/data/rest_api_enable.js
+++ b/router/tests/component/data/rest_api_enable.js
@@ -51,7 +51,7 @@ var group_replication_membership_online =
 
 var options = {
   cluster_type: "gr",
-  innodb_cluster_name: "mycluster",
+  innodb_cluster_name: "my-cluster",
   innodb_cluster_instances: mysqld.global.innodb_cluster_instances,
   gr_id: mysqld.global.gr_id,
   group_replication_name: mysqld.global.gr_id,
diff --git a/router/tests/component/test_bootstrap.cc b/router/tests/component/test_bootstrap.cc
index 26ad0f336b7..3e723751f23 100644
--- a/router/tests/component/test_bootstrap.cc
+++ b/router/tests/component/test_bootstrap.cc
@@ -120,7 +120,7 @@ router_id=1)";
   // require tons of escaping
   // user=mysql_router1_daxi69tk9btt
   const char *expected_config_gr_part2 =
-      R"(metadata_cluster=mycluster
+      R"(metadata_cluster=my-cluster
 ttl=0.5
 auth_cache_ttl=-1
 auth_cache_refresh_interval=2
@@ -129,28 +129,28 @@ use_gr_notifications=0
 [routing:bootstrap_rw]
 bind_address=0.0.0.0
 bind_port=6446
-destinations=metadata-cache://mycluster/?role=PRIMARY
+destinations=metadata-cache://my-cluster/?role=PRIMARY
 routing_strategy=first-available
 protocol=classic
 
 [routing:bootstrap_ro]
 bind_address=0.0.0.0
 bind_port=6447
-destinations=metadata-cache://mycluster/?role=SECONDARY
+destinations=metadata-cache://my-cluster/?role=SECONDARY
 routing_strategy=round-robin-with-fallback
 protocol=classic
 
 [routing:bootstrap_x_rw]
 bind_address=0.0.0.0
 bind_port=6448
-destinations=metadata-cache://mycluster/?role=PRIMARY
+destinations=metadata-cache://my-cluster/?role=PRIMARY
 routing_strategy=first-available
 protocol=x
 
 [routing:bootstrap_x_ro]
 bind_address=0.0.0.0
 bind_port=6449
-destinations=metadata-cache://mycluster/?role=SECONDARY
+destinations=metadata-cache://my-cluster/?role=SECONDARY
 routing_strategy=round-robin-with-fallback
 protocol=x)";
 
@@ -162,7 +162,7 @@ router_id=1)";
   // require tons of escaping
   // user=mysql_router1_ritc56yrjz42
   const char *expected_config_ar_part2 =
-      R"(metadata_cluster=mycluster
+      R"(metadata_cluster=my-cluster
 ttl=0.5
 auth_cache_ttl=-1
 auth_cache_refresh_interval=2
@@ -170,28 +170,28 @@ auth_cache_refresh_interval=2
 [routing:bootstrap_rw]
 bind_address=0.0.0.0
 bind_port=6446
-destinations=metadata-cache://mycluster/?role=PRIMARY
+destinations=metadata-cache://my-cluster/?role=PRIMARY
 routing_strategy=first-available
 protocol=classic
 
 [routing:bootstrap_ro]
 bind_address=0.0.0.0
 bind_port=6447
-destinations=metadata-cache://mycluster/?role=SECONDARY
+destinations=metadata-cache://my-cluster/?role=SECONDARY
 routing_strategy=round-robin-with-fallback
 protocol=classic
 
 [routing:bootstrap_x_rw]
 bind_address=0.0.0.0
 bind_port=6448
-destinations=metadata-cache://mycluster/?role=PRIMARY
+destinations=metadata-cache://my-cluster/?role=PRIMARY
 routing_strategy=first-available
 protocol=x
 
 [routing:bootstrap_x_ro]
 bind_address=0.0.0.0
 bind_port=6449
-destinations=metadata-cache://mycluster/?role=SECONDARY
+destinations=metadata-cache://my-cluster/?role=SECONDARY
 routing_strategy=round-robin-with-fallback
 protocol=x)";
 
@@ -254,7 +254,7 @@ void check_bind_port(const std::string &conf_file_content,
       "[routing:"s + route_name + "]\n"
       "bind_address=0.0.0.0\n" +
       "bind_port=" + std::to_string(expected_bind_port) + "\n" +
-      "destinations=metadata-cache://mycluster/?role=" +  server_role + "\n" +
+      "destinations=metadata-cache://my-cluster/?role=" +  server_role + "\n" +
       "routing_strategy=" + routing_strategy + "\n" +
       "protocol=" + protocol_name + "\n";
   // clang-format on
@@ -965,16 +965,23 @@ class RouterBootstrapFailoverSuperReadonly
  */
 TEST_P(RouterBootstrapFailoverSuperReadonly, BootstrapFailoverSuperReadonly) {
   const auto param = GetParam();
+  const std::string cluster_type_specific_id =
+      param.cluster_type == ClusterType::RS_V2
+          ? "00000000-0000-0000-0000-0000000000c1"
+          : "00000000-0000-0000-0000-0000000000g1";
 
   std::vector<Config> config{
       {"127.0.0.1", port_pool_.get_next_available(),
        port_pool_.get_next_available(),
-       get_data_dir().join(param.trace_file).str()},
+       get_data_dir().join(param.trace_file).str(), /*unaccessible=*/false,
+       cluster_type_specific_id},
       {"127.0.0.1", port_pool_.get_next_available(),
        port_pool_.get_next_available(),
-       get_data_dir().join(param.trace_file2).str()},
+       get_data_dir().join(param.trace_file2).str(), /*unaccessible=*/false,
+       cluster_type_specific_id},
       {"127.0.0.1", port_pool_.get_next_available(),
-       port_pool_.get_next_available(), ""},
+       port_pool_.get_next_available(), "", /*unaccessible=*/false,
+       cluster_type_specific_id},
   };
 
   ASSERT_NO_FATAL_FAILURE(bootstrap_failover(config, param.cluster_type));
@@ -1023,20 +1030,26 @@ class RouterBootstrapFailoverSuperReadonly2ndNodeDead
 TEST_P(RouterBootstrapFailoverSuperReadonly2ndNodeDead,
        BootstrapFailoverSuperReadonly2ndNodeDead) {
   const auto param = GetParam();
+  const std::string cluster_type_specific_id =
+      param.cluster_type == ClusterType::RS_V2
+          ? "00000000-0000-0000-0000-0000000000c1"
+          : "00000000-0000-0000-0000-0000000000g1";
 
   const auto dead_port = port_pool_.get_next_available();
   std::vector<Config> config{
       // member-1, PRIMARY, fails at first write
       {"127.0.0.1", port_pool_.get_next_available(),
        port_pool_.get_next_available(),
-       get_data_dir().join(param.trace_file).str()},
+       get_data_dir().join(param.trace_file).str(), /*unaccessible=*/false,
+       cluster_type_specific_id},
       // member-2, unreachable
       {"127.0.0.1", dead_port, port_pool_.get_next_available(), "",
-       /*unaccessible=*/true},
+       /*unaccessible=*/true, cluster_type_specific_id},
       // member-3, succeeds
       {"127.0.0.1", port_pool_.get_next_available(),
        port_pool_.get_next_available(),
-       get_data_dir().join(param.trace_file2).str()},
+       get_data_dir().join(param.trace_file2).str(), /*unaccessible=*/false,
+       cluster_type_specific_id},
   };
 
   ASSERT_NO_FATAL_FAILURE(bootstrap_failover(
@@ -1324,7 +1337,7 @@ INSTANTIATE_TEST_SUITE_P(
 /**
  * @test
  * This test proves that bootstrap will not print out the success message
- * ("MySQL Router configured for the InnoDB cluster 'mycluster'" and many lines
+ * ("MySQL Router configured for the InnoDB cluster 'my-cluster'" and many lines
  *  that follow it) until entire bootstrap succeeds.
  *
  * At the time of writing, the last operation that bootstrap performs is
@@ -1380,7 +1393,7 @@ TEST_F(RouterBootstrapTest,
   // displayed
   EXPECT_THAT(router.get_full_output(), ::testing::Not(::testing::HasSubstr(
                                             "MySQL Router configured for the "
-                                            "InnoDB cluster 'mycluster'")));
+                                            "InnoDB cluster 'my-cluster'")));
 
   server_mock.kill();
 }
@@ -1637,7 +1650,8 @@ TEST_P(ConfUseGrNotificationParamTest, ConfUseGrNotificationParam) {
   set_mock_bootstrap_data(
       http_port, "test",
       {{"localhost", server_port}, {"localhost", server_port2}},
-      GetParam().metadata_schema_version, "cluster-specific-id");
+      GetParam().metadata_schema_version,
+      "00000000-0000-0000-0000-0000000000c1");
 
   const auto router_port_rw = port_pool_.get_next_available();
   const auto router_port_ro = port_pool_.get_next_available();
@@ -1686,7 +1700,8 @@ TEST_P(ConfUseGrNotificationParamTest, ConfUseGrNotificationParam) {
   // launch mock server that is our metadata server
   launch_mysql_server_mock(runtime_json_stmts, server_port, EXIT_SUCCESS, false,
                            http_port);
-  set_mock_metadata(http_port, "cluster-specific-id", {server_port});
+  set_mock_metadata(http_port, "00000000-0000-0000-0000-0000000000g1",
+                    {server_port});
 
   ASSERT_NO_FATAL_FAILURE(launch_router({"-c", conf_file}));
 }
@@ -1995,7 +2010,7 @@ TEST_F(RouterBootstrapTest, BootstrapRouterDuplicateEntry) {
                            false, bootstrap_server_http_port);
   set_mock_bootstrap_data(bootstrap_server_http_port, "test",
                           {{"127.0.0.1", server_port}}, {2, 0, 3},
-                          "cluster-specific-id");
+                          "00000000-0000-0000-0000-0000000000c1");
 
   // launch the router in bootstrap mode
   auto &router = launch_router_for_bootstrap(
@@ -2031,7 +2046,7 @@ TEST_F(RouterBootstrapTest, CheckAuthBackendWhenOldMetadata) {
                            http_port);
 
   set_mock_bootstrap_data(http_port, "test", {{"localhost", server_port}},
-                          {1, 0, 0}, "cluster-specific-id");
+                          {1, 0, 0}, "00000000-0000-0000-0000-0000000000c1");
 
   const auto base_listening_port = port_pool_.get_next_available();
   std::vector<std::string> bootsrtap_params{
@@ -2476,7 +2491,7 @@ TEST_F(RouterBootstrapTest, SSLOptions) {
   set_mock_bootstrap_data(
       http_port, "test",
       {{"localhost", server_port}, {"localhost", server_port2}}, {2, 1, 0},
-      "00000000-0000-0000-0000-0000000000g1");
+      "00000000-0000-0000-0000-0000000000c1");
 
   const auto router_port_rw = port_pool_.get_next_available();
   const auto router_port_ro = port_pool_.get_next_available();
diff --git a/router/tests/component/test_bootstrap_account.cc b/router/tests/component/test_bootstrap_account.cc
index 2feded3f03b..320bbbfe95f 100644
--- a/router/tests/component/test_bootstrap_account.cc
+++ b/router/tests/component/test_bootstrap_account.cc
@@ -306,8 +306,7 @@ class AccountReuseTestBase : public RouterComponentBootstrapTest {
 
   // ---- account validation queries ----
   static std::string sql_val1(const std::string &cluster_name = "test") {
-    return "select C.cluster_id, C.cluster_name, I.mysql_server_uuid, "
-           "I.endpoint, I.xendpoint, I.attributes "
+    return "select I.mysql_server_uuid, I.endpoint, I.xendpoint, I.attributes "
            "from mysql_innodb_cluster_metadata.v2_instances I join "
            "mysql_innodb_cluster_metadata.v2_gr_clusters C on I.cluster_id = "
            "C.cluster_id where C.cluster_name = '" +
@@ -4765,7 +4764,7 @@ TEST_F(RouterReportHostTest, typical_usage) {
     // check if the bootstrapping was successful
     EXPECT_THAT(router.get_full_output(),
                 ::testing::HasSubstr("MySQL Router configured for the "
-                                     "InnoDB Cluster 'mycluster'"));
+                                     "InnoDB Cluster 'my-cluster'"));
     check_exit_code(router, EXIT_SUCCESS);
 
     server_mock.kill();
diff --git a/router/tests/component/test_bootstrap_clusterset.cc b/router/tests/component/test_bootstrap_clusterset.cc
index 40c39664e6f..93371d38077 100644
--- a/router/tests/component/test_bootstrap_clusterset.cc
+++ b/router/tests/component/test_bootstrap_clusterset.cc
@@ -52,20 +52,9 @@ using namespace std::string_literals;
 using mysqlrouter::ClusterType;
 
 // for the test with no param
-class RouterClusterSetBootstrapTest : public RouterComponentClusterSetTest {
+class RouterClusterSetBootstrapTest : public RouterComponentBootstrapTest,
+                                      public RouterComponentClusterSetTest {
  protected:
-  ProcessWrapper &launch_router_for_bootstrap(
-      std::vector<std::string> params, int expected_exit_code = EXIT_SUCCESS,
-      const bool disable_rest = true,
-      ProcessWrapper::OutputResponder output_responder =
-          RouterComponentBootstrapTest::kBootstrapOutputResponder) {
-    if (disable_rest) params.push_back("--disable-rest");
-
-    return ProcessManager::launch_router(
-        params, expected_exit_code, /*catch_stderr=*/true, /*with_sudo=*/false,
-        /*wait_for_notify_ready=*/std::chrono::seconds(-1), output_responder);
-  }
-
   using NodeAddress = std::pair<std::string, uint16_t>;
   TempDirectory bootstrap_directory;
   uint64_t view_id{1};
diff --git a/router/tests/component/test_bootstrap_system_deployment.cc b/router/tests/component/test_bootstrap_system_deployment.cc
index 0f8c1546c65..ff2f536f2a6 100644
--- a/router/tests/component/test_bootstrap_system_deployment.cc
+++ b/router/tests/component/test_bootstrap_system_deployment.cc
@@ -107,7 +107,7 @@ TEST_F(RouterBootstrapSystemDeploymentTest, BootstrapPass) {
 
   EXPECT_TRUE(
       router.expect_output("MySQL Router configured for the "
-                           "InnoDB Cluster 'mycluster'"));
+                           "InnoDB Cluster 'my-cluster'"));
 }
 
 /*
diff --git a/router/tests/component/test_clusterset.cc b/router/tests/component/test_clusterset.cc
index 6dc8b47e05a..59e60c3cbcc 100644
--- a/router/tests/component/test_clusterset.cc
+++ b/router/tests/component/test_clusterset.cc
@@ -43,12 +43,10 @@ Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
 #include "keyring/keyring_manager.h"
 #include "mock_server_rest_client.h"
 #include "mock_server_testutils.h"
-#include "mysql/harness/utility/string.h"  // join
 #include "mysqlrouter/cluster_metadata.h"
 #include "mysqlrouter/mysql_session.h"
 #include "mysqlrouter/rest_client.h"
 #include "mysqlrouter/utils.h"
-#include "rest_api_testutils.h"
 #include "router_component_clusterset.h"
 #include "router_component_test.h"
 #include "router_component_testutils.h"
@@ -58,29 +56,27 @@ using mysqlrouter::ClusterType;
 using mysqlrouter::MySQLSession;
 using ::testing::PrintToString;
 using namespace std::chrono_literals;
-using namespace std::string_literals;
 
 Path g_origin_path;
 
 class ClusterSetTest : public RouterComponentClusterSetTest {
  protected:
-  std::string metadata_cache_section(const std::chrono::milliseconds ttl = kTTL,
-                                     bool use_gr_notifications = false) {
+  std::pair<std::string, std::map<std::string, std::string>>
+  metadata_cache_section(const std::chrono::milliseconds ttl = kTTL,
+                         const std::string &cluster_type_str = "gr") {
     auto ttl_str = std::to_string(std::chrono::duration<double>(ttl).count());
 
-    return mysql_harness::ConfigBuilder::build_section(
-        "metadata_cache:test",
-        {{"cluster_type", "gr"},
-         {"router_id", "1"},
-         {"user", "mysql_router1_user"},
-         {"metadata_cluster", "test"},
-         {"connect_timeout", "1"},
-         {"ttl", ttl_str},
-         {"use_gr_notifications", use_gr_notifications ? "1" : "0"}});
+    std::map<std::string, std::string> options{
+        {"cluster_type", cluster_type_str}, {"router_id", "1"},
+        {"user", "mysql_router1_user"},     {"metadata_cluster", "test"},
+        {"connect_timeout", "1"},           {"ttl", ttl_str}};
+
+    return {"metadata_cache:test", options};
   }
 
-  std::string routing_section(uint16_t router_port, const std::string &role,
-                              const std::string &strategy) {
+  std::pair<std::string, std::map<std::string, std::string>> routing_section(
+      uint16_t router_port, const std::string &role,
+      const std::string &strategy) {
     std::map<std::string, std::string> options{
         {"bind_port", std::to_string(router_port)},
         {"destinations", "metadata-cache://test/default?role=" + role},
@@ -90,15 +86,13 @@ class ClusterSetTest : public RouterComponentClusterSetTest {
       options["routing_strategy"] = strategy;
     }
 
-    return mysql_harness::ConfigBuilder::build_section(
-        "routing:test_default" + std::to_string(router_port), options);
+    return {"routing:test_default" + std::to_string(router_port), options};
   }
 
   auto &launch_router(const int expected_errorcode = EXIT_SUCCESS,
                       const std::chrono::milliseconds wait_for_notify_ready =
                           kReadyNotifyTimeout,
-                      const std::chrono::milliseconds metadata_ttl = kTTL,
-                      bool use_gr_notifications = false) {
+                      const std::chrono::milliseconds metadata_ttl = kTTL) {
     SCOPED_TRACE("// Prepare the dynamic state file for the Router");
     const auto clusterset_all_nodes_ports =
         clusterset_data_.get_all_nodes_classic_ports();
@@ -108,10 +102,16 @@ class ClusterSetTest : public RouterComponentClusterSetTest {
                                                     clusterset_all_nodes_ports,
                                                     /*view_id*/ 1));
 
-    SCOPED_TRACE("// Prepare the config file for the Router");
     router_port_rw = port_pool_.get_next_available();
     router_port_ro = port_pool_.get_next_available();
 
+    auto writer = config_writer(temp_test_dir.name())
+                      .section(routing_section(router_port_rw, "PRIMARY",
+                                               "first-available"))
+                      .section(routing_section(router_port_ro, "SECONDARY",
+                                               "round-robin"))
+                      .section(metadata_cache_section(metadata_ttl));
+
     const std::string masterkey_file =
         Path(temp_test_dir.name()).join("master.key").str();
     const std::string keyring_file =
@@ -122,25 +122,18 @@ class ClusterSetTest : public RouterComponentClusterSetTest {
     mysql_harness::flush_keyring();
     mysql_harness::reset_keyring();
 
-    auto default_section = get_DEFAULT_defaults();
+    // launch the router with metadata-cache configuration
+    auto &default_section = writer.sections()["DEFAULT"];
     default_section["keyring_path"] = keyring_file;
     default_section["master_key_path"] = masterkey_file;
     default_section["dynamic_state"] = router_state_file;
 
-    const std::string userfile = create_password_file();
-    const std::string rest_sections = mysql_harness::join(
-        get_restapi_config("rest_metadata_cache", userfile, true), "\n");
-
-    router_conf_file = create_config_file(
-        temp_test_dir.name(),
-        metadata_cache_section(metadata_ttl, use_gr_notifications) +
-            routing_section(router_port_rw, "PRIMARY", "first-available") +
-            routing_section(router_port_ro, "SECONDARY", "round-robin") +
-            rest_sections,
-        &default_section);
-    auto &router = ProcessManager::launch_router(
-        {"-c", router_conf_file}, expected_errorcode, /*catch_stderr=*/true,
-        /*with_sudo=*/false, wait_for_notify_ready);
+    auto &router =
+        router_spawner()
+            .expected_exit_code(expected_errorcode)
+            .wait_for_notify_ready(wait_for_notify_ready)
+            .wait_for_sync_point(ProcessManager::Spawner::SyncPoint::READY)
+            .spawn({"-c", writer.write()});
 
     return router;
   }
@@ -161,28 +154,6 @@ class ClusterSetTest : public RouterComponentClusterSetTest {
     return get_int_field_value(server_globals, name);
   }
 
-  void set_fetch_whole_topology(bool value) {
-    const std::string metadata_cache_section_name = "test";
-    const std::string path = std::string(rest_api_basepath) + "/metadata/" +
-                             metadata_cache_section_name + "/config";
-    ASSERT_TRUE(wait_for_rest_endpoint_ready(path, http_port_, kRestApiUsername,
-                                             kRestApiPassword));
-
-    const std::string parameter = "fetchWholeTopology="s + (value ? "1" : "0");
-
-    IOContext io_ctx;
-    RestClient rest_client(io_ctx, "127.0.0.1", http_port_, kRestApiUsername,
-                           kRestApiPassword);
-
-    auto req =
-        rest_client.request_sync(HttpMethod::Get, path + "?" + parameter);
-
-    ASSERT_TRUE(req) << "HTTP Request failed (early): " << req.error_msg()
-                     << std::endl;
-    ASSERT_GT(req.get_response_code(), 0u)
-        << "HTTP Request failed: " << req.error_msg() << std::endl;
-  }
-
   // @brief wait until global read from the mock server is greater or equal
   // expected threashold
   // @retval true selected global is greater or equal to expected threshold
@@ -432,15 +403,13 @@ TEST_P(ClusterChangeTargetClusterInTheMetadataTest,
                                          ? "accepting RW connections"
                                          : "not accepting RW connections";
 
-    const std::string pattern1 =
-        "INFO .* Target cluster\\(s\\) are part of a ClusterSet: " +
-        accepting_rw;
-    const std::string pattern2 =
-        "INFO .* Cluster '" + target_cluster_name +
-        "': role of a cluster within a ClusterSet is '" + cluster_role + "';";
+    const std::string pattern =
+        "INFO .* Target cluster '" + target_cluster_name +
+        "' is part of a ClusterSet; role of a cluster within a ClusterSet "
+        "is '" +
+        cluster_role + "'; " + accepting_rw;
 
-    EXPECT_TRUE(wait_log_contains(router, pattern1, 5s)) << pattern1;
-    EXPECT_TRUE(wait_log_contains(router, pattern2, 5s)) << pattern2;
+    EXPECT_TRUE(wait_log_contains(router, pattern, 5s)) << pattern;
   }
 
   SCOPED_TRACE(
@@ -494,30 +463,25 @@ TEST_P(ClusterChangeTargetClusterInTheMetadataTest,
     const std::string accepting_rw = changed_target_cluster_id == 0
                                          ? "accepting RW connections"
                                          : "not accepting RW connections";
-    const std::string pattern1 =
+    const std::string pattern =
         "INFO .* New target cluster assigned in the metadata: '" +
         changed_target_cluster_name + "'";
 
     const std::string pattern2 =
-        "INFO .* Target cluster\\(s\\) are part of a ClusterSet: " +
-        accepting_rw;
-    const std::string pattern3 =
-        "INFO .* Cluster '" + changed_target_cluster_name +
-        "': role of a cluster within a ClusterSet is '" + cluster_role + "';";
-
-    EXPECT_TRUE(wait_log_contains(router, pattern1, 5s)) << pattern1;
-    EXPECT_TRUE(wait_log_contains(router, pattern2, 5s)) << pattern2;
+        "INFO .* Target cluster '" + changed_target_cluster_name +
+        "' is part of a ClusterSet; role of a cluster within a ClusterSet "
+        "is '" +
+        cluster_role + "'; " + accepting_rw;
 
-    const std::string pattern4 =
+    const std::string pattern3 =
         "INFO .* New router options read from the metadata "
         "'\\{\"target_cluster\" : \"" +
         changed_target_cluster + "\" \\}', was '\\{\"target_cluster\" : \"" +
         initial_target_cluster + "\" \\}'";
 
-    EXPECT_TRUE(wait_log_contains(router, pattern1, 5s)) << pattern1;
+    EXPECT_TRUE(wait_log_contains(router, pattern, 5s)) << pattern;
     EXPECT_TRUE(wait_log_contains(router, pattern2, 100ms)) << pattern2;
     EXPECT_TRUE(wait_log_contains(router, pattern3, 100ms)) << pattern3;
-    EXPECT_TRUE(wait_log_contains(router, pattern4, 100ms)) << pattern4;
   }
 
   if (GetParam().initial_connections_should_drop) {
@@ -2372,180 +2336,6 @@ INSTANTIATE_TEST_SUITE_P(UseReplicaPrimaryAsRwNodeInvalid,
                          ClusterSetUseReplicaPrimaryAsRwNodeInvalidTest,
                          ::testing::Values("\"\"", "0", "1", "\"foo\"",
                                            "\"false\""));
-/**
- * @test Checks that switching between fetch_whole_topology on and off works as
- * expected when it comes to routing new connections and keeping/closing
- * existing ones
- */
-TEST_F(ClusterSetTest, FetchWholeTopologyConnections) {
-  const std::string target_cluster = "00000000-0000-0000-0000-0000000000g2";
-  const auto target_cluster_id = 1;
-
-  create_clusterset(
-      view_id, target_cluster_id, /*primary_cluster_id*/ 0,
-      "metadata_clusterset.js",
-      /*router_options*/ R"({"target_cluster" : ")" + target_cluster + "\" }");
-
-  SCOPED_TRACE("// Launch the Router");
-  /*auto &router = */ launch_router();
-
-  // since our target cluster is replica we should not be able to make RW
-  // connection
-  verify_new_connection_fails(router_port_rw);
-
-  // RO connections should be routed to the first replica
-  std::vector<std::unique_ptr<MySQLSession>> ro_cons_to_target_cluster;
-  for (const auto &node :
-       clusterset_data_.clusters[kFirstReplicaClusterId].nodes) {
-    ro_cons_to_target_cluster.emplace_back(
-        make_new_connection_ok(router_port_ro, node.classic_port));
-  }
-
-  EXPECT_EQ(3, ro_cons_to_target_cluster.size());
-
-  // switch the mode to fetch_whole_topology
-  set_fetch_whole_topology(true);
-  EXPECT_TRUE(wait_for_transaction_count_increase(
-      clusterset_data_.clusters[0].nodes[0].http_port, 2));
-
-  // since now the nodes pool is the superset of the previous pool the existing
-  // RO connections should still be alive
-  for (const auto &con : ro_cons_to_target_cluster) {
-    verify_existing_connection_ok(con.get());
-  }
-
-  // there is RW node now in the available nodes pool (from Primary Cluster) so
-  // the RW connection should be possible now
-  const auto rw_con = make_new_connection_ok(
-      router_port_rw,
-      clusterset_data_.clusters[kPrimaryClusterId].nodes[0].classic_port);
-
-  // Let's make a bunch of new RO connections, they should go to the RO nodes of
-  // all the Clusters of the ClusterSet since we are in the fetch_whole_topology
-  // mode now
-  std::vector<std::unique_ptr<MySQLSession>> ro_cons_to_primary;
-  for (size_t i = 1;
-       i < clusterset_data_.clusters[kPrimaryClusterId].nodes.size(); ++i) {
-    ro_cons_to_primary.emplace_back(make_new_connection_ok(
-        router_port_ro,
-        clusterset_data_.clusters[kPrimaryClusterId].nodes[i].classic_port));
-  }
-  EXPECT_EQ(2, ro_cons_to_primary.size());
-
-  std::vector<std::unique_ptr<MySQLSession>> ro_cons_to_first_replica;
-  for (size_t i = 1;
-       i < clusterset_data_.clusters[kFirstReplicaClusterId].nodes.size();
-       ++i) {
-    ro_cons_to_first_replica.emplace_back(make_new_connection_ok(
-        router_port_ro, clusterset_data_.clusters[kFirstReplicaClusterId]
-                            .nodes[i]
-                            .classic_port));
-  }
-  EXPECT_EQ(2, ro_cons_to_first_replica.size());
-
-  std::vector<std::unique_ptr<MySQLSession>> ro_cons_to_second_replica;
-  for (size_t i = 1;
-       i < clusterset_data_.clusters[kSecondReplicaClusterId].nodes.size();
-       ++i) {
-    ro_cons_to_second_replica.emplace_back(make_new_connection_ok(
-        router_port_ro, clusterset_data_.clusters[kSecondReplicaClusterId]
-                            .nodes[i]
-                            .classic_port));
-  }
-  EXPECT_EQ(2, ro_cons_to_second_replica.size());
-
-  // switch off the mode fetch_whole_topology
-  set_fetch_whole_topology(false);
-  EXPECT_TRUE(wait_for_transaction_count_increase(
-      clusterset_data_.clusters[0].nodes[0].http_port, 2));
-
-  // we are back in the "use only the target cluster" mode
-  // the RW connection should be shut down
-  verify_existing_connection_dropped(rw_con.get());
-
-  // the RO connections to the Clusters other than our target_cluster should be
-  // dropped too
-  for (const auto &con : ro_cons_to_primary) {
-    verify_existing_connection_dropped(con.get());
-  }
-  for (const auto &con : ro_cons_to_second_replica) {
-    verify_existing_connection_dropped(con.get());
-  }
-
-  // the RO connections to our target_cluster should still be fine tho
-  for (const auto &con : ro_cons_to_target_cluster) {
-    verify_existing_connection_ok(con.get());
-  }
-  for (const auto &con : ro_cons_to_first_replica) {
-    verify_existing_connection_ok(con.get());
-  }
-
-  // again no new RW connection should be possible
-  verify_new_connection_fails(router_port_rw);
-  // new RO connections should be directed to our target_cluster
-  for (const auto &node :
-       clusterset_data_.clusters[kFirstReplicaClusterId].nodes) {
-    ro_cons_to_target_cluster.emplace_back(
-        make_new_connection_ok(router_port_ro, node.classic_port));
-  }
-}
-
-/**
- * @test Checks that switching between fetch_whole_topology on and off works as
- * expected when when GR notifications are in use
- */
-TEST_F(ClusterSetTest, UseMultipleClustersGrNotifications) {
-  const std::string target_cluster = "00000000-0000-0000-0000-0000000000g2";
-  const auto target_cluster_id = 1;
-
-  create_clusterset(
-      view_id, target_cluster_id, /*primary_cluster_id*/ 0,
-      "metadata_clusterset.js",
-      /*router_options*/ R"({"target_cluster" : ")" + target_cluster + "\" }",
-      ".*", false, true);
-
-  SCOPED_TRACE("// Launch the Router");
-  auto &router = launch_router(EXIT_SUCCESS, 10s, kTTL, true);
-
-  EXPECT_TRUE(wait_for_transaction_count_increase(
-      clusterset_data_.clusters[0].nodes[0].http_port, 2));
-
-  // we do not use multiple clusters yet, let's check that we opened GR
-  // notification connections only to our target_cluster
-  std::string log_content = router.get_logfile_content();
-  for (auto &cluster : clusterset_data_.clusters) {
-    for (auto &node : cluster.nodes) {
-      const std::string log_entry =
-          "Enabling GR notices for cluster '" + cluster.name +
-          "' changes on node 127.0.0.1:" + std::to_string(node.x_port);
-
-      const size_t expected_log_occurences =
-          cluster.gr_uuid == target_cluster ? 1 : 0;
-      EXPECT_EQ(expected_log_occurences,
-                count_str_occurences(log_content, log_entry));
-    }
-  }
-
-  // switch to use multiple clusters now
-  set_fetch_whole_topology(true);
-  EXPECT_TRUE(wait_for_transaction_count_increase(
-      clusterset_data_.clusters[0].nodes[0].http_port, 2));
-
-  // now we expect the GR notification listener to be opened once on each
-  // ClusterSet node
-  log_content = router.get_logfile_content();
-  for (auto &cluster : clusterset_data_.clusters) {
-    for (auto &node : cluster.nodes) {
-      const std::string log_entry =
-          "Enabling GR notices for cluster '" + cluster.name +
-          "' changes on node 127.0.0.1:" + std::to_string(node.x_port);
-
-      const size_t expected_log_occurences = 1;
-      EXPECT_EQ(expected_log_occurences,
-                count_str_occurences(log_content, log_entry));
-    }
-  }
-}
 
 int main(int argc, char *argv[]) {
   init_windows_sockets();
diff --git a/router/tests/component/test_master_key_reader_writer.cc b/router/tests/component/test_master_key_reader_writer.cc
index f1cd1ecf362..5f86255367a 100644
--- a/router/tests/component/test_master_key_reader_writer.cc
+++ b/router/tests/component/test_master_key_reader_writer.cc
@@ -239,7 +239,7 @@ TEST_F(MasterKeyReaderWriterTest,
   // check if the bootstrapping was successful
   ASSERT_NO_FATAL_FAILURE(check_exit_code(router, EXIT_SUCCESS, 30000ms));
   EXPECT_TRUE(router.expect_output(
-      "MySQL Router configured for the InnoDB Cluster 'mycluster'"))
+      "MySQL Router configured for the InnoDB Cluster 'my-cluster'"))
       << router.get_full_output() << std::endl
       << "server: " << server_mock.get_full_output();
 
@@ -289,7 +289,7 @@ TEST_F(MasterKeyReaderWriterTest,
   ASSERT_NO_FATAL_FAILURE(check_exit_code(router, EXIT_SUCCESS, 30000ms));
   EXPECT_TRUE(
       router.expect_output("MySQL Router configured for the "
-                           "InnoDB Cluster 'mycluster'"))
+                           "InnoDB Cluster 'my-cluster'"))
       << router.get_full_output() << std::endl
       << "server: " << server_mock.get_full_output();
 
@@ -492,7 +492,7 @@ TEST_F(MasterKeyReaderWriterTest,
   ASSERT_NO_FATAL_FAILURE(check_exit_code(router, EXIT_SUCCESS, 30000ms));
   EXPECT_TRUE(
       router.expect_output("MySQL Router configured for the "
-                           "InnoDB Cluster 'mycluster'"))
+                           "InnoDB Cluster 'my-cluster'"))
       << router.get_full_output() << std::endl
       << "server: " << server_mock.get_full_output();
 
@@ -812,7 +812,7 @@ TEST_F(MasterKeyReaderWriterSystemDeploymentTest, BootstrapPass) {
 
   EXPECT_TRUE(
       router.expect_output("MySQL Router configured for the "
-                           "InnoDB Cluster 'mycluster'"))
+                           "InnoDB Cluster 'my-cluster'"))
       << router.get_full_output() << std::endl
       << "server: " << server_mock.get_full_output();
 
diff --git a/router/tests/component/test_rest_api_enable.cc b/router/tests/component/test_rest_api_enable.cc
index bdeccd7c573..b79d16a0d57 100644
--- a/router/tests/component/test_rest_api_enable.cc
+++ b/router/tests/component/test_rest_api_enable.cc
@@ -101,7 +101,7 @@ class TestRestApiEnable : public RouterComponentTest {
     check_exit_code(router_bootstrap, EXIT_SUCCESS);
 
     EXPECT_TRUE(router_bootstrap.expect_output(
-        "MySQL Router configured for the InnoDB Cluster 'mycluster'"));
+        "MySQL Router configured for the InnoDB Cluster 'my-cluster'"));
 
     auto plugin_dir = mysql_harness::get_plugin_dir(get_origin().str());
     EXPECT_TRUE(add_line_to_config_file(config_path.str(), "DEFAULT",
@@ -608,7 +608,7 @@ TEST_P(EnableWrongHttpsPort, ensure_bootstrap_fails_for_invalid_https_port) {
   check_exit_code(router_bootstrap, EXIT_FAILURE);
 
   EXPECT_FALSE(router_bootstrap.expect_output(
-      "MySQL Router configured for the InnoDB Cluster 'mycluster'"));
+      "MySQL Router configured for the InnoDB Cluster 'my-cluster'"));
 
   EXPECT_FALSE(certificate_files_exists(
       {cert_file_t::k_ca_key, cert_file_t::k_ca_cert, cert_file_t::k_router_key,
@@ -665,7 +665,7 @@ TEST_F(TestRestApiEnable, bootstrap_conflicting_options) {
   check_exit_code(router_bootstrap, EXIT_FAILURE);
 
   EXPECT_FALSE(router_bootstrap.expect_output(
-      "MySQL Router configured for the InnoDB Cluster 'mycluster'"));
+      "MySQL Router configured for the InnoDB Cluster 'my-cluster'"));
 
   EXPECT_FALSE(certificate_files_exists(
       {cert_file_t::k_ca_key, cert_file_t::k_ca_cert, cert_file_t::k_router_key,
@@ -970,7 +970,7 @@ class TestRestApiEnableBootstrapFailover : public TestRestApiEnable {
 
  private:
   const mysqlrouter::MetadataSchemaVersion metadata_version{2, 0, 3};
-  const std::string cluster_name{"mycluster"};
+  const std::string cluster_name{"my-cluster"};
   std::vector<std::pair<uint16_t, ProcessWrapper &>> mock_servers;
   std::vector<std::pair<std::string, unsigned>> gr_members;
   static const uint8_t k_node_count{3};
diff --git a/router/tests/component/test_routing.cc b/router/tests/component/test_routing.cc
index 4ee527e0786..bd4bb4d99f0 100644
--- a/router/tests/component/test_routing.cc
+++ b/router/tests/component/test_routing.cc
@@ -161,7 +161,7 @@ TEST_F(RouterRoutingTest, RoutingOk) {
   ASSERT_NO_FATAL_FAILURE(check_exit_code(router_bootstrapping, EXIT_SUCCESS));
 
   ASSERT_TRUE(router_bootstrapping.expect_output(
-      "MySQL Router configured for the InnoDB Cluster 'mycluster'"));
+      "MySQL Router configured for the InnoDB Cluster 'my-cluster'"));
 }
 
 struct ConnectTimeoutTestParam {
diff --git a/router/tests/component/test_state_file.cc b/router/tests/component/test_state_file.cc
index 2d70c6e7247..9a28ffed69a 100644
--- a/router/tests/component/test_state_file.cc
+++ b/router/tests/component/test_state_file.cc
@@ -1128,8 +1128,9 @@ TEST_F(StateFileDirectoryBootstrapTest, DirectoryBootstrapTest) {
   // check the state file that was produced, if it contains
   // what the bootstrap server has reported
   const std::string state_file = temp_test_dir.name() + "/data/state.json";
-  check_state_file(state_file, ClusterType::GR_V1, "cluster-specific-id",
-                   {5500, 5510, 5520}, 0, "localhost");
+  check_state_file(state_file, ClusterType::GR_V1,
+                   "00000000-0000-0000-0000-0000000000g1", {5500, 5510, 5520},
+                   0, "localhost");
 
   // check that static file has a proper reference to the dynamic file
   const std::string conf_content =
@@ -1189,8 +1190,9 @@ TEST_F(StateFileSystemBootstrapTest, SystemBootstrapTest) {
   const std::string state_file =
       RouterSystemLayout::tmp_dir_ + "/stage/var/lib/mysqlrouter/state.json";
 
-  check_state_file(state_file, ClusterType::GR_V1, "cluster-specific-id",
-                   {5500, 5510, 5520}, 0, "localhost");
+  check_state_file(state_file, ClusterType::GR_V1,
+                   "00000000-0000-0000-0000-0000000000g1", {5500, 5510, 5520},
+                   0, "localhost");
 }
 
 #endif  // SKIP_BOOTSTRAP_SYSTEM_DEPLOYMENT_TESTS
diff --git a/router/tests/helpers/router_component_clusterset.cc b/router/tests/helpers/router_component_clusterset.cc
index c13c3588c5a..4241cb694b5 100644
--- a/router/tests/helpers/router_component_clusterset.cc
+++ b/router/tests/helpers/router_component_clusterset.cc
@@ -30,8 +30,8 @@
 void RouterComponentClusterSetTest::create_clusterset(
     uint64_t view_id, int target_cluster_id, int primary_cluster_id,
     const std::string &tracefile, const std::string &router_options,
-    const std::string &expected_target_cluster, bool simulate_cluster_not_found,
-    bool use_gr_notifications) {
+    const std::string &expected_target_cluster,
+    bool simulate_cluster_not_found) {
   const std::string tracefile_path = get_data_dir().str() + "/" + tracefile;
 
   ClusterSetData clusterset_data;
@@ -57,9 +57,6 @@ void RouterComponentClusterSetTest::create_clusterset(
       cluster_node.host = "127.0.0.1";
       cluster_node.classic_port = port_pool_.get_next_available();
       cluster_node.http_port = port_pool_.get_next_available();
-      if (use_gr_notifications) {
-        cluster_node.x_port = port_pool_.get_next_available();
-      }
 
       cluster_data.nodes.push_back(cluster_node);
     }
@@ -74,9 +71,9 @@ void RouterComponentClusterSetTest::create_clusterset(
     auto &cluster = clusterset_data.clusters[cluster_id];
     for (unsigned node_id = 0; node_id < cluster.nodes.size(); ++node_id) {
       auto &node = cluster.nodes[node_id];
-      node.process = &launch_mysql_server_mock(
-          tracefile_path, node.classic_port, EXIT_SUCCESS, false,
-          node.http_port, node.x_port);
+      node.process =
+          &launch_mysql_server_mock(tracefile_path, node.classic_port,
+                                    EXIT_SUCCESS, false, node.http_port);
 
       set_mock_metadata(view_id, cluster_id, target_cluster_id, node.http_port,
                         clusterset_data, router_options,
@@ -143,9 +140,6 @@ void RouterComponentClusterSetTest::add_clusterset_data_field(
       add_json_str_field(node_obj, "host", node_data.host);
       add_json_int_field(node_obj, "classic_port", node_data.classic_port);
       add_json_int_field(node_obj, "http_port", node_data.http_port);
-      if (node_data.x_port > 0) {
-        add_json_int_field(node_obj, "x_port", node_data.x_port);
-      }
 
       cluster_nodes_array.PushBack(node_obj, json_allocator);
     }
diff --git a/router/tests/helpers/router_component_clusterset.h b/router/tests/helpers/router_component_clusterset.h
index 18324f42dc5..9d36ab907e3 100644
--- a/router/tests/helpers/router_component_clusterset.h
+++ b/router/tests/helpers/router_component_clusterset.h
@@ -42,7 +42,6 @@
 #include <rapidjson/stringbuffer.h>
 
 #include "mysqlrouter/cluster_metadata.h"
-#include "rest_api_testutils.h"
 #include "router_component_test.h"
 
 using mysqlrouter::ClusterType;
@@ -58,14 +57,13 @@ using JsonStringBuffer =
     rapidjson::GenericStringBuffer<rapidjson::UTF8<>, rapidjson::CrtAllocator>;
 }  // namespace
 
-class RouterComponentClusterSetTest : public RestApiComponentTest {
+class RouterComponentClusterSetTest : virtual public RouterComponentTest {
  protected:
   struct ClusterNode {
     std::string uuid;
 
     std::string host;
     uint16_t classic_port;
-    uint16_t x_port{0};
     uint16_t http_port;
 
     ProcessWrapper *process{nullptr};
@@ -125,8 +123,7 @@ class RouterComponentClusterSetTest : public RestApiComponentTest {
                          int primary_cluster_id, const std::string &tracefile,
                          const std::string &router_options = "",
                          const std::string &expected_target_cluster = ".*",
-                         bool simulate_cluster_not_found = false,
-                         bool use_gr_notifications = false);
+                         bool simulate_cluster_not_found = false);
 
   void change_clusterset_primary(ClusterSetData &clusterset_data,
                                  const unsigned new_primary_id);
diff --git a/router/tests/helpers/router_component_test.cc b/router/tests/helpers/router_component_test.cc
index 9b4a7b2bf10..c3080ede108 100644
--- a/router/tests/helpers/router_component_test.cc
+++ b/router/tests/helpers/router_component_test.cc
@@ -116,7 +116,7 @@ void RouterComponentBootstrapTest::bootstrap_failover(
     std::chrono::milliseconds wait_for_exit_timeout,
     const mysqlrouter::MetadataSchemaVersion &metadata_version,
     const std::vector<std::string> &extra_router_options) {
-  std::string cluster_name("mycluster");
+  std::string cluster_name("my-cluster");
 
   std::vector<std::pair<std::string, unsigned>> gr_members;
   for (const auto &mock_server_config : mock_server_configs) {
diff --git a/router/tests/helpers/router_component_test.h b/router/tests/helpers/router_component_test.h
index b26dd6e1da2..da3511974b6 100644
--- a/router/tests/helpers/router_component_test.h
+++ b/router/tests/helpers/router_component_test.h
@@ -160,7 +160,7 @@ class RouterComponentBootstrapTest : virtual public RouterComponentTest {
     uint16_t http_port;
     std::string js_filename;
     bool unaccessible{false};
-    std::string cluster_specific_id{"cluster-specific-id"};
+    std::string cluster_specific_id{"00000000-0000-0000-0000-0000000000g1"};
   };
 
   void bootstrap_failover(
-- 
2.37.2

